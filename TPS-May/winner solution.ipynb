{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tabular May - Baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-XohP1V5wvDO",
        "ylFx55xNG10O",
        "g2jILZN8FAbW",
        "vPutft8ZI3vE"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJjDNiCkwn2-"
      },
      "source": [
        "# Installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJoVKJb5wN0L",
        "outputId": "351399d2-3ccb-45b4-98be-79282f371611"
      },
      "source": [
        "# Kaggle API for downloading the datasets\n",
        "!pip install --upgrade -q kaggle\n",
        "\n",
        "# Optuna for parameter search\n",
        "!pip install -q optuna\n",
        "\n",
        "!pip install --upgrade xgboost\n",
        "\n",
        "# upgrask sklearn\n",
        "!pip install --upgrade scikit-learn\n",
        "\n",
        "!pip install category_encoders\n",
        "!pip install catboost\n",
        "# lighgbm gpu compatible\n",
        "!git clone --recursive https://github.com/Microsoft/LightGBM\n",
        "! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 296kB 7.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 8.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 27.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 36.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 25.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 6.9MB/s \n",
            "\u001b[?25h  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting xgboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/35/169eec194bf1f9ef52ed670f5032ef2abaf6ed285cfadcb4b6026b800fc9/xgboost-1.4.2-py3-none-manylinux2010_x86_64.whl (166.7MB)\n",
            "\u001b[K     |████████████████████████████████| 166.7MB 41kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.19.5)\n",
            "Installing collected packages: xgboost\n",
            "  Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "Successfully installed xgboost-1.4.2\n",
            "Collecting scikit-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/eb/a48f25c967526b66d5f1fa7a984594f0bf0a5afafa94a8c4dbc317744620/scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3MB 1.7MB/s \n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.24.2 threadpoolctl-2.1.0\n",
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/57/fcef41c248701ee62e8325026b90c432adea35555cbc870aff9cfba23727/category_encoders-2.2.2-py2.py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.24.2)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.19.5)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (2.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.2.2\n",
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/80/8e9c57ec32dfed6ba2922bc5c96462cbf8596ce1a6f5de532ad1e43e53fe/catboost-0.25.1-cp37-none-manylinux1_x86_64.whl (67.3MB)\n",
            "\u001b[K     |████████████████████████████████| 67.3MB 64kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.25.1\n",
            "Cloning into 'LightGBM'...\n",
            "remote: Enumerating objects: 22151, done.\u001b[K\n",
            "remote: Counting objects: 100% (697/697), done.\u001b[K\n",
            "remote: Compressing objects: 100% (393/393), done.\u001b[K\n",
            "remote: Total 22151 (delta 414), reused 496 (delta 292), pack-reused 21454\u001b[K\n",
            "Receiving objects: 100% (22151/22151), 17.50 MiB | 28.67 MiB/s, done.\n",
            "Resolving deltas: 100% (16125/16125), done.\n",
            "Submodule 'include/boost/compute' (https://github.com/boostorg/compute) registered for path 'external_libs/compute'\n",
            "Submodule 'eigen' (https://gitlab.com/libeigen/eigen.git) registered for path 'external_libs/eigen'\n",
            "Submodule 'external_libs/fast_double_parser' (https://github.com/lemire/fast_double_parser.git) registered for path 'external_libs/fast_double_parser'\n",
            "Submodule 'external_libs/fmt' (https://github.com/fmtlib/fmt.git) registered for path 'external_libs/fmt'\n",
            "Cloning into '/content/LightGBM/external_libs/compute'...\n",
            "remote: Enumerating objects: 21728, done.        \n",
            "remote: Total 21728 (delta 0), reused 0 (delta 0), pack-reused 21728        \n",
            "Receiving objects: 100% (21728/21728), 8.51 MiB | 24.54 MiB/s, done.\n",
            "Resolving deltas: 100% (17566/17566), done.\n",
            "Cloning into '/content/LightGBM/external_libs/eigen'...\n",
            "remote: Enumerating objects: 1146, done.        \n",
            "remote: Counting objects: 100% (1146/1146), done.        \n",
            "remote: Compressing objects: 100% (377/377), done.        \n",
            "remote: Total 109780 (delta 876), reused 1005 (delta 765), pack-reused 108634        \n",
            "Receiving objects: 100% (109780/109780), 101.91 MiB | 27.08 MiB/s, done.\n",
            "Resolving deltas: 100% (90143/90143), done.\n",
            "Cloning into '/content/LightGBM/external_libs/fast_double_parser'...\n",
            "remote: Enumerating objects: 686, done.        \n",
            "remote: Counting objects: 100% (186/186), done.        \n",
            "remote: Compressing objects: 100% (117/117), done.        \n",
            "remote: Total 686 (delta 91), reused 101 (delta 42), pack-reused 500        \n",
            "Receiving objects: 100% (686/686), 801.53 KiB | 15.12 MiB/s, done.\n",
            "Resolving deltas: 100% (345/345), done.\n",
            "Cloning into '/content/LightGBM/external_libs/fmt'...\n",
            "remote: Enumerating objects: 26035, done.        \n",
            "remote: Counting objects: 100% (1266/1266), done.        \n",
            "remote: Compressing objects: 100% (413/413), done.        \n",
            "remote: Total 26035 (delta 799), reused 1114 (delta 705), pack-reused 24769        \n",
            "Receiving objects: 100% (26035/26035), 13.23 MiB | 22.50 MiB/s, done.\n",
            "Resolving deltas: 100% (17574/17574), done.\n",
            "Submodule path 'external_libs/compute': checked out '36c89134d4013b2e5e45bc55656a18bd6141995a'\n",
            "Submodule path 'external_libs/eigen': checked out '8ba1b0f41a7950dc3e1d4ed75859e36c73311235'\n",
            "Submodule path 'external_libs/fast_double_parser': checked out 'ace60646c02dc54c57f19d644e49a61e7e7758ec'\n",
            "Submodule 'benchmark/dependencies/abseil-cpp' (https://github.com/abseil/abseil-cpp.git) registered for path 'external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp'\n",
            "Submodule 'benchmark/dependencies/double-conversion' (https://github.com/google/double-conversion.git) registered for path 'external_libs/fast_double_parser/benchmarks/dependencies/double-conversion'\n",
            "Cloning into '/content/LightGBM/external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp'...\n",
            "remote: Enumerating objects: 14570, done.        \n",
            "remote: Counting objects: 100% (505/505), done.        \n",
            "remote: Compressing objects: 100% (381/381), done.        \n",
            "remote: Total 14570 (delta 266), reused 341 (delta 124), pack-reused 14065        \n",
            "Receiving objects: 100% (14570/14570), 9.78 MiB | 22.10 MiB/s, done.\n",
            "Resolving deltas: 100% (11007/11007), done.\n",
            "Cloning into '/content/LightGBM/external_libs/fast_double_parser/benchmarks/dependencies/double-conversion'...\n",
            "remote: Enumerating objects: 1225, done.        \n",
            "remote: Counting objects: 100% (69/69), done.        \n",
            "remote: Compressing objects: 100% (49/49), done.        \n",
            "remote: Total 1225 (delta 38), reused 34 (delta 20), pack-reused 1156        \n",
            "Receiving objects: 100% (1225/1225), 7.08 MiB | 17.86 MiB/s, done.\n",
            "Resolving deltas: 100% (810/810), done.\n",
            "Submodule path 'external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp': checked out 'd936052d32a5b7ca08b0199a6724724aea432309'\n",
            "Submodule path 'external_libs/fast_double_parser/benchmarks/dependencies/double-conversion': checked out 'f4cb2384efa55dee0e6652f8674b05763441ab09'\n",
            "Submodule path 'external_libs/fmt': checked out 'cc09f1a6798c085c325569ef466bcdcffdc266d4'\n",
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found OpenMP_C: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP: TRUE (found version \"4.5\")  \n",
            "-- Looking for CL_VERSION_2_2\n",
            "-- Looking for CL_VERSION_2_2 - found\n",
            "-- Found OpenCL: /usr/lib/x86_64-linux-gnu/libOpenCL.so (found version \"2.2\") \n",
            "-- OpenCL include directory: /usr/include\n",
            "-- Boost version: 1.65.1\n",
            "-- Found the following Boost libraries:\n",
            "--   filesystem\n",
            "--   system\n",
            "-- Performing Test MM_PREFETCH\n",
            "-- Performing Test MM_PREFETCH - Success\n",
            "-- Using _mm_prefetch\n",
            "-- Performing Test MM_MALLOC\n",
            "-- Performing Test MM_MALLOC - Success\n",
            "-- Using _mm_malloc\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/LightGBM/build\n",
            "\u001b[35m\u001b[1mScanning dependencies of target _lightgbm\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target lightgbm\u001b[0m\n",
            "[  1%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/boosting.cpp.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/main.cpp.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/application/application.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/boosting.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/bin.cpp.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt.cpp.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/config.cpp.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/config_auto.cpp.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/bin.cpp.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/dataset.cpp.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/config.cpp.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/config_auto.cpp.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/dataset.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/dataset_loader.cpp.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/dataset_loader.cpp.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/file_io.cpp.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/json11.cpp.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/file_io.cpp.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/json11.cpp.o\u001b[0m\n",
            "[ 39%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/metadata.cpp.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/parser.cpp.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/metadata.cpp.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/train_share_states.cpp.o\u001b[0m\n",
            "[ 44%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/tree.cpp.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/metric/dcg_calculator.cpp.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/metric/metric.cpp.o\u001b[0m\n",
            "[ 49%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/parser.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/ifaddrs_patch.cpp.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linker_topo.cpp.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linkers_mpi.cpp.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linkers_socket.cpp.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/train_share_states.cpp.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/tree.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/network.cpp.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/objective/objective_function.cpp.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/cuda_tree_learner.cpp.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/metric/dcg_calculator.cpp.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/metric/metric.cpp.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/linear_tree_learner.cpp.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/ifaddrs_patch.cpp.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linker_topo.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_mpi.cpp.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_socket.cpp.o\u001b[0m\n",
            "[ 79%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/network.cpp.o\u001b[0m\n",
            "[ 81%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/tree_learner.cpp.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 84%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/objective/objective_function.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/cuda_tree_learner.cpp.o\u001b[0m\n",
            "[ 86%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 89%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/linear_tree_learner.cpp.o\u001b[0m\n",
            "[ 92%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\u001b[0m\n",
            "[ 94%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/tree_learner.cpp.o\u001b[0m\n",
            "[ 95%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 97%] \u001b[32m\u001b[1mLinking CXX executable ../lightgbm\u001b[0m\n",
            "[ 97%] Built target lightgbm\n",
            "[ 98%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/c_api.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX shared library ../lib_lightgbm.so\u001b[0m\n",
            "[100%] Built target _lightgbm\n",
            "running install\n",
            "running build\n",
            "running build_py\n",
            "INFO:root:Generating grammar tables from /usr/lib/python3.7/lib2to3/Grammar.txt\n",
            "INFO:root:Generating grammar tables from /usr/lib/python3.7/lib2to3/PatternGrammar.txt\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/lightgbm\n",
            "copying lightgbm/plotting.py -> build/lib/lightgbm\n",
            "copying lightgbm/callback.py -> build/lib/lightgbm\n",
            "copying lightgbm/libpath.py -> build/lib/lightgbm\n",
            "copying lightgbm/sklearn.py -> build/lib/lightgbm\n",
            "copying lightgbm/dask.py -> build/lib/lightgbm\n",
            "copying lightgbm/engine.py -> build/lib/lightgbm\n",
            "copying lightgbm/__init__.py -> build/lib/lightgbm\n",
            "copying lightgbm/basic.py -> build/lib/lightgbm\n",
            "copying lightgbm/compat.py -> build/lib/lightgbm\n",
            "running egg_info\n",
            "creating lightgbm.egg-info\n",
            "writing lightgbm.egg-info/PKG-INFO\n",
            "writing dependency_links to lightgbm.egg-info/dependency_links.txt\n",
            "writing requirements to lightgbm.egg-info/requires.txt\n",
            "writing top-level names to lightgbm.egg-info/top_level.txt\n",
            "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "no previously-included directories found matching 'build'\n",
            "warning: no files found matching 'LICENSE'\n",
            "warning: no files found matching '*.txt'\n",
            "warning: no files found matching '*.so' under directory 'lightgbm'\n",
            "warning: no files found matching 'compile/CMakeLists.txt'\n",
            "warning: no files found matching 'compile/cmake/IntegratedOpenCL.cmake'\n",
            "warning: no files found matching '*.so' under directory 'compile'\n",
            "warning: no files found matching '*.dll' under directory 'compile/Release'\n",
            "warning: no files found matching 'compile/external_libs/compute/CMakeLists.txt'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/compute/cmake'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/compute/include'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/compute/meta'\n",
            "warning: no files found matching 'compile/external_libs/eigen/CMakeLists.txt'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Cholesky'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Core'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Dense'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Eigenvalues'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Geometry'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Householder'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Jacobi'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/LU'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/QR'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/SVD'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Cholesky'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Core'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Eigenvalues'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Geometry'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Householder'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Jacobi'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/LU'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/misc'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/plugins'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/QR'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/SVD'\n",
            "warning: no files found matching 'compile/external_libs/fast_double_parser/CMakeLists.txt'\n",
            "warning: no files found matching 'compile/external_libs/fast_double_parser/LICENSE'\n",
            "warning: no files found matching 'compile/external_libs/fast_double_parser/LICENSE.BSL'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/fast_double_parser/include'\n",
            "warning: no files found matching 'compile/external_libs/fmt/CMakeLists.txt'\n",
            "warning: no files found matching 'compile/external_libs/fmt/LICENSE.rst'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/fmt/include'\n",
            "warning: no files found matching '*' under directory 'compile/include'\n",
            "warning: no files found matching '*' under directory 'compile/src'\n",
            "warning: no files found matching 'LightGBM.sln' under directory 'compile/windows'\n",
            "warning: no files found matching 'LightGBM.vcxproj' under directory 'compile/windows'\n",
            "warning: no files found matching '*.dll' under directory 'compile/windows/x64/DLL'\n",
            "warning: no previously-included files matching '*.py[co]' found anywhere in distribution\n",
            "warning: no previously-included files found matching 'compile/external_libs/compute/.git'\n",
            "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
            "copying lightgbm/VERSION.txt -> build/lib/lightgbm\n",
            "running install_lib\n",
            "copying build/lib/lightgbm/plotting.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/callback.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/libpath.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/sklearn.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/dask.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/engine.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/__init__.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/VERSION.txt -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/basic.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/compat.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "INFO:LightGBM:Installing lib_lightgbm from: ['../lib_lightgbm.so']\n",
            "copying ../lib_lightgbm.so -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/plotting.py to plotting.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/callback.py to callback.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/libpath.py to libpath.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py to sklearn.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/dask.py to dask.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/engine.py to engine.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/basic.py to basic.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/compat.py to compat.cpython-37.pyc\n",
            "running install_egg_info\n",
            "Copying lightgbm.egg-info to /usr/local/lib/python3.7/dist-packages/lightgbm-3.2.1.99-py3.7.egg-info\n",
            "running install_scripts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XohP1V5wvDO"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yr4iQ1JFwlVk",
        "outputId": "1f024603-c54b-4395-fd4a-13aba87bf617"
      },
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import OrdinalEncoder,OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score,roc_auc_score, log_loss\n",
        "from sklearn.model_selection import StratifiedKFold, KFold,cross_val_predict,cross_val_score,cross_validate\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import optuna\n",
        "import lightgbm as lgbm\n",
        "import xgboost as xgb\n",
        "import pickle\n",
        "from google.colab import files\n",
        "import category_encoders as ce\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "from sklearn.feature_selection import SelectKBest, f_classif,chi2,SelectPercentile\n",
        "from scipy.stats import rankdata\n",
        "from sklearn.mixture import GaussianMixture \n",
        "from scipy.sparse import hstack\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.calibration import calibration_curve\n",
        "\n",
        "import string\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning:\n",
            "\n",
            "pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmRJTanLwzGV"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "KIZ7Deekww2W",
        "outputId": "de5f1d4a-f641-4de0-b494-c8ff4216d8e6"
      },
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# get a list of kaggle competitions\n",
        "#!kaggle competitions list\n",
        "\n",
        "# download the target competition\n",
        "!kaggle competitions download 'tabular-playground-series-may-2021'\n",
        "\n",
        "# unzip the files if needed\n",
        "## !unzip tabular-playground-series-jan-2021.zip\n",
        "\n",
        "# load the data\n",
        "df_all = pd.read_csv(\"train.csv.zip\")\n",
        "df_test = pd.read_csv(\"test.csv.zip\")\n",
        "df_submission = pd.read_csv(\"sample_submission.csv.zip\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-77492a7f-f2f6-4b96-b4f4-b065fd699014\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-77492a7f-f2f6-4b96-b4f4-b065fd699014\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 64 bytes\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading train.csv.zip to /content\n",
            "  0% 0.00/1.72M [00:00<?, ?B/s]\n",
            "100% 1.72M/1.72M [00:00<00:00, 56.6MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            "  0% 0.00/851k [00:00<?, ?B/s]\n",
            "100% 851k/851k [00:00<00:00, 118MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/128k [00:00<?, ?B/s]\n",
            "100% 128k/128k [00:00<00:00, 132MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeqVL_BkyLDl"
      },
      "source": [
        "# Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ncq_DNFyMHO",
        "outputId": "3c6ae8bc-b1df-4730-a3cf-08bc14593ceb"
      },
      "source": [
        "df_all.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 52 columns):\n",
            " #   Column      Non-Null Count   Dtype \n",
            "---  ------      --------------   ----- \n",
            " 0   id          100000 non-null  int64 \n",
            " 1   feature_0   100000 non-null  int64 \n",
            " 2   feature_1   100000 non-null  int64 \n",
            " 3   feature_2   100000 non-null  int64 \n",
            " 4   feature_3   100000 non-null  int64 \n",
            " 5   feature_4   100000 non-null  int64 \n",
            " 6   feature_5   100000 non-null  int64 \n",
            " 7   feature_6   100000 non-null  int64 \n",
            " 8   feature_7   100000 non-null  int64 \n",
            " 9   feature_8   100000 non-null  int64 \n",
            " 10  feature_9   100000 non-null  int64 \n",
            " 11  feature_10  100000 non-null  int64 \n",
            " 12  feature_11  100000 non-null  int64 \n",
            " 13  feature_12  100000 non-null  int64 \n",
            " 14  feature_13  100000 non-null  int64 \n",
            " 15  feature_14  100000 non-null  int64 \n",
            " 16  feature_15  100000 non-null  int64 \n",
            " 17  feature_16  100000 non-null  int64 \n",
            " 18  feature_17  100000 non-null  int64 \n",
            " 19  feature_18  100000 non-null  int64 \n",
            " 20  feature_19  100000 non-null  int64 \n",
            " 21  feature_20  100000 non-null  int64 \n",
            " 22  feature_21  100000 non-null  int64 \n",
            " 23  feature_22  100000 non-null  int64 \n",
            " 24  feature_23  100000 non-null  int64 \n",
            " 25  feature_24  100000 non-null  int64 \n",
            " 26  feature_25  100000 non-null  int64 \n",
            " 27  feature_26  100000 non-null  int64 \n",
            " 28  feature_27  100000 non-null  int64 \n",
            " 29  feature_28  100000 non-null  int64 \n",
            " 30  feature_29  100000 non-null  int64 \n",
            " 31  feature_30  100000 non-null  int64 \n",
            " 32  feature_31  100000 non-null  int64 \n",
            " 33  feature_32  100000 non-null  int64 \n",
            " 34  feature_33  100000 non-null  int64 \n",
            " 35  feature_34  100000 non-null  int64 \n",
            " 36  feature_35  100000 non-null  int64 \n",
            " 37  feature_36  100000 non-null  int64 \n",
            " 38  feature_37  100000 non-null  int64 \n",
            " 39  feature_38  100000 non-null  int64 \n",
            " 40  feature_39  100000 non-null  int64 \n",
            " 41  feature_40  100000 non-null  int64 \n",
            " 42  feature_41  100000 non-null  int64 \n",
            " 43  feature_42  100000 non-null  int64 \n",
            " 44  feature_43  100000 non-null  int64 \n",
            " 45  feature_44  100000 non-null  int64 \n",
            " 46  feature_45  100000 non-null  int64 \n",
            " 47  feature_46  100000 non-null  int64 \n",
            " 48  feature_47  100000 non-null  int64 \n",
            " 49  feature_48  100000 non-null  int64 \n",
            " 50  feature_49  100000 non-null  int64 \n",
            " 51  target      100000 non-null  object\n",
            "dtypes: int64(51), object(1)\n",
            "memory usage: 39.7+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwxrWjEtyNUW",
        "outputId": "a104ef93-0417-4fd3-c1f7-e56605a914f3"
      },
      "source": [
        "df_test.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 51 columns):\n",
            " #   Column      Non-Null Count  Dtype\n",
            "---  ------      --------------  -----\n",
            " 0   id          50000 non-null  int64\n",
            " 1   feature_0   50000 non-null  int64\n",
            " 2   feature_1   50000 non-null  int64\n",
            " 3   feature_2   50000 non-null  int64\n",
            " 4   feature_3   50000 non-null  int64\n",
            " 5   feature_4   50000 non-null  int64\n",
            " 6   feature_5   50000 non-null  int64\n",
            " 7   feature_6   50000 non-null  int64\n",
            " 8   feature_7   50000 non-null  int64\n",
            " 9   feature_8   50000 non-null  int64\n",
            " 10  feature_9   50000 non-null  int64\n",
            " 11  feature_10  50000 non-null  int64\n",
            " 12  feature_11  50000 non-null  int64\n",
            " 13  feature_12  50000 non-null  int64\n",
            " 14  feature_13  50000 non-null  int64\n",
            " 15  feature_14  50000 non-null  int64\n",
            " 16  feature_15  50000 non-null  int64\n",
            " 17  feature_16  50000 non-null  int64\n",
            " 18  feature_17  50000 non-null  int64\n",
            " 19  feature_18  50000 non-null  int64\n",
            " 20  feature_19  50000 non-null  int64\n",
            " 21  feature_20  50000 non-null  int64\n",
            " 22  feature_21  50000 non-null  int64\n",
            " 23  feature_22  50000 non-null  int64\n",
            " 24  feature_23  50000 non-null  int64\n",
            " 25  feature_24  50000 non-null  int64\n",
            " 26  feature_25  50000 non-null  int64\n",
            " 27  feature_26  50000 non-null  int64\n",
            " 28  feature_27  50000 non-null  int64\n",
            " 29  feature_28  50000 non-null  int64\n",
            " 30  feature_29  50000 non-null  int64\n",
            " 31  feature_30  50000 non-null  int64\n",
            " 32  feature_31  50000 non-null  int64\n",
            " 33  feature_32  50000 non-null  int64\n",
            " 34  feature_33  50000 non-null  int64\n",
            " 35  feature_34  50000 non-null  int64\n",
            " 36  feature_35  50000 non-null  int64\n",
            " 37  feature_36  50000 non-null  int64\n",
            " 38  feature_37  50000 non-null  int64\n",
            " 39  feature_38  50000 non-null  int64\n",
            " 40  feature_39  50000 non-null  int64\n",
            " 41  feature_40  50000 non-null  int64\n",
            " 42  feature_41  50000 non-null  int64\n",
            " 43  feature_42  50000 non-null  int64\n",
            " 44  feature_43  50000 non-null  int64\n",
            " 45  feature_44  50000 non-null  int64\n",
            " 46  feature_45  50000 non-null  int64\n",
            " 47  feature_46  50000 non-null  int64\n",
            " 48  feature_47  50000 non-null  int64\n",
            " 49  feature_48  50000 non-null  int64\n",
            " 50  feature_49  50000 non-null  int64\n",
            "dtypes: int64(51)\n",
            "memory usage: 19.5 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc5fvoCfzROs",
        "outputId": "54c6b2f7-3b3d-4f79-bec9-5c39d29ae508"
      },
      "source": [
        "df_all['target']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        Class_2\n",
              "1        Class_1\n",
              "2        Class_1\n",
              "3        Class_4\n",
              "4        Class_2\n",
              "          ...   \n",
              "99995    Class_1\n",
              "99996    Class_2\n",
              "99997    Class_3\n",
              "99998    Class_2\n",
              "99999    Class_3\n",
              "Name: target, Length: 100000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcjp4k8uzlWu",
        "outputId": "23907d98-3825-4b5e-f252-421979aa9f04"
      },
      "source": [
        "df_all['target'].value_counts()/len(df_all)*100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Class_2    57.497\n",
              "Class_3    21.420\n",
              "Class_4    12.593\n",
              "Class_1     8.490\n",
              "Name: target, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um4ESDzxzn0-",
        "outputId": "e66d4d1b-6503-4183-8301-a3f87c368624"
      },
      "source": [
        "for col in list(df_all.columns):\n",
        "  if col.startswith(\"f\"):\n",
        "    print(f\"col: {col},nunique:{df_all[col].nunique()},min:{df_all[col].min()},max: {df_all[col].max()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "col: feature_0,nunique:11,min:0,max: 10\n",
            "col: feature_1,nunique:31,min:0,max: 31\n",
            "col: feature_2,nunique:7,min:0,max: 6\n",
            "col: feature_3,nunique:26,min:0,max: 26\n",
            "col: feature_4,nunique:38,min:0,max: 38\n",
            "col: feature_5,nunique:11,min:0,max: 10\n",
            "col: feature_6,nunique:28,min:0,max: 27\n",
            "col: feature_7,nunique:32,min:0,max: 31\n",
            "col: feature_8,nunique:37,min:0,max: 39\n",
            "col: feature_9,nunique:18,min:0,max: 17\n",
            "col: feature_10,nunique:17,min:0,max: 16\n",
            "col: feature_11,nunique:13,min:0,max: 12\n",
            "col: feature_12,nunique:12,min:0,max: 11\n",
            "col: feature_13,nunique:4,min:0,max: 3\n",
            "col: feature_14,nunique:52,min:0,max: 51\n",
            "col: feature_15,nunique:21,min:0,max: 20\n",
            "col: feature_16,nunique:20,min:0,max: 19\n",
            "col: feature_17,nunique:17,min:0,max: 16\n",
            "col: feature_18,nunique:14,min:0,max: 13\n",
            "col: feature_19,nunique:58,min:-2,max: 55\n",
            "col: feature_20,nunique:18,min:0,max: 17\n",
            "col: feature_21,nunique:36,min:0,max: 36\n",
            "col: feature_22,nunique:5,min:0,max: 4\n",
            "col: feature_23,nunique:20,min:0,max: 19\n",
            "col: feature_24,nunique:35,min:0,max: 34\n",
            "col: feature_25,nunique:23,min:0,max: 23\n",
            "col: feature_26,nunique:22,min:0,max: 21\n",
            "col: feature_27,nunique:32,min:0,max: 31\n",
            "col: feature_28,nunique:24,min:0,max: 23\n",
            "col: feature_29,nunique:14,min:0,max: 13\n",
            "col: feature_30,nunique:43,min:-1,max: 41\n",
            "col: feature_31,nunique:46,min:-1,max: 46\n",
            "col: feature_32,nunique:30,min:-2,max: 27\n",
            "col: feature_33,nunique:25,min:0,max: 24\n",
            "col: feature_34,nunique:26,min:0,max: 25\n",
            "col: feature_35,nunique:44,min:-2,max: 43\n",
            "col: feature_36,nunique:4,min:0,max: 3\n",
            "col: feature_37,nunique:15,min:0,max: 14\n",
            "col: feature_38,nunique:71,min:-8,max: 66\n",
            "col: feature_39,nunique:70,min:-5,max: 66\n",
            "col: feature_40,nunique:22,min:0,max: 21\n",
            "col: feature_41,nunique:31,min:0,max: 32\n",
            "col: feature_42,nunique:40,min:-2,max: 37\n",
            "col: feature_43,nunique:33,min:0,max: 33\n",
            "col: feature_44,nunique:10,min:0,max: 9\n",
            "col: feature_45,nunique:27,min:0,max: 26\n",
            "col: feature_46,nunique:30,min:0,max: 29\n",
            "col: feature_47,nunique:26,min:0,max: 25\n",
            "col: feature_48,nunique:45,min:0,max: 44\n",
            "col: feature_49,nunique:21,min:0,max: 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqQhNwXv15lf"
      },
      "source": [
        "# Logistic Regression\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TCNliSm3kXJ"
      },
      "source": [
        "X = df_all.drop(labels=['id','target'],axis=1,inplace=False).copy()\n",
        "y = df_all['target'].values\n",
        "X_test = df_test.drop(labels=['id'],axis=1,inplace=False).copy()\n",
        "random_seed = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gBRJppoznSS"
      },
      "source": [
        "encoder = OneHotEncoder()\n",
        "all_encoded = encoder.fit_transform(X.append(X_test))\n",
        "#X = all_encoded[0:len(X)]\n",
        "#X_test = all_encoded[len(X):]\n",
        "X = all_encoded.tocsr()[0:len(X)]\n",
        "X_test = all_encoded [len(df_all):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rByxT0Tsr2nt",
        "outputId": "67d53b71-263a-45c9-bcd1-c0f71b9c463d"
      },
      "source": [
        "df_all['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Class_2    57497\n",
              "Class_3    21420\n",
              "Class_4    12593\n",
              "Class_1     8490\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWy1TZ-Q0E8K"
      },
      "source": [
        "params = {\n",
        "          'penalty':'l2',\n",
        "          'multi_class':'ovr',\n",
        "          'solver':'lbfgs',  \n",
        "          'C':0.01,\n",
        "          'max_iter':10000 ,\n",
        "          'class_weight':None        \n",
        "          }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "9TTAwAMapw0k",
        "outputId": "8089d442-526b-4e9f-85f3-3224aff3291e"
      },
      "source": [
        "name = 'logistic_regression'\n",
        "k=5\n",
        "seed_list=[0,1,2]\n",
        "kf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\n",
        "oof = np.zeros((len(df_all),4))\n",
        "test_preds_list = []\n",
        "score_list = []\n",
        "fold=1\n",
        "  \n",
        "splits = list(kf.split(X,y))\n",
        "fold = 1\n",
        "for train_idx, val_idx in splits:\n",
        "  X_train, X_val = X[train_idx], X[val_idx]\n",
        "  y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "  val_preds_list = []\n",
        "\n",
        "  for seed in seed_list:\n",
        "    \n",
        "    # fit and run model\n",
        "    \n",
        "    base_model = LogisticRegression(**params,random_state=seed)\n",
        "    model = CalibratedClassifierCV(base_model, method='sigmoid', cv=k)\n",
        "\n",
        "\n",
        "    model.fit(X_train,y=y_train)\n",
        "\n",
        "    \n",
        "    val_preds_list.append(model.predict_proba(X_val))\n",
        "    test_preds_list.append(model.predict_proba(X_test))\n",
        "    \n",
        "  oof[val_idx] = np.mean(val_preds_list,axis=0)\n",
        "  score = log_loss(y_val, oof[val_idx])\n",
        "  print(f\"fold: {fold},log_loss: {score}\")\n",
        "  score_list.append(score)\n",
        "  # print(f\"fold: {fold}, class0 tr %: {y_train.value_counts()[0]/len(y_train)}, class0 val %: {y_val.value_counts()[0]/len(y_val)} \")\n",
        "  fold +=1\n",
        "  \n",
        "cv_logloss = np.mean(score_list)\n",
        "print(f\"{name} ,log_loss: {cv_logloss}\")\n",
        "\n",
        "preds= np.mean(test_preds_list,axis=0)\n",
        "\n",
        "\n",
        "file_name_oof = \"logistic_3seeds_oof.txt\"\n",
        "file_name_test = \"logistic_3seeds_test.csv\"\n",
        "with open(file_name_oof, \"wb\") as fp:\n",
        "      pickle.dump(oof, fp)\n",
        "\n",
        "files.download(file_name_oof)\n",
        "\n",
        "df_submission[['Class_1','Class_2','Class_3','Class_4']] = preds\n",
        "df_submission.to_csv(file_name_test,index=None)\n",
        "files.download(file_name_test) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold: 1,log_loss: 1.0896463404941772\n",
            "fold: 2,log_loss: 1.0942270580398394\n",
            "fold: 3,log_loss: 1.0891577719590186\n",
            "fold: 4,log_loss: 1.0909161253698327\n",
            "fold: 5,log_loss: 1.0913208228386768\n",
            "logistic_regression ,log_loss: 1.091053623740309\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_6eeb37c4-ada6-4ae1-a13c-3fea742fde34\", \"logistic_3seeds_oof.txt\", 3200161)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_9cf94d32-f782-46d3-92c6-12b783e76b6b\", \"logistic_3seeds_test.csv\", 4260799)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiYFO4NY6C_0"
      },
      "source": [
        "# Logistic Regression Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPD7WSZs6F95"
      },
      "source": [
        "X = df_all.drop(labels=['id','target'],axis=1,inplace=False).copy()\n",
        "y = df_all['target'].values\n",
        "X_test = df_test.drop(labels=['id'],axis=1,inplace=False).copy()\n",
        "random_seed = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0n8WXd26Ilu"
      },
      "source": [
        "encoder = OneHotEncoder()\n",
        "all_encoded = encoder.fit_transform(X.append(X_test))\n",
        "#X = all_encoded[0:len(X)]\n",
        "#X_test = all_encoded[len(X):]\n",
        "X = all_encoded.tocsr()[0:len(X)]\n",
        "X_test = all_encoded [len(df_all):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1siAGX96L3y"
      },
      "source": [
        "# for the fixed learning rate, use the opt n iterations and tune the tree hyperparameters\n",
        "def objective(trial,data=X,target=y):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  param_space = {\n",
        "          'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
        "          'penalty':'l2',\n",
        "          'solver': trial.suggest_categorical('solver',['newton-cg', 'lbfgs', 'sag', 'saga']),\n",
        "          'multi_class':trial.suggest_categorical('multi_class',['ovr','multinomial']),\n",
        "          'max_iter':10000,\n",
        "          'class_weight':trial.suggest_categorical('class_weight',['balanced',None])  ,\n",
        "           'n_jobs':-1\n",
        "                }\n",
        "            \n",
        "  #X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=.1,random_state=2021,stratify=y)\n",
        "  k=5\n",
        "  seed_list=[0]\n",
        "  kf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\n",
        "  oof = np.zeros((len(df_all),4))\n",
        "  score_list = []\n",
        "  fold=1\n",
        "  \n",
        "  splits = list(kf.split(X,y))\n",
        "  for train_idx, val_idx in splits:\n",
        "    X_train, X_val = X[train_idx,:], X[val_idx,:]\n",
        "    y_train, y_val = y[train_idx], y[val_idx]\n",
        "  \n",
        "    val_preds_list = []\n",
        "  \n",
        "    for seed in seed_list:\n",
        "      # fit and run model\n",
        "      param_space['random_state'] = seed\n",
        "\n",
        "      model = LogisticRegression(**param_space)\n",
        "      #model = CalibratedClassifierCV(base_model, method='sigmoid', cv=k)\n",
        "      model.fit(X_train,y=y_train)\n",
        "\n",
        "    \n",
        "      val_preds_list.append(model.predict_proba(X_val))\n",
        "     #test_preds_list.append(model.predict_proba(X_test)[:,1])\n",
        "    \n",
        "    oof[val_idx] = np.mean(val_preds_list,axis=0)\n",
        "    score = log_loss(y_val, oof[val_idx])\n",
        "    print(f\"fold: {fold},logloss: {score}\")\n",
        "    score_list.append(score)\n",
        "    fold +=1\n",
        "  \n",
        "  cv_logloss = np.mean(score_list)\n",
        "  \n",
        "  return cv_logloss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sGG7tA8087C5",
        "outputId": "c77a5dc3-34a7-4782-9a20-246d4e62c1f5"
      },
      "source": [
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective,n_trials= 30)\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:', study.best_trial.params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-23 21:34:19,970]\u001b[0m A new study created in memory with name: no-name-e54f9865-05d6-4133-b5ea-f97b94246e0c\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.3764405615079547\n",
            "fold: 2,logloss: 1.3834771132244839\n",
            "fold: 3,logloss: 1.368472549230804\n",
            "fold: 4,logloss: 1.3779910953879444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-23 21:50:43,588]\u001b[0m Trial 0 finished with value: 1.3767282841741353 and parameters: {'C': 25.59567454799754, 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'balanced'}. Best is trial 0 with value: 1.3767282841741353.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 5,logloss: 1.37726010151949\n",
            "fold: 1,logloss: 1.0900952690611299\n",
            "fold: 2,logloss: 1.0948244337170032\n",
            "fold: 3,logloss: 1.0893037142024011\n",
            "fold: 4,logloss: 1.0911801388813611\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-23 21:51:08,441]\u001b[0m Trial 1 finished with value: 1.0914300977030766 and parameters: {'C': 0.011306868379481878, 'solver': 'lbfgs', 'multi_class': 'ovr', 'class_weight': None}. Best is trial 1 with value: 1.0914300977030766.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 5,logloss: 1.0917469326534879\n",
            "fold: 1,logloss: 1.3585600445617116\n",
            "fold: 2,logloss: 1.360367794521934\n",
            "fold: 3,logloss: 1.3590950520755476\n",
            "fold: 4,logloss: 1.3590496389703264\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-23 21:51:59,896]\u001b[0m Trial 2 finished with value: 1.359296016240332 and parameters: {'C': 0.0011601245555505422, 'solver': 'sag', 'multi_class': 'ovr', 'class_weight': 'balanced'}. Best is trial 1 with value: 1.0914300977030766.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 5,logloss: 1.3594075510721408\n",
            "fold: 1,logloss: 1.117450939030146\n",
            "fold: 2,logloss: 1.1246899524455831\n",
            "fold: 3,logloss: 1.1105893937759883\n",
            "fold: 4,logloss: 1.1190206492093495\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-23 22:09:46,663]\u001b[0m Trial 3 finished with value: 1.1178212896529782 and parameters: {'C': 70.4746329417603, 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': None}. Best is trial 1 with value: 1.0914300977030766.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 5,logloss: 1.1173555138038245\n",
            "fold: 1,logloss: 1.353413576429374\n",
            "fold: 2,logloss: 1.35793889494657\n",
            "fold: 3,logloss: 1.3533390437286332\n",
            "fold: 4,logloss: 1.3548351910443481\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-23 22:18:48,191]\u001b[0m Trial 4 finished with value: 1.3549259519169254 and parameters: {'C': 0.005769650714001403, 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'balanced'}. Best is trial 1 with value: 1.0914300977030766.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 5,logloss: 1.3551030534357023\n",
            "fold: 1,logloss: 1.3502231290723012\n",
            "fold: 2,logloss: 1.3532840598910092\n",
            "fold: 3,logloss: 1.3498243592864143\n",
            "fold: 4,logloss: 1.351104003195148\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-23 22:19:26,663]\u001b[0m Trial 5 finished with value: 1.3512587421478046 and parameters: {'C': 0.028666703876421454, 'solver': 'newton-cg', 'multi_class': 'ovr', 'class_weight': 'balanced'}. Best is trial 1 with value: 1.0914300977030766.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 5,logloss: 1.3518581592941503\n",
            "fold: 1,logloss: 1.3792497069330918\n",
            "fold: 2,logloss: 1.3871583635506648\n",
            "fold: 3,logloss: 1.3712495107058411\n",
            "fold: 4,logloss: 1.3810230821585758\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-27845a7a65c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'minimize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of finished trials:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best trial:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-c19ec9fa0542>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial, data, target)\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparam_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0;31m#model = CalibratedClassifierCV(base_model, method='sigmoid', cv=k)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1414\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1416\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnO3pIv99jpO"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M7nloIj3nQ4"
      },
      "source": [
        "X = df_all.drop(labels=['id','target'],axis=1,inplace=False).copy()\n",
        "y = df_all['target'].values\n",
        "X_test = df_test.drop(labels=['id'],axis=1,inplace=False).copy()\n",
        "random_seed = 0\n",
        "\n",
        "encoder = OrdinalEncoder()\n",
        "all_encoded = encoder.fit_transform(X.append(X_test))\n",
        "X = all_encoded[0:len(X)]\n",
        "X_test = all_encoded[len(X):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lIF-goM9tcP"
      },
      "source": [
        "params = {\n",
        "          'bootstrap':True,\n",
        "          'max_depth':30,\n",
        "          'max_features':'auto'  ,\n",
        "          'min_samples_leaf' :10,\n",
        "          'min_samples_split':5,\n",
        "          'n_estimators':1560\n",
        "          }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19XfhNlr9zfu",
        "outputId": "6fb7f55a-4a81-4a3a-f0b6-e04d760b3dbf"
      },
      "source": [
        "name = 'random_forest'\n",
        "k=5\n",
        "seed_list=[0,1,2]\n",
        "kf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\n",
        "oof = np.zeros((len(df_all),4))\n",
        "test_preds_list = []\n",
        "score_list = []\n",
        "fold=1\n",
        "  \n",
        "splits = list(kf.split(X,y))\n",
        "fold = 1\n",
        "for train_idx, val_idx in splits:\n",
        "  X_train, X_val = X[train_idx], X[val_idx]\n",
        "  y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "  val_preds_list = []\n",
        "\n",
        "  for seed in seed_list:\n",
        "    \n",
        "    # fit and run model\n",
        "    \n",
        "    base_model = RandomForestClassifier(**params,random_state=seed)\n",
        "    model = CalibratedClassifierCV(base_model, method='sigmoid', cv=k)\n",
        "\n",
        "    model.fit(X_train,y=y_train)\n",
        "\n",
        "    \n",
        "    val_preds_list.append(model.predict_proba(X_val))\n",
        "    test_preds_list.append(model.predict_proba(X_test))\n",
        "    \n",
        "  oof[val_idx] = np.mean(val_preds_list,axis=0)\n",
        "  score = log_loss(y_val, oof[val_idx])\n",
        "  print(f\"fold: {fold},log_loss: {score}\")\n",
        "  score_list.append(score)\n",
        "  # print(f\"fold: {fold}, class0 tr %: {y_train.value_counts()[0]/len(y_train)}, class0 val %: {y_val.value_counts()[0]/len(y_val)} \")\n",
        "  fold +=1\n",
        "  \n",
        "cv_logloss = np.mean(score_list)\n",
        "print(f\"{name} ,log_loss: {cv_logloss}\")\n",
        "\n",
        "preds= np.mean(test_preds_list,axis=0)\n",
        "\n",
        "\n",
        "file_name_oof = \"rfc_3seeds_oof.txt\"\n",
        "file_name_test = \"rfc_3seeds_test.csv\"\n",
        "with open(file_name_oof, \"wb\") as fp:\n",
        "      pickle.dump(oof, fp)\n",
        "\n",
        "#files.download(file_name_oof)\n",
        "\n",
        "df_submission[['Class_1','Class_2','Class_3','Class_4']] = preds\n",
        "df_submission.to_csv(file_name_test,index=None)\n",
        "#files.download(file_name_test) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold: 1,log_loss: 1.096954666028222\n",
            "fold: 2,log_loss: 1.099633708005841\n",
            "fold: 3,log_loss: 1.0972724875462816\n",
            "fold: 4,log_loss: 1.0970865994352583\n",
            "fold: 5,log_loss: 1.0974270829667088\n",
            "random_forest ,log_loss: 1.0976749087964623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylFx55xNG10O"
      },
      "source": [
        "# Random Forest Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCZ79oVkG_nr"
      },
      "source": [
        "X = df_all.drop(labels=['id','target'],axis=1,inplace=False).copy()\n",
        "y = df_all['target'].values\n",
        "X_test = df_test.drop(labels=['id'],axis=1,inplace=False).copy()\n",
        "random_seed = 0\n",
        "\n",
        "encoder = OrdinalEncoder()\n",
        "all_encoded = encoder.fit_transform(X.append(X_test))\n",
        "X = all_encoded[0:len(X)]\n",
        "X_test = all_encoded[len(X):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwWpUJyx9-GD"
      },
      "source": [
        "# for the fixed learning rate, use the opt n iterations and tune the tree hyperparameters\n",
        "def objective(trial,data=X,target=y):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  param_space = {\n",
        "               'max_depth': trial.suggest_int('max_depth', 2, 30),\n",
        "               'n_estimators': trial.suggest_int('n_estimators', 200,2000,10),\n",
        "               'max_features': trial.suggest_categorical('max_features',['auto','sqrt']),\n",
        "               'min_samples_split':trial.suggest_categorical('min_samples_split',[2,5,10]),\n",
        "               'bootstrap' : trial.suggest_categorical('bootstrap',[True,False]),\n",
        "               'min_samples_leaf':trial.suggest_categorical('min_samples_leaf',[2,5,10])\n",
        "\n",
        "                }\n",
        "            \n",
        "  model = RandomForestClassifier(**param_space,random_state=random_seed,n_jobs=-1)\n",
        "  kf = StratifiedKFold(n_splits=5,shuffle=True,random_state=random_seed)\n",
        "  scores = cross_val_score(model,X,y,scoring='neg_log_loss',cv=kf)\n",
        "  cv_score = -1*scores.mean()\n",
        "      \n",
        "  return cv_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heh25kuaJh3j",
        "outputId": "3aba032e-5c41-4c38-cb9b-f8d44369f986"
      },
      "source": [
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective,n_trials= 25)\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:', study.best_trial.params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-20 19:06:59,333]\u001b[0m A new study created in memory with name: no-name-428bead7-59a4-4895-934b-a0f3a7f79456\u001b[0m\n",
            "\u001b[32m[I 2021-05-20 19:14:07,483]\u001b[0m Trial 0 finished with value: 1.1037324397093398 and parameters: {'max_depth': 30, 'n_estimators': 990, 'max_features': 'sqrt', 'min_samples_split': 10, 'bootstrap': False, 'min_samples_leaf': 2}. Best is trial 0 with value: 1.1037324397093398.\u001b[0m\n",
            "\u001b[32m[I 2021-05-20 19:22:15,105]\u001b[0m Trial 1 finished with value: 1.1011955293418823 and parameters: {'max_depth': 24, 'n_estimators': 1890, 'max_features': 'auto', 'min_samples_split': 5, 'bootstrap': True, 'min_samples_leaf': 5}. Best is trial 1 with value: 1.1011955293418823.\u001b[0m\n",
            "\u001b[32m[I 2021-05-20 19:25:17,256]\u001b[0m Trial 2 finished with value: 1.1041724861895943 and parameters: {'max_depth': 30, 'n_estimators': 420, 'max_features': 'auto', 'min_samples_split': 10, 'bootstrap': False, 'min_samples_leaf': 2}. Best is trial 1 with value: 1.1011955293418823.\u001b[0m\n",
            "\u001b[32m[I 2021-05-20 19:26:51,829]\u001b[0m Trial 3 finished with value: 1.114695508750384 and parameters: {'max_depth': 2, 'n_estimators': 1920, 'max_features': 'auto', 'min_samples_split': 10, 'bootstrap': True, 'min_samples_leaf': 5}. Best is trial 1 with value: 1.1011955293418823.\u001b[0m\n",
            "\u001b[32m[I 2021-05-20 19:28:48,524]\u001b[0m Trial 4 finished with value: 1.1084374939464248 and parameters: {'max_depth': 7, 'n_estimators': 1040, 'max_features': 'sqrt', 'min_samples_split': 10, 'bootstrap': True, 'min_samples_leaf': 5}. Best is trial 1 with value: 1.1011955293418823.\u001b[0m\n",
            "\u001b[32m[I 2021-05-20 19:31:41,648]\u001b[0m Trial 5 finished with value: 1.1025422696650826 and parameters: {'max_depth': 22, 'n_estimators': 650, 'max_features': 'sqrt', 'min_samples_split': 2, 'bootstrap': True, 'min_samples_leaf': 2}. Best is trial 1 with value: 1.1011955293418823.\u001b[0m\n",
            "\u001b[32m[I 2021-05-20 19:38:40,074]\u001b[0m Trial 6 finished with value: 1.1005636307726856 and parameters: {'max_depth': 27, 'n_estimators': 1660, 'max_features': 'auto', 'min_samples_split': 10, 'bootstrap': True, 'min_samples_leaf': 10}. Best is trial 6 with value: 1.1005636307726856.\u001b[0m\n",
            "\u001b[32m[I 2021-05-20 19:40:24,512]\u001b[0m Trial 7 finished with value: 1.113155752307214 and parameters: {'max_depth': 3, 'n_estimators': 1690, 'max_features': 'auto', 'min_samples_split': 5, 'bootstrap': True, 'min_samples_leaf': 10}. Best is trial 6 with value: 1.1005636307726856.\u001b[0m\n",
            "\u001b[32m[I 2021-05-20 19:42:18,025]\u001b[0m Trial 8 finished with value: 1.1059637362402643 and parameters: {'max_depth': 10, 'n_estimators': 770, 'max_features': 'sqrt', 'min_samples_split': 10, 'bootstrap': True, 'min_samples_leaf': 2}. Best is trial 6 with value: 1.1005636307726856.\u001b[0m\n",
            "\u001b[32m[I 2021-05-20 19:44:07,746]\u001b[0m Trial 9 finished with value: 1.10327026862017 and parameters: {'max_depth': 24, 'n_estimators': 280, 'max_features': 'auto', 'min_samples_split': 10, 'bootstrap': False, 'min_samples_leaf': 2}. Best is trial 6 with value: 1.1005636307726856.\u001b[0m\n",
            "\u001b[32m[I 2021-05-20 19:48:59,557]\u001b[0m Trial 10 finished with value: 1.1024106276567873 and parameters: {'max_depth': 16, 'n_estimators': 1460, 'max_features': 'auto', 'min_samples_split': 2, 'bootstrap': True, 'min_samples_leaf': 10}. Best is trial 6 with value: 1.1005636307726856.\u001b[0m\n",
            "\u001b[32m[I 2021-05-20 19:55:22,971]\u001b[0m Trial 11 finished with value: 1.1012440675312254 and parameters: {'max_depth': 24, 'n_estimators': 1460, 'max_features': 'auto', 'min_samples_split': 5, 'bootstrap': True, 'min_samples_leaf': 5}. Best is trial 6 with value: 1.1005636307726856.\u001b[0m\n",
            "\u001b[32m[I 2021-05-20 20:02:39,674]\u001b[0m Trial 12 finished with value: 1.1014807852660766 and parameters: {'max_depth': 19, 'n_estimators': 1990, 'max_features': 'auto', 'min_samples_split': 5, 'bootstrap': True, 'min_samples_leaf': 10}. Best is trial 6 with value: 1.1005636307726856.\u001b[0m\n",
            "\u001b[32m[I 2021-05-20 20:09:53,499]\u001b[0m Trial 13 finished with value: 1.1005519527803482 and parameters: {'max_depth': 28, 'n_estimators': 1690, 'max_features': 'auto', 'min_samples_split': 5, 'bootstrap': True, 'min_samples_leaf': 10}. Best is trial 13 with value: 1.1005519527803482.\u001b[0m\n",
            "\u001b[32m[I 2021-05-20 20:15:58,832]\u001b[0m Trial 14 finished with value: 1.1005620524415336 and parameters: {'max_depth': 28, 'n_estimators': 1420, 'max_features': 'auto', 'min_samples_split': 5, 'bootstrap': True, 'min_samples_leaf': 10}. Best is trial 13 with value: 1.1005519527803482.\u001b[0m\n",
            "\u001b[32m[I 2021-05-20 20:21:38,609]\u001b[0m Trial 15 finished with value: 1.1004397508167638 and parameters: {'max_depth': 30, 'n_estimators': 1300, 'max_features': 'auto', 'min_samples_split': 5, 'bootstrap': True, 'min_samples_leaf': 10}. Best is trial 15 with value: 1.1004397508167638.\u001b[0m\n",
            "\u001b[32m[I 2021-05-20 20:26:49,253]\u001b[0m Trial 16 finished with value: 1.1038689327474296 and parameters: {'max_depth': 13, 'n_estimators': 1250, 'max_features': 'auto', 'min_samples_split': 5, 'bootstrap': False, 'min_samples_leaf': 10}. Best is trial 15 with value: 1.1004397508167638.\u001b[0m\n",
            "\u001b[32m[I 2021-05-20 20:31:21,594]\u001b[0m Trial 17 finished with value: 1.1015332281500485 and parameters: {'max_depth': 19, 'n_estimators': 1230, 'max_features': 'auto', 'min_samples_split': 5, 'bootstrap': True, 'min_samples_leaf': 10}. Best is trial 15 with value: 1.1004397508167638.\u001b[0m\n",
            "\u001b[32m[I 2021-05-20 20:38:38,237]\u001b[0m Trial 18 finished with value: 1.1003949167640061 and parameters: {'max_depth': 30, 'n_estimators': 1680, 'max_features': 'auto', 'min_samples_split': 5, 'bootstrap': True, 'min_samples_leaf': 10}. Best is trial 18 with value: 1.1003949167640061.\u001b[0m\n",
            "\u001b[32m[I 2021-05-20 20:42:15,063]\u001b[0m Trial 19 finished with value: 1.1005924219662884 and parameters: {'max_depth': 30, 'n_estimators': 830, 'max_features': 'auto', 'min_samples_split': 2, 'bootstrap': True, 'min_samples_leaf': 10}. Best is trial 18 with value: 1.1003949167640061.\u001b[0m\n",
            "\u001b[32m[I 2021-05-20 20:47:31,428]\u001b[0m Trial 20 finished with value: 1.1006199431655812 and parameters: {'max_depth': 26, 'n_estimators': 1260, 'max_features': 'auto', 'min_samples_split': 5, 'bootstrap': True, 'min_samples_leaf': 10}. Best is trial 18 with value: 1.1003949167640061.\u001b[0m\n",
            "\u001b[32m[I 2021-05-20 20:55:02,617]\u001b[0m Trial 21 finished with value: 1.1003929459954018 and parameters: {'max_depth': 30, 'n_estimators': 1730, 'max_features': 'auto', 'min_samples_split': 5, 'bootstrap': True, 'min_samples_leaf': 10}. Best is trial 21 with value: 1.1003929459954018.\u001b[0m\n",
            "\u001b[32m[I 2021-05-20 21:01:50,073]\u001b[0m Trial 22 finished with value: 1.1003921339466658 and parameters: {'max_depth': 30, 'n_estimators': 1560, 'max_features': 'auto', 'min_samples_split': 5, 'bootstrap': True, 'min_samples_leaf': 10}. Best is trial 22 with value: 1.1003921339466658.\u001b[0m\n",
            "\u001b[32m[I 2021-05-20 21:08:51,339]\u001b[0m Trial 23 finished with value: 1.101182348452623 and parameters: {'max_depth': 21, 'n_estimators': 1820, 'max_features': 'auto', 'min_samples_split': 5, 'bootstrap': True, 'min_samples_leaf': 10}. Best is trial 22 with value: 1.1003921339466658.\u001b[0m\n",
            "\u001b[32m[I 2021-05-20 21:15:35,057]\u001b[0m Trial 24 finished with value: 1.1005969378931395 and parameters: {'max_depth': 26, 'n_estimators': 1590, 'max_features': 'auto', 'min_samples_split': 5, 'bootstrap': True, 'min_samples_leaf': 10}. Best is trial 22 with value: 1.1003921339466658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of finished trials: 25\n",
            "Best trial: {'max_depth': 30, 'n_estimators': 1560, 'max_features': 'auto', 'min_samples_split': 5, 'bootstrap': True, 'min_samples_leaf': 10}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ6JWk5TKrrr",
        "outputId": "7c3a19af-2e20-4502-c2a2-6f5ce628b2e6"
      },
      "source": [
        "study.best_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'max_depth': 30,\n",
              " 'max_features': 'auto',\n",
              " 'min_samples_leaf': 10,\n",
              " 'min_samples_split': 5,\n",
              " 'n_estimators': 1560}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtC_S97E8ep_"
      },
      "source": [
        "# LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziRoFgy81RDC"
      },
      "source": [
        "# X = df_all.drop(labels=['id','target'],axis=1,inplace=False).copy()\n",
        "# y = df_all['target'].values\n",
        "# X_test = df_test.drop(labels=['id'],axis=1,inplace=False).copy()\n",
        "# random_seed = 0\n",
        "\n",
        "# encoder = OrdinalEncoder()\n",
        "# all_encoded = encoder.fit_transform(X.append(X_test))\n",
        "# X = all_encoded[0:len(X)]\n",
        "# X_test = all_encoded[len(X):]\n",
        "\n",
        "# cat_features = np.arange(0,X.shape[1]).tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3YaeSvscX2Q"
      },
      "source": [
        "X = df_all.drop(labels=['id','target'],axis=1,inplace=False).copy()\n",
        "y = df_all['target'].values\n",
        "X_test = df_test.drop(labels=['id'],axis=1,inplace=False).copy()\n",
        "random_seed = 0\n",
        "\n",
        "encoder = OrdinalEncoder()\n",
        "all_encoded = encoder.fit_transform(X.append(X_test))\n",
        "X = all_encoded[0:len(X)]\n",
        "X_test = all_encoded[len(X):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fnrHkVe4FeH"
      },
      "source": [
        "# params = {\n",
        "#  'colsample_bytree': .1,\n",
        "#  'learning_rate': .01,\n",
        "#  'max_depth': 3,\n",
        "#  'min_child_samples': 81,\n",
        "#  'min_child_weight':0.5261052720119306,\n",
        "\n",
        "#  'num_leaves': 109,\n",
        "#  'reg_alpha': 14.411664782568891,\n",
        "#  'reg_lambda': 0.011351864739530503,\n",
        "#  'subsample': 0.04015184467061349\n",
        "#  }\n",
        "\n",
        "\n",
        "params = {\n",
        "  'learning_rate': .02,\n",
        "   'max_depth': 3,\n",
        "    'num_leaves': 6,\n",
        "    'min_split_gain': 0.17865452483871047,\n",
        "    'reg_alpha': 9.540720621520459,\n",
        "    'reg_lambda': 4.5781292529661375,\n",
        "    'colsample_bytree': 0.0644950794287173,\n",
        "    'subsample': 0.9314592865852914,\n",
        "    'subsample_freq': 7,\n",
        "    'min_child_samples': 57\n",
        "\n",
        "#  'colsample_bytree': .1,\n",
        "#  'max_depth': 3,\n",
        "#  'min_child_samples': 81,\n",
        "#  'min_child_weight':0.5261052720119306,\n",
        "\n",
        "#  'num_leaves': 109,\n",
        "#  'reg_alpha': 14.411664782568891,\n",
        "#  'reg_lambda': 0.011351864739530503,\n",
        "#  'subsample': 0.04015184467061349\n",
        " }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sx5IGxi4GPE",
        "outputId": "345ff517-ada9-4b9d-9717-8c5b755dd662"
      },
      "source": [
        "params_lgbm = params\n",
        "params_lgbm['boosting_type'] = 'gbdt'\n",
        "params_lgbm['device'] = 'gpu'\n",
        "params_lgbm ['objective'] = 'multiclasss'\n",
        "params_lgbm ['num_classes'] = 4,\n",
        "\n",
        "params_lgbm ['metric'] = 'multi_logloss'\n",
        "params_lgbm ['verbosity'] = -1\n",
        "params_lgbm ['n_estimators']= 50000\n",
        "#params_lgbm[\"cat_feature\"] = cat_features\n",
        "\n",
        "name = 'lighgbm_3seeds_5fold'\n",
        "k=5\n",
        "seed_list=[0,1,2]\n",
        "kf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\n",
        "oof = np.zeros((len(df_all),4))\n",
        "test_preds_list = []\n",
        "score_list = []\n",
        "fold=1\n",
        "  \n",
        "splits = list(kf.split(X,y))\n",
        "fold = 1\n",
        "for train_idx, val_idx in splits:\n",
        "  X_train, X_val = X[train_idx], X[val_idx]\n",
        "  y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "  val_preds_list = []\n",
        "\n",
        "  for seed in seed_list:\n",
        "    \n",
        "    # fit and run model\n",
        "    params_lgbm['random_state'] = seed\n",
        "    \n",
        "    model = lgbm.LGBMClassifier(**params_lgbm)\n",
        "    \n",
        "    model.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_val,y_val)],\n",
        "              early_stopping_rounds=100,\n",
        "              eval_names=['train','val'],verbose=200)\n",
        "\n",
        "    \n",
        "    val_preds_list.append(model.predict_proba(X_val))\n",
        "    test_preds_list.append(model.predict_proba(X_test))\n",
        "    \n",
        "  oof[val_idx] = np.mean(val_preds_list,axis=0)\n",
        "  score = log_loss(y_val, oof[val_idx])\n",
        "  print(f\"fold: {fold},log_loss: {score}\")\n",
        "  score_list.append(score)\n",
        "  # print(f\"fold: {fold}, class0 tr %: {y_train.value_counts()[0]/len(y_train)}, class0 val %: {y_val.value_counts()[0]/len(y_val)} \")\n",
        "  fold +=1\n",
        "  \n",
        "cv_logloss = np.mean(score_list)\n",
        "print(f\"{name} ,log_loss: {cv_logloss}\")\n",
        "\n",
        "preds= np.mean(test_preds_list,axis=0)\n",
        "\n",
        "\n",
        "file_name_oof = name +\"_oof.txt\"\n",
        "file_name_test = name + \"_test.csv\"\n",
        "with open(file_name_oof, \"wb\") as fp:\n",
        "      pickle.dump(oof, fp)\n",
        "\n",
        "#files.download(file_name_oof)\n",
        "\n",
        "df_submission[['Class_1','Class_2','Class_3','Class_4']] = preds\n",
        "df_submission.to_csv(file_name_test,index=None)\n",
        "#files.download(file_name_test) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttrain's multi_logloss: 1.10559\tval's multi_logloss: 1.10679\n",
            "[400]\ttrain's multi_logloss: 1.09827\tval's multi_logloss: 1.10052\n",
            "[600]\ttrain's multi_logloss: 1.09365\tval's multi_logloss: 1.09686\n",
            "[800]\ttrain's multi_logloss: 1.09028\tval's multi_logloss: 1.09443\n",
            "[1000]\ttrain's multi_logloss: 1.08782\tval's multi_logloss: 1.09282\n",
            "[1200]\ttrain's multi_logloss: 1.08592\tval's multi_logloss: 1.09169\n",
            "[1400]\ttrain's multi_logloss: 1.08445\tval's multi_logloss: 1.09087\n",
            "[1600]\ttrain's multi_logloss: 1.08327\tval's multi_logloss: 1.09034\n",
            "[1800]\ttrain's multi_logloss: 1.08231\tval's multi_logloss: 1.0899\n",
            "[2000]\ttrain's multi_logloss: 1.08154\tval's multi_logloss: 1.08961\n",
            "[2200]\ttrain's multi_logloss: 1.08088\tval's multi_logloss: 1.08938\n",
            "[2400]\ttrain's multi_logloss: 1.08032\tval's multi_logloss: 1.08924\n",
            "[2600]\ttrain's multi_logloss: 1.07983\tval's multi_logloss: 1.08914\n",
            "[2800]\ttrain's multi_logloss: 1.07946\tval's multi_logloss: 1.08904\n",
            "[3000]\ttrain's multi_logloss: 1.07911\tval's multi_logloss: 1.08899\n",
            "[3200]\ttrain's multi_logloss: 1.07884\tval's multi_logloss: 1.08895\n",
            "Early stopping, best iteration is:\n",
            "[3263]\ttrain's multi_logloss: 1.07876\tval's multi_logloss: 1.08894\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttrain's multi_logloss: 1.10626\tval's multi_logloss: 1.10754\n",
            "[400]\ttrain's multi_logloss: 1.09886\tval's multi_logloss: 1.10131\n",
            "[600]\ttrain's multi_logloss: 1.09395\tval's multi_logloss: 1.09751\n",
            "[800]\ttrain's multi_logloss: 1.09047\tval's multi_logloss: 1.09497\n",
            "[1000]\ttrain's multi_logloss: 1.08794\tval's multi_logloss: 1.09324\n",
            "[1200]\ttrain's multi_logloss: 1.08596\tval's multi_logloss: 1.09202\n",
            "[1400]\ttrain's multi_logloss: 1.08446\tval's multi_logloss: 1.09118\n",
            "[1600]\ttrain's multi_logloss: 1.08323\tval's multi_logloss: 1.09061\n",
            "[1800]\ttrain's multi_logloss: 1.08222\tval's multi_logloss: 1.09013\n",
            "[2000]\ttrain's multi_logloss: 1.0814\tval's multi_logloss: 1.08979\n",
            "[2200]\ttrain's multi_logloss: 1.0807\tval's multi_logloss: 1.08956\n",
            "[2400]\ttrain's multi_logloss: 1.08013\tval's multi_logloss: 1.08941\n",
            "[2600]\ttrain's multi_logloss: 1.07965\tval's multi_logloss: 1.08927\n",
            "[2800]\ttrain's multi_logloss: 1.07928\tval's multi_logloss: 1.08917\n",
            "[3000]\ttrain's multi_logloss: 1.07895\tval's multi_logloss: 1.08915\n",
            "[3200]\ttrain's multi_logloss: 1.07866\tval's multi_logloss: 1.08911\n",
            "Early stopping, best iteration is:\n",
            "[3143]\ttrain's multi_logloss: 1.07873\tval's multi_logloss: 1.08911\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttrain's multi_logloss: 1.10636\tval's multi_logloss: 1.10771\n",
            "[400]\ttrain's multi_logloss: 1.09892\tval's multi_logloss: 1.10154\n",
            "[600]\ttrain's multi_logloss: 1.09388\tval's multi_logloss: 1.0975\n",
            "[800]\ttrain's multi_logloss: 1.09054\tval's multi_logloss: 1.09509\n",
            "[1000]\ttrain's multi_logloss: 1.08793\tval's multi_logloss: 1.0933\n",
            "[1200]\ttrain's multi_logloss: 1.086\tval's multi_logloss: 1.09207\n",
            "[1400]\ttrain's multi_logloss: 1.08438\tval's multi_logloss: 1.09118\n",
            "[1600]\ttrain's multi_logloss: 1.08313\tval's multi_logloss: 1.09049\n",
            "[1800]\ttrain's multi_logloss: 1.08213\tval's multi_logloss: 1.09005\n",
            "[2000]\ttrain's multi_logloss: 1.08129\tval's multi_logloss: 1.0897\n",
            "[2200]\ttrain's multi_logloss: 1.08063\tval's multi_logloss: 1.08943\n",
            "[2400]\ttrain's multi_logloss: 1.08008\tval's multi_logloss: 1.08927\n",
            "[2600]\ttrain's multi_logloss: 1.07958\tval's multi_logloss: 1.08912\n",
            "[2800]\ttrain's multi_logloss: 1.07918\tval's multi_logloss: 1.08901\n",
            "[3000]\ttrain's multi_logloss: 1.07884\tval's multi_logloss: 1.08896\n",
            "[3200]\ttrain's multi_logloss: 1.07857\tval's multi_logloss: 1.08893\n",
            "[3400]\ttrain's multi_logloss: 1.07832\tval's multi_logloss: 1.08892\n",
            "Early stopping, best iteration is:\n",
            "[3367]\ttrain's multi_logloss: 1.07837\tval's multi_logloss: 1.0889\n",
            "fold: 1,log_loss: 1.0888838757026693\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttrain's multi_logloss: 1.10523\tval's multi_logloss: 1.10765\n",
            "[400]\ttrain's multi_logloss: 1.09765\tval's multi_logloss: 1.10202\n",
            "[600]\ttrain's multi_logloss: 1.09285\tval's multi_logloss: 1.0989\n",
            "[800]\ttrain's multi_logloss: 1.08935\tval's multi_logloss: 1.09694\n",
            "[1000]\ttrain's multi_logloss: 1.08679\tval's multi_logloss: 1.09562\n",
            "[1200]\ttrain's multi_logloss: 1.08482\tval's multi_logloss: 1.09476\n",
            "[1400]\ttrain's multi_logloss: 1.08328\tval's multi_logloss: 1.0942\n",
            "[1600]\ttrain's multi_logloss: 1.08203\tval's multi_logloss: 1.09384\n",
            "[1800]\ttrain's multi_logloss: 1.08103\tval's multi_logloss: 1.09365\n",
            "[2000]\ttrain's multi_logloss: 1.08021\tval's multi_logloss: 1.09343\n",
            "[2200]\ttrain's multi_logloss: 1.07949\tval's multi_logloss: 1.09334\n",
            "[2400]\ttrain's multi_logloss: 1.07891\tval's multi_logloss: 1.09326\n",
            "[2600]\ttrain's multi_logloss: 1.07844\tval's multi_logloss: 1.09322\n",
            "[2800]\ttrain's multi_logloss: 1.07802\tval's multi_logloss: 1.0932\n",
            "Early stopping, best iteration is:\n",
            "[2731]\ttrain's multi_logloss: 1.07816\tval's multi_logloss: 1.0932\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttrain's multi_logloss: 1.106\tval's multi_logloss: 1.10846\n",
            "[400]\ttrain's multi_logloss: 1.09834\tval's multi_logloss: 1.10282\n",
            "[600]\ttrain's multi_logloss: 1.09325\tval's multi_logloss: 1.09941\n",
            "[800]\ttrain's multi_logloss: 1.08966\tval's multi_logloss: 1.0972\n",
            "[1000]\ttrain's multi_logloss: 1.08702\tval's multi_logloss: 1.09585\n",
            "[1200]\ttrain's multi_logloss: 1.08495\tval's multi_logloss: 1.0949\n",
            "[1400]\ttrain's multi_logloss: 1.08337\tval's multi_logloss: 1.0943\n",
            "[1600]\ttrain's multi_logloss: 1.08211\tval's multi_logloss: 1.09388\n",
            "[1800]\ttrain's multi_logloss: 1.08101\tval's multi_logloss: 1.09356\n",
            "[2000]\ttrain's multi_logloss: 1.08014\tval's multi_logloss: 1.0934\n",
            "[2200]\ttrain's multi_logloss: 1.07944\tval's multi_logloss: 1.09326\n",
            "[2400]\ttrain's multi_logloss: 1.07885\tval's multi_logloss: 1.09322\n",
            "Early stopping, best iteration is:\n",
            "[2472]\ttrain's multi_logloss: 1.07867\tval's multi_logloss: 1.09319\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttrain's multi_logloss: 1.10608\tval's multi_logloss: 1.10836\n",
            "[400]\ttrain's multi_logloss: 1.0984\tval's multi_logloss: 1.10268\n",
            "[600]\ttrain's multi_logloss: 1.09317\tval's multi_logloss: 1.09917\n",
            "[800]\ttrain's multi_logloss: 1.08966\tval's multi_logloss: 1.09719\n",
            "[1000]\ttrain's multi_logloss: 1.08695\tval's multi_logloss: 1.09578\n",
            "[1200]\ttrain's multi_logloss: 1.08488\tval's multi_logloss: 1.0949\n",
            "[1400]\ttrain's multi_logloss: 1.08321\tval's multi_logloss: 1.09422\n",
            "[1600]\ttrain's multi_logloss: 1.08191\tval's multi_logloss: 1.09378\n",
            "[1800]\ttrain's multi_logloss: 1.0809\tval's multi_logloss: 1.09348\n",
            "[2000]\ttrain's multi_logloss: 1.08001\tval's multi_logloss: 1.09329\n",
            "[2200]\ttrain's multi_logloss: 1.07931\tval's multi_logloss: 1.09317\n",
            "[2400]\ttrain's multi_logloss: 1.07872\tval's multi_logloss: 1.09307\n",
            "[2600]\ttrain's multi_logloss: 1.07821\tval's multi_logloss: 1.09303\n",
            "Early stopping, best iteration is:\n",
            "[2545]\ttrain's multi_logloss: 1.07835\tval's multi_logloss: 1.09302\n",
            "fold: 2,log_loss: 1.092998407873959\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttrain's multi_logloss: 1.10572\tval's multi_logloss: 1.10677\n",
            "[400]\ttrain's multi_logloss: 1.09842\tval's multi_logloss: 1.10034\n",
            "[600]\ttrain's multi_logloss: 1.09389\tval's multi_logloss: 1.09649\n",
            "[800]\ttrain's multi_logloss: 1.09056\tval's multi_logloss: 1.09385\n",
            "[1000]\ttrain's multi_logloss: 1.08809\tval's multi_logloss: 1.09217\n",
            "[1200]\ttrain's multi_logloss: 1.08621\tval's multi_logloss: 1.09095\n",
            "[1400]\ttrain's multi_logloss: 1.08476\tval's multi_logloss: 1.09016\n",
            "[1600]\ttrain's multi_logloss: 1.08357\tval's multi_logloss: 1.08956\n",
            "[1800]\ttrain's multi_logloss: 1.08262\tval's multi_logloss: 1.08906\n",
            "[2000]\ttrain's multi_logloss: 1.08187\tval's multi_logloss: 1.08869\n",
            "[2200]\ttrain's multi_logloss: 1.0812\tval's multi_logloss: 1.08846\n",
            "[2400]\ttrain's multi_logloss: 1.08067\tval's multi_logloss: 1.08829\n",
            "[2600]\ttrain's multi_logloss: 1.08021\tval's multi_logloss: 1.08812\n",
            "[2800]\ttrain's multi_logloss: 1.07985\tval's multi_logloss: 1.08801\n",
            "[3000]\ttrain's multi_logloss: 1.07953\tval's multi_logloss: 1.08792\n",
            "[3200]\ttrain's multi_logloss: 1.07928\tval's multi_logloss: 1.08785\n",
            "[3400]\ttrain's multi_logloss: 1.07905\tval's multi_logloss: 1.08778\n",
            "[3600]\ttrain's multi_logloss: 1.07885\tval's multi_logloss: 1.08772\n",
            "[3800]\ttrain's multi_logloss: 1.07868\tval's multi_logloss: 1.08769\n",
            "[4000]\ttrain's multi_logloss: 1.07853\tval's multi_logloss: 1.08765\n",
            "[4200]\ttrain's multi_logloss: 1.07841\tval's multi_logloss: 1.08763\n",
            "[4400]\ttrain's multi_logloss: 1.07831\tval's multi_logloss: 1.08761\n",
            "[4600]\ttrain's multi_logloss: 1.07821\tval's multi_logloss: 1.08758\n",
            "[4800]\ttrain's multi_logloss: 1.07813\tval's multi_logloss: 1.08757\n",
            "[5000]\ttrain's multi_logloss: 1.07804\tval's multi_logloss: 1.08757\n",
            "Early stopping, best iteration is:\n",
            "[5046]\ttrain's multi_logloss: 1.07803\tval's multi_logloss: 1.08756\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttrain's multi_logloss: 1.10634\tval's multi_logloss: 1.10769\n",
            "[400]\ttrain's multi_logloss: 1.09894\tval's multi_logloss: 1.10134\n",
            "[600]\ttrain's multi_logloss: 1.0941\tval's multi_logloss: 1.09735\n",
            "[800]\ttrain's multi_logloss: 1.09069\tval's multi_logloss: 1.0947\n",
            "[1000]\ttrain's multi_logloss: 1.08818\tval's multi_logloss: 1.09293\n",
            "[1200]\ttrain's multi_logloss: 1.08623\tval's multi_logloss: 1.09163\n",
            "[1400]\ttrain's multi_logloss: 1.08474\tval's multi_logloss: 1.09061\n",
            "[1600]\ttrain's multi_logloss: 1.08353\tval's multi_logloss: 1.0899\n",
            "[1800]\ttrain's multi_logloss: 1.08252\tval's multi_logloss: 1.08936\n",
            "[2000]\ttrain's multi_logloss: 1.08171\tval's multi_logloss: 1.08893\n",
            "[2200]\ttrain's multi_logloss: 1.08104\tval's multi_logloss: 1.08862\n",
            "[2400]\ttrain's multi_logloss: 1.08051\tval's multi_logloss: 1.08839\n",
            "[2600]\ttrain's multi_logloss: 1.08006\tval's multi_logloss: 1.08815\n",
            "[2800]\ttrain's multi_logloss: 1.07969\tval's multi_logloss: 1.08798\n",
            "[3000]\ttrain's multi_logloss: 1.07937\tval's multi_logloss: 1.08788\n",
            "[3200]\ttrain's multi_logloss: 1.07909\tval's multi_logloss: 1.08778\n",
            "[3400]\ttrain's multi_logloss: 1.07887\tval's multi_logloss: 1.08773\n",
            "[3600]\ttrain's multi_logloss: 1.07867\tval's multi_logloss: 1.08769\n",
            "[3800]\ttrain's multi_logloss: 1.07851\tval's multi_logloss: 1.08765\n",
            "[4000]\ttrain's multi_logloss: 1.07838\tval's multi_logloss: 1.08761\n",
            "[4200]\ttrain's multi_logloss: 1.07826\tval's multi_logloss: 1.08758\n",
            "[4400]\ttrain's multi_logloss: 1.07815\tval's multi_logloss: 1.08756\n",
            "[4600]\ttrain's multi_logloss: 1.07804\tval's multi_logloss: 1.08754\n",
            "[4800]\ttrain's multi_logloss: 1.07795\tval's multi_logloss: 1.08752\n",
            "[5000]\ttrain's multi_logloss: 1.07788\tval's multi_logloss: 1.08751\n",
            "[5200]\ttrain's multi_logloss: 1.07781\tval's multi_logloss: 1.08749\n",
            "[5400]\ttrain's multi_logloss: 1.07775\tval's multi_logloss: 1.08747\n",
            "Early stopping, best iteration is:\n",
            "[5455]\ttrain's multi_logloss: 1.07773\tval's multi_logloss: 1.08747\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttrain's multi_logloss: 1.10635\tval's multi_logloss: 1.1076\n",
            "[400]\ttrain's multi_logloss: 1.09906\tval's multi_logloss: 1.10108\n",
            "[600]\ttrain's multi_logloss: 1.09407\tval's multi_logloss: 1.09705\n",
            "[800]\ttrain's multi_logloss: 1.09075\tval's multi_logloss: 1.09446\n",
            "[1000]\ttrain's multi_logloss: 1.08817\tval's multi_logloss: 1.09258\n",
            "[1200]\ttrain's multi_logloss: 1.08622\tval's multi_logloss: 1.09123\n",
            "[1400]\ttrain's multi_logloss: 1.08463\tval's multi_logloss: 1.09022\n",
            "[1600]\ttrain's multi_logloss: 1.0834\tval's multi_logloss: 1.08953\n",
            "[1800]\ttrain's multi_logloss: 1.0824\tval's multi_logloss: 1.08901\n",
            "[2000]\ttrain's multi_logloss: 1.08155\tval's multi_logloss: 1.08861\n",
            "[2200]\ttrain's multi_logloss: 1.08089\tval's multi_logloss: 1.08831\n",
            "[2400]\ttrain's multi_logloss: 1.08036\tval's multi_logloss: 1.08808\n",
            "[2600]\ttrain's multi_logloss: 1.07991\tval's multi_logloss: 1.08792\n",
            "[2800]\ttrain's multi_logloss: 1.07953\tval's multi_logloss: 1.08779\n",
            "[3000]\ttrain's multi_logloss: 1.07923\tval's multi_logloss: 1.0877\n",
            "[3200]\ttrain's multi_logloss: 1.07897\tval's multi_logloss: 1.0876\n",
            "[3400]\ttrain's multi_logloss: 1.07874\tval's multi_logloss: 1.08756\n",
            "[3600]\ttrain's multi_logloss: 1.07855\tval's multi_logloss: 1.08751\n",
            "[3800]\ttrain's multi_logloss: 1.07839\tval's multi_logloss: 1.08748\n",
            "[4000]\ttrain's multi_logloss: 1.07825\tval's multi_logloss: 1.08746\n",
            "[4200]\ttrain's multi_logloss: 1.07815\tval's multi_logloss: 1.08744\n",
            "[4400]\ttrain's multi_logloss: 1.07804\tval's multi_logloss: 1.08743\n",
            "Early stopping, best iteration is:\n",
            "[4459]\ttrain's multi_logloss: 1.07801\tval's multi_logloss: 1.08741\n",
            "fold: 3,log_loss: 1.087415138927424\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttrain's multi_logloss: 1.10547\tval's multi_logloss: 1.10713\n",
            "[400]\ttrain's multi_logloss: 1.09816\tval's multi_logloss: 1.10103\n",
            "[600]\ttrain's multi_logloss: 1.09352\tval's multi_logloss: 1.09746\n",
            "[800]\ttrain's multi_logloss: 1.09018\tval's multi_logloss: 1.09498\n",
            "[1000]\ttrain's multi_logloss: 1.08772\tval's multi_logloss: 1.0933\n",
            "[1200]\ttrain's multi_logloss: 1.08583\tval's multi_logloss: 1.09222\n",
            "[1400]\ttrain's multi_logloss: 1.08436\tval's multi_logloss: 1.09138\n",
            "[1600]\ttrain's multi_logloss: 1.08315\tval's multi_logloss: 1.09077\n",
            "[1800]\ttrain's multi_logloss: 1.08217\tval's multi_logloss: 1.09038\n",
            "[2000]\ttrain's multi_logloss: 1.08139\tval's multi_logloss: 1.0901\n",
            "[2200]\ttrain's multi_logloss: 1.08072\tval's multi_logloss: 1.08987\n",
            "[2400]\ttrain's multi_logloss: 1.08015\tval's multi_logloss: 1.08965\n",
            "[2600]\ttrain's multi_logloss: 1.0797\tval's multi_logloss: 1.08953\n",
            "[2800]\ttrain's multi_logloss: 1.07931\tval's multi_logloss: 1.08942\n",
            "[3000]\ttrain's multi_logloss: 1.07897\tval's multi_logloss: 1.08935\n",
            "[3200]\ttrain's multi_logloss: 1.07871\tval's multi_logloss: 1.0893\n",
            "[3400]\ttrain's multi_logloss: 1.07849\tval's multi_logloss: 1.08926\n",
            "[3600]\ttrain's multi_logloss: 1.07828\tval's multi_logloss: 1.08923\n",
            "[3800]\ttrain's multi_logloss: 1.07811\tval's multi_logloss: 1.0892\n",
            "Early stopping, best iteration is:\n",
            "[3846]\ttrain's multi_logloss: 1.07808\tval's multi_logloss: 1.0892\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttrain's multi_logloss: 1.10636\tval's multi_logloss: 1.10758\n",
            "[400]\ttrain's multi_logloss: 1.09892\tval's multi_logloss: 1.10129\n",
            "[600]\ttrain's multi_logloss: 1.09402\tval's multi_logloss: 1.09738\n",
            "[800]\ttrain's multi_logloss: 1.09054\tval's multi_logloss: 1.09484\n",
            "[1000]\ttrain's multi_logloss: 1.08797\tval's multi_logloss: 1.09308\n",
            "[1200]\ttrain's multi_logloss: 1.08598\tval's multi_logloss: 1.09188\n",
            "[1400]\ttrain's multi_logloss: 1.08447\tval's multi_logloss: 1.09108\n",
            "[1600]\ttrain's multi_logloss: 1.08325\tval's multi_logloss: 1.09051\n",
            "[1800]\ttrain's multi_logloss: 1.08223\tval's multi_logloss: 1.0901\n",
            "[2000]\ttrain's multi_logloss: 1.08142\tval's multi_logloss: 1.08977\n",
            "[2200]\ttrain's multi_logloss: 1.08075\tval's multi_logloss: 1.0895\n",
            "[2400]\ttrain's multi_logloss: 1.08018\tval's multi_logloss: 1.08935\n",
            "[2600]\ttrain's multi_logloss: 1.07971\tval's multi_logloss: 1.08923\n",
            "[2800]\ttrain's multi_logloss: 1.07932\tval's multi_logloss: 1.08914\n",
            "[3000]\ttrain's multi_logloss: 1.07897\tval's multi_logloss: 1.0891\n",
            "[3200]\ttrain's multi_logloss: 1.07868\tval's multi_logloss: 1.08906\n",
            "[3400]\ttrain's multi_logloss: 1.07845\tval's multi_logloss: 1.08902\n",
            "[3600]\ttrain's multi_logloss: 1.07827\tval's multi_logloss: 1.089\n",
            "[3800]\ttrain's multi_logloss: 1.0781\tval's multi_logloss: 1.089\n",
            "Early stopping, best iteration is:\n",
            "[3700]\ttrain's multi_logloss: 1.07818\tval's multi_logloss: 1.08899\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttrain's multi_logloss: 1.10644\tval's multi_logloss: 1.10748\n",
            "[400]\ttrain's multi_logloss: 1.099\tval's multi_logloss: 1.10113\n",
            "[600]\ttrain's multi_logloss: 1.09392\tval's multi_logloss: 1.09713\n",
            "[800]\ttrain's multi_logloss: 1.09055\tval's multi_logloss: 1.09469\n",
            "[1000]\ttrain's multi_logloss: 1.08793\tval's multi_logloss: 1.09294\n",
            "[1200]\ttrain's multi_logloss: 1.08598\tval's multi_logloss: 1.09178\n",
            "[1400]\ttrain's multi_logloss: 1.08437\tval's multi_logloss: 1.09094\n",
            "[1600]\ttrain's multi_logloss: 1.08309\tval's multi_logloss: 1.09038\n",
            "[1800]\ttrain's multi_logloss: 1.08209\tval's multi_logloss: 1.08996\n",
            "[2000]\ttrain's multi_logloss: 1.08124\tval's multi_logloss: 1.08967\n",
            "[2200]\ttrain's multi_logloss: 1.08054\tval's multi_logloss: 1.08948\n",
            "[2400]\ttrain's multi_logloss: 1.07998\tval's multi_logloss: 1.08933\n",
            "[2600]\ttrain's multi_logloss: 1.0795\tval's multi_logloss: 1.08922\n",
            "[2800]\ttrain's multi_logloss: 1.07911\tval's multi_logloss: 1.08914\n",
            "[3000]\ttrain's multi_logloss: 1.07878\tval's multi_logloss: 1.08908\n",
            "[3200]\ttrain's multi_logloss: 1.07852\tval's multi_logloss: 1.08904\n",
            "[3400]\ttrain's multi_logloss: 1.07829\tval's multi_logloss: 1.08901\n",
            "[3600]\ttrain's multi_logloss: 1.07812\tval's multi_logloss: 1.089\n",
            "[3800]\ttrain's multi_logloss: 1.07795\tval's multi_logloss: 1.08899\n",
            "[4000]\ttrain's multi_logloss: 1.07781\tval's multi_logloss: 1.08898\n",
            "Early stopping, best iteration is:\n",
            "[3902]\ttrain's multi_logloss: 1.07787\tval's multi_logloss: 1.08898\n",
            "fold: 4,log_loss: 1.0889760096665408\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttrain's multi_logloss: 1.10561\tval's multi_logloss: 1.10694\n",
            "[400]\ttrain's multi_logloss: 1.09822\tval's multi_logloss: 1.10084\n",
            "[600]\ttrain's multi_logloss: 1.09353\tval's multi_logloss: 1.09743\n",
            "[800]\ttrain's multi_logloss: 1.09012\tval's multi_logloss: 1.09508\n",
            "[1000]\ttrain's multi_logloss: 1.08764\tval's multi_logloss: 1.09358\n",
            "[1200]\ttrain's multi_logloss: 1.0857\tval's multi_logloss: 1.09258\n",
            "[1400]\ttrain's multi_logloss: 1.08421\tval's multi_logloss: 1.09192\n",
            "[1600]\ttrain's multi_logloss: 1.08301\tval's multi_logloss: 1.09142\n",
            "[1800]\ttrain's multi_logloss: 1.08204\tval's multi_logloss: 1.09109\n",
            "[2000]\ttrain's multi_logloss: 1.08124\tval's multi_logloss: 1.09085\n",
            "[2200]\ttrain's multi_logloss: 1.08056\tval's multi_logloss: 1.09065\n",
            "[2400]\ttrain's multi_logloss: 1.08001\tval's multi_logloss: 1.09056\n",
            "[2600]\ttrain's multi_logloss: 1.07953\tval's multi_logloss: 1.09045\n",
            "[2800]\ttrain's multi_logloss: 1.07912\tval's multi_logloss: 1.0904\n",
            "[3000]\ttrain's multi_logloss: 1.07878\tval's multi_logloss: 1.09032\n",
            "Early stopping, best iteration is:\n",
            "[3004]\ttrain's multi_logloss: 1.07878\tval's multi_logloss: 1.09032\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttrain's multi_logloss: 1.10629\tval's multi_logloss: 1.10771\n",
            "[400]\ttrain's multi_logloss: 1.09883\tval's multi_logloss: 1.10147\n",
            "[600]\ttrain's multi_logloss: 1.09387\tval's multi_logloss: 1.09773\n",
            "[800]\ttrain's multi_logloss: 1.09031\tval's multi_logloss: 1.09531\n",
            "[1000]\ttrain's multi_logloss: 1.08772\tval's multi_logloss: 1.09372\n",
            "[1200]\ttrain's multi_logloss: 1.08573\tval's multi_logloss: 1.09257\n",
            "[1400]\ttrain's multi_logloss: 1.08418\tval's multi_logloss: 1.09178\n",
            "[1600]\ttrain's multi_logloss: 1.08294\tval's multi_logloss: 1.09127\n",
            "[1800]\ttrain's multi_logloss: 1.08191\tval's multi_logloss: 1.0909\n",
            "[2000]\ttrain's multi_logloss: 1.08107\tval's multi_logloss: 1.09065\n",
            "[2200]\ttrain's multi_logloss: 1.08038\tval's multi_logloss: 1.09047\n",
            "[2400]\ttrain's multi_logloss: 1.07983\tval's multi_logloss: 1.09038\n",
            "[2600]\ttrain's multi_logloss: 1.07935\tval's multi_logloss: 1.09033\n",
            "[2800]\ttrain's multi_logloss: 1.07895\tval's multi_logloss: 1.09027\n",
            "[3000]\ttrain's multi_logloss: 1.07864\tval's multi_logloss: 1.09021\n",
            "Early stopping, best iteration is:\n",
            "[3094]\ttrain's multi_logloss: 1.07851\tval's multi_logloss: 1.09019\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttrain's multi_logloss: 1.10635\tval's multi_logloss: 1.10788\n",
            "[400]\ttrain's multi_logloss: 1.0989\tval's multi_logloss: 1.10178\n",
            "[600]\ttrain's multi_logloss: 1.09387\tval's multi_logloss: 1.09775\n",
            "[800]\ttrain's multi_logloss: 1.09045\tval's multi_logloss: 1.09536\n",
            "[1000]\ttrain's multi_logloss: 1.08783\tval's multi_logloss: 1.09367\n",
            "[1200]\ttrain's multi_logloss: 1.08586\tval's multi_logloss: 1.09255\n",
            "[1400]\ttrain's multi_logloss: 1.08423\tval's multi_logloss: 1.09176\n",
            "[1600]\ttrain's multi_logloss: 1.08292\tval's multi_logloss: 1.09121\n",
            "[1800]\ttrain's multi_logloss: 1.08189\tval's multi_logloss: 1.09082\n",
            "[2000]\ttrain's multi_logloss: 1.08105\tval's multi_logloss: 1.09058\n",
            "[2200]\ttrain's multi_logloss: 1.08034\tval's multi_logloss: 1.09041\n",
            "[2400]\ttrain's multi_logloss: 1.07977\tval's multi_logloss: 1.0903\n",
            "[2600]\ttrain's multi_logloss: 1.07929\tval's multi_logloss: 1.09022\n",
            "[2800]\ttrain's multi_logloss: 1.07889\tval's multi_logloss: 1.09016\n",
            "[3000]\ttrain's multi_logloss: 1.07856\tval's multi_logloss: 1.09012\n",
            "[3200]\ttrain's multi_logloss: 1.07828\tval's multi_logloss: 1.09008\n",
            "[3400]\ttrain's multi_logloss: 1.07805\tval's multi_logloss: 1.09007\n",
            "[3600]\ttrain's multi_logloss: 1.07785\tval's multi_logloss: 1.09008\n",
            "Early stopping, best iteration is:\n",
            "[3544]\ttrain's multi_logloss: 1.07791\tval's multi_logloss: 1.09006\n",
            "fold: 5,log_loss: 1.090083858818489\n",
            "lighgbm_3seeds_5fold ,log_loss: 1.0896714581978164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2jILZN8FAbW"
      },
      "source": [
        "# Lightgbm Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCxTk9nZ8KX-"
      },
      "source": [
        "# X = df_all.drop(labels=['id','target'],axis=1,inplace=False).copy()\n",
        "# y = df_all['target'].values\n",
        "# X_test = df_test.drop(labels=['id'],axis=1,inplace=False).copy()\n",
        "# random_seed = 0\n",
        "\n",
        "# encoder = OrdinalEncoder()\n",
        "# all_encoded = encoder.fit_transform(X.append(X_test))\n",
        "# X = all_encoded[0:len(X)]\n",
        "# X_test = all_encoded[len(X):]\n",
        "\n",
        "# cat_features = np.arange(0,X.shape[1]).tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vLBdT8awaPf"
      },
      "source": [
        "X = df_all.drop(labels=['id','target'],axis=1,inplace=False).copy()\n",
        "y = df_all['target'].values\n",
        "X_test = df_test.drop(labels=['id'],axis=1,inplace=False).copy()\n",
        "random_seed = 0\n",
        "\n",
        "encoder = OrdinalEncoder()\n",
        "all_encoded = encoder.fit_transform(X.append(X_test))\n",
        "X = all_encoded[0:len(X)]\n",
        "X_test = all_encoded[len(X):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Km8HQoQFLGN"
      },
      "source": [
        "# for the fixed learning rate, use the opt n iterations and tune the tree hyperparameters\n",
        "def objective(trial,data=X,target=y):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  param_space = {\n",
        "               'device':'gpu',  # Use GPU acceleration\n",
        "               'boosting_type': 'gbdt',\n",
        "               'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 1e3),\n",
        "               'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 1e3),\n",
        "               'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1 , 1.0),\n",
        "               'subsample': trial.suggest_float('subsample', 0.1, 1.0),\n",
        "               'learning_rate': trial.suggest_loguniform('learning_rate', 1e-2, 1e-2),\n",
        "               'num_leaves': trial.suggest_int(\"num_leaves\", 31,256),\n",
        "               'min_child_samples': trial.suggest_int('min_child_samples', 1, 500),\n",
        "               'max_depth':trial.suggest_int('max_depth',3,127),\n",
        "               'n_estimators':100000,\n",
        "               'objective':'multiclass',\n",
        "               'metric':'multi_logloss'\n",
        "                }\n",
        "            \n",
        "  #X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=.1,random_state=2021,stratify=y)\n",
        "  k=5\n",
        "  seed_list=[0]\n",
        "  kf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\n",
        "  oof = np.zeros((len(df_all),4))\n",
        "  score_list = []\n",
        "  fold=1\n",
        "  \n",
        "  splits = list(kf.split(X,y))\n",
        "  for train_idx, val_idx in splits:\n",
        "    X_train, X_val = X[train_idx,:], X[val_idx,:]\n",
        "    y_train, y_val = y[train_idx], y[val_idx]\n",
        "  \n",
        "    val_preds_list = []\n",
        "  \n",
        "    for seed in seed_list:\n",
        "      # fit and run model\n",
        "      param_space['random_state'] = seed\n",
        "\n",
        "      model = lgbm.LGBMClassifier(**param_space)\n",
        "      model.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_val,y_val)],\n",
        "                early_stopping_rounds=100,\n",
        "                eval_names=['train','val'],verbose=0)\n",
        "    \n",
        "      val_preds_list.append(model.predict_proba(X_val))\n",
        "     #test_preds_list.append(model.predict_proba(X_test)[:,1])\n",
        "    \n",
        "    oof[val_idx] = np.mean(val_preds_list,axis=0)\n",
        "    score = log_loss(y_val, oof[val_idx])\n",
        "    print(f\"fold: {fold},logloss: {score}\")\n",
        "    score_list.append(score)\n",
        "    fold +=1\n",
        "  \n",
        "  cv_logloss = np.mean(score_list)\n",
        "  \n",
        "  return cv_logloss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "CoS-nU8OF6Ip",
        "outputId": "1e23a61b-f553-4b11-a9fc-6332c5d87e01"
      },
      "source": [
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective,n_trials= 30)\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:', study.best_trial.params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-23 19:46:25,041]\u001b[0m A new study created in memory with name: no-name-fb79f113-3753-4660-a29d-2bb115b0a193\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.1198736476631492\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-27845a7a65c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'minimize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of finished trials:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best trial:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-4dd5a11c6a70>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial, data, target)\u001b[0m\n\u001b[1;32m     42\u001b[0m       model.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_val,y_val)],\n\u001b[1;32m     43\u001b[0m                 \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 eval_names=['train','val'],verbose=0)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m       \u001b[0mval_preds_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    903\u001b[0m                     \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m                     callbacks=callbacks, init_model=init_model)\n\u001b[0m\u001b[1;32m    906\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    697\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_metrics_callable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                               callbacks=callbacks, init_model=init_model)\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36meval_train\u001b[0;34m(self, feval)\u001b[0m\n\u001b[1;32m   2859\u001b[0m             \u001b[0mList\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2860\u001b[0m         \"\"\"\n\u001b[0;32m-> 2861\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inner_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_data_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2863\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[0;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[1;32m   3397\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3398\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_out_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3399\u001b[0;31m                 result.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[1;32m   3400\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtmp_out_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_inner_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3401\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length of eval results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDjVJt4Ky_7M",
        "outputId": "382a69e8-dfba-4203-9533-e62ff8a2446c"
      },
      "source": [
        "study.best_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cat_l2': 1,\n",
              " 'cat_smooth': 41,\n",
              " 'colsample_bytree': 0.10152839180930642,\n",
              " 'learning_rate': 0.028561805912614473,\n",
              " 'max_depth': 77,\n",
              " 'min_child_samples': 256,\n",
              " 'min_data_per_group': 293,\n",
              " 'num_leaves': 69,\n",
              " 'reg_alpha': 41.076503175793036,\n",
              " 'reg_lambda': 0.0011579102445110068,\n",
              " 'subsample': 0.3473382674747556}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPutft8ZI3vE"
      },
      "source": [
        "# XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-qRle3VzCos"
      },
      "source": [
        "X = df_all.drop(labels=['id','target'],axis=1,inplace=False).copy()\n",
        "y = df_all['target'].map({\"Class_1\":0,\"Class_2\":1,\"Class_3\":2,\"Class_4\":3}).values\n",
        "X_test = df_test.drop(labels=['id'],axis=1,inplace=False).copy()\n",
        "random_seed = 0\n",
        "\n",
        "encoder = OrdinalEncoder()\n",
        "all_encoded = encoder.fit_transform(X.append(X_test))\n",
        "X = all_encoded[0:len(X)]\n",
        "X_test = all_encoded[len(X):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzzszDO4I_XX"
      },
      "source": [
        "# params = { \n",
        "# 'max_depth': 6,  \n",
        "# 'learning_rate': 0.1,\n",
        "# 'gamma': 0.5, \n",
        "# 'reg_lambda': 20, \n",
        "# 'reg_alpha': 10, \n",
        "# 'colsample_bytree': 0.1\n",
        "#               }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4heyZcFTt9VZ"
      },
      "source": [
        "params =  {'lambda': 1.3718620937297796, \n",
        "           'alpha': 6.395781966352342, \n",
        "           'colsample_bytree': 0.2390564723786096, \n",
        "           'colsample_bynode': 0.7459555518737353, \n",
        "           'colsample_bylevel': 0.36002014547566097, \n",
        "           'subsample': 0.6302863949739616,\n",
        "           'eta': 0.01, \n",
        "           'grow_policy': 'lossguide', \n",
        "           'max_depth': 19, \n",
        "           'min_child_weight': 28, \n",
        "           'max_bin': 258, \n",
        "           'deterministic_histogram': False}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-Rl-FstPKBi2",
        "outputId": "2780fb98-f0f9-44bd-e50f-50a6a3a29938"
      },
      "source": [
        "params_xgb = params\n",
        "params_xgb[\"tree_method\"] = \"gpu_hist\"\n",
        "params_xgb[\"predictor\"] = 'gpu_predictor'\n",
        "params_xgb[\"objective\"] = 'multi:softprob'\n",
        "params_xgb[\"num_class\"] = 4\n",
        "#params_xgb[\"eval_metric\"] ='logloss'\n",
        "\n",
        "name = 'xgboost_3seeds_5fold'\n",
        "k=5\n",
        "seed_list=[0,1,2]\n",
        "kf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\n",
        "oof = np.zeros((len(df_all),4))\n",
        "test_preds_list = []\n",
        "score_list = []\n",
        "fold=1\n",
        "  \n",
        "splits = list(kf.split(X,y))\n",
        "fold = 1\n",
        "for train_idx, val_idx in splits:\n",
        "  X_train, X_val = X[train_idx], X[val_idx]\n",
        "  y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "  val_preds_list = []\n",
        "\n",
        "  for seed in seed_list:\n",
        "    \n",
        "    # fit and run model\n",
        "    params_xgb['seed'] = seed\n",
        "    \n",
        "    dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
        "    dval = xgb.DMatrix(data=X_val, label=y_val)\n",
        "    dtest = xgb.DMatrix(data=X_test)\n",
        "    \n",
        "    model = xgb.train(params_xgb, dtrain,\\\n",
        "                       evals=[(dtrain,'train'),(dval,'val')],\\\n",
        "                       verbose_eval=100,\n",
        "                       early_stopping_rounds=100,\n",
        "                       num_boost_round=100000)\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "    val_preds_list.append(model.predict(dval))\n",
        "    test_preds_list.append(model.predict(dtest))\n",
        "    \n",
        "  oof[val_idx] = np.mean(val_preds_list,axis=0)\n",
        "  score = log_loss(y_val, oof[val_idx])\n",
        "  print(f\"fold: {fold},log_loss: {score}\")\n",
        "  score_list.append(score)\n",
        "  # print(f\"fold: {fold}, class0 tr %: {y_train.value_counts()[0]/len(y_train)}, class0 val %: {y_val.value_counts()[0]/len(y_val)} \")\n",
        "  fold +=1\n",
        "  \n",
        "cv_logloss = np.mean(score_list)\n",
        "print(f\"{name} ,log_loss: {cv_logloss}\")\n",
        "\n",
        "preds= np.mean(test_preds_list,axis=0)\n",
        "\n",
        "\n",
        "file_name_oof = name + \"_oof.txt\"\n",
        "file_name_test = name + \"_test.csv\"\n",
        "with open(file_name_oof, \"wb\") as fp:\n",
        "      pickle.dump(oof, fp)\n",
        "\n",
        "files.download(file_name_oof)\n",
        "\n",
        "df_submission[['Class_1','Class_2','Class_3','Class_4']] = preds\n",
        "df_submission.to_csv(file_name_test,index=None)\n",
        "files.download(file_name_test) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[17:18:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-mlogloss:1.38227\tval-mlogloss:1.38227\n",
            "[100]\ttrain-mlogloss:1.17808\tval-mlogloss:1.17847\n",
            "[200]\ttrain-mlogloss:1.12669\tval-mlogloss:1.12765\n",
            "[300]\ttrain-mlogloss:1.11088\tval-mlogloss:1.11255\n",
            "[400]\ttrain-mlogloss:1.10397\tval-mlogloss:1.10650\n",
            "[500]\ttrain-mlogloss:1.09971\tval-mlogloss:1.10320\n",
            "[600]\ttrain-mlogloss:1.09634\tval-mlogloss:1.10086\n",
            "[700]\ttrain-mlogloss:1.09341\tval-mlogloss:1.09903\n",
            "[800]\ttrain-mlogloss:1.09083\tval-mlogloss:1.09751\n",
            "[900]\ttrain-mlogloss:1.08853\tval-mlogloss:1.09623\n",
            "[1000]\ttrain-mlogloss:1.08639\tval-mlogloss:1.09517\n",
            "[1100]\ttrain-mlogloss:1.08442\tval-mlogloss:1.09425\n",
            "[1200]\ttrain-mlogloss:1.08256\tval-mlogloss:1.09347\n",
            "[1300]\ttrain-mlogloss:1.08087\tval-mlogloss:1.09280\n",
            "[1400]\ttrain-mlogloss:1.07927\tval-mlogloss:1.09222\n",
            "[1500]\ttrain-mlogloss:1.07774\tval-mlogloss:1.09170\n",
            "[1600]\ttrain-mlogloss:1.07631\tval-mlogloss:1.09130\n",
            "[1700]\ttrain-mlogloss:1.07493\tval-mlogloss:1.09091\n",
            "[1800]\ttrain-mlogloss:1.07361\tval-mlogloss:1.09057\n",
            "[1900]\ttrain-mlogloss:1.07237\tval-mlogloss:1.09024\n",
            "[2000]\ttrain-mlogloss:1.07114\tval-mlogloss:1.08998\n",
            "[2100]\ttrain-mlogloss:1.06997\tval-mlogloss:1.08976\n",
            "[2200]\ttrain-mlogloss:1.06880\tval-mlogloss:1.08961\n",
            "[2300]\ttrain-mlogloss:1.06770\tval-mlogloss:1.08946\n",
            "[2400]\ttrain-mlogloss:1.06663\tval-mlogloss:1.08932\n",
            "[2500]\ttrain-mlogloss:1.06560\tval-mlogloss:1.08922\n",
            "[2600]\ttrain-mlogloss:1.06457\tval-mlogloss:1.08911\n",
            "[2700]\ttrain-mlogloss:1.06359\tval-mlogloss:1.08903\n",
            "[2800]\ttrain-mlogloss:1.06263\tval-mlogloss:1.08899\n",
            "[2900]\ttrain-mlogloss:1.06163\tval-mlogloss:1.08892\n",
            "[3000]\ttrain-mlogloss:1.06072\tval-mlogloss:1.08887\n",
            "[3100]\ttrain-mlogloss:1.05980\tval-mlogloss:1.08883\n",
            "[3200]\ttrain-mlogloss:1.05889\tval-mlogloss:1.08883\n",
            "[3222]\ttrain-mlogloss:1.05867\tval-mlogloss:1.08882\n",
            "[17:19:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-mlogloss:1.38227\tval-mlogloss:1.38227\n",
            "[100]\ttrain-mlogloss:1.17825\tval-mlogloss:1.17858\n",
            "[200]\ttrain-mlogloss:1.12680\tval-mlogloss:1.12767\n",
            "[300]\ttrain-mlogloss:1.11108\tval-mlogloss:1.11271\n",
            "[400]\ttrain-mlogloss:1.10425\tval-mlogloss:1.10673\n",
            "[500]\ttrain-mlogloss:1.09990\tval-mlogloss:1.10334\n",
            "[600]\ttrain-mlogloss:1.09660\tval-mlogloss:1.10106\n",
            "[700]\ttrain-mlogloss:1.09367\tval-mlogloss:1.09916\n",
            "[800]\ttrain-mlogloss:1.09107\tval-mlogloss:1.09762\n",
            "[900]\ttrain-mlogloss:1.08875\tval-mlogloss:1.09631\n",
            "[1000]\ttrain-mlogloss:1.08662\tval-mlogloss:1.09520\n",
            "[1100]\ttrain-mlogloss:1.08462\tval-mlogloss:1.09426\n",
            "[1200]\ttrain-mlogloss:1.08286\tval-mlogloss:1.09344\n",
            "[1300]\ttrain-mlogloss:1.08104\tval-mlogloss:1.09270\n",
            "[1400]\ttrain-mlogloss:1.07939\tval-mlogloss:1.09209\n",
            "[1500]\ttrain-mlogloss:1.07786\tval-mlogloss:1.09156\n",
            "[1600]\ttrain-mlogloss:1.07643\tval-mlogloss:1.09113\n",
            "[1700]\ttrain-mlogloss:1.07502\tval-mlogloss:1.09076\n",
            "[1800]\ttrain-mlogloss:1.07372\tval-mlogloss:1.09041\n",
            "[1900]\ttrain-mlogloss:1.07245\tval-mlogloss:1.09010\n",
            "[2000]\ttrain-mlogloss:1.07126\tval-mlogloss:1.08984\n",
            "[2100]\ttrain-mlogloss:1.07006\tval-mlogloss:1.08962\n",
            "[2200]\ttrain-mlogloss:1.06889\tval-mlogloss:1.08945\n",
            "[2300]\ttrain-mlogloss:1.06777\tval-mlogloss:1.08925\n",
            "[2400]\ttrain-mlogloss:1.06670\tval-mlogloss:1.08911\n",
            "[2500]\ttrain-mlogloss:1.06564\tval-mlogloss:1.08893\n",
            "[2600]\ttrain-mlogloss:1.06462\tval-mlogloss:1.08880\n",
            "[2700]\ttrain-mlogloss:1.06363\tval-mlogloss:1.08873\n",
            "[2800]\ttrain-mlogloss:1.06266\tval-mlogloss:1.08865\n",
            "[2900]\ttrain-mlogloss:1.06168\tval-mlogloss:1.08861\n",
            "[3000]\ttrain-mlogloss:1.06070\tval-mlogloss:1.08858\n",
            "[3100]\ttrain-mlogloss:1.05975\tval-mlogloss:1.08859\n",
            "[3200]\ttrain-mlogloss:1.05884\tval-mlogloss:1.08855\n",
            "[3300]\ttrain-mlogloss:1.05793\tval-mlogloss:1.08855\n",
            "[3400]\ttrain-mlogloss:1.05706\tval-mlogloss:1.08852\n",
            "[3457]\ttrain-mlogloss:1.05658\tval-mlogloss:1.08852\n",
            "[17:20:59] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-mlogloss:1.38222\tval-mlogloss:1.38222\n",
            "[100]\ttrain-mlogloss:1.17800\tval-mlogloss:1.17844\n",
            "[200]\ttrain-mlogloss:1.12680\tval-mlogloss:1.12779\n",
            "[300]\ttrain-mlogloss:1.11104\tval-mlogloss:1.11280\n",
            "[400]\ttrain-mlogloss:1.10415\tval-mlogloss:1.10680\n",
            "[500]\ttrain-mlogloss:1.09971\tval-mlogloss:1.10334\n",
            "[600]\ttrain-mlogloss:1.09633\tval-mlogloss:1.10092\n",
            "[700]\ttrain-mlogloss:1.09344\tval-mlogloss:1.09909\n",
            "[800]\ttrain-mlogloss:1.09087\tval-mlogloss:1.09755\n",
            "[900]\ttrain-mlogloss:1.08852\tval-mlogloss:1.09626\n",
            "[1000]\ttrain-mlogloss:1.08642\tval-mlogloss:1.09517\n",
            "[1100]\ttrain-mlogloss:1.08445\tval-mlogloss:1.09424\n",
            "[1200]\ttrain-mlogloss:1.08260\tval-mlogloss:1.09346\n",
            "[1300]\ttrain-mlogloss:1.08095\tval-mlogloss:1.09276\n",
            "[1400]\ttrain-mlogloss:1.07936\tval-mlogloss:1.09214\n",
            "[1500]\ttrain-mlogloss:1.07786\tval-mlogloss:1.09162\n",
            "[1600]\ttrain-mlogloss:1.07638\tval-mlogloss:1.09116\n",
            "[1700]\ttrain-mlogloss:1.07501\tval-mlogloss:1.09080\n",
            "[1800]\ttrain-mlogloss:1.07370\tval-mlogloss:1.09048\n",
            "[1900]\ttrain-mlogloss:1.07243\tval-mlogloss:1.09019\n",
            "[2000]\ttrain-mlogloss:1.07122\tval-mlogloss:1.08995\n",
            "[2100]\ttrain-mlogloss:1.07003\tval-mlogloss:1.08973\n",
            "[2200]\ttrain-mlogloss:1.06888\tval-mlogloss:1.08951\n",
            "[2300]\ttrain-mlogloss:1.06777\tval-mlogloss:1.08936\n",
            "[2400]\ttrain-mlogloss:1.06668\tval-mlogloss:1.08922\n",
            "[2500]\ttrain-mlogloss:1.06563\tval-mlogloss:1.08909\n",
            "[2600]\ttrain-mlogloss:1.06461\tval-mlogloss:1.08901\n",
            "[2700]\ttrain-mlogloss:1.06357\tval-mlogloss:1.08893\n",
            "[2800]\ttrain-mlogloss:1.06258\tval-mlogloss:1.08888\n",
            "[2900]\ttrain-mlogloss:1.06163\tval-mlogloss:1.08884\n",
            "[3000]\ttrain-mlogloss:1.06067\tval-mlogloss:1.08877\n",
            "[3100]\ttrain-mlogloss:1.05977\tval-mlogloss:1.08874\n",
            "[3200]\ttrain-mlogloss:1.05882\tval-mlogloss:1.08869\n",
            "[3300]\ttrain-mlogloss:1.05788\tval-mlogloss:1.08866\n",
            "[3400]\ttrain-mlogloss:1.05703\tval-mlogloss:1.08865\n",
            "[3500]\ttrain-mlogloss:1.05612\tval-mlogloss:1.08864\n",
            "[3521]\ttrain-mlogloss:1.05594\tval-mlogloss:1.08864\n",
            "fold: 1,log_loss: 1.0886032680421063\n",
            "[17:22:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-mlogloss:1.38228\tval-mlogloss:1.38228\n",
            "[100]\ttrain-mlogloss:1.17792\tval-mlogloss:1.17858\n",
            "[200]\ttrain-mlogloss:1.12639\tval-mlogloss:1.12788\n",
            "[300]\ttrain-mlogloss:1.11039\tval-mlogloss:1.11298\n",
            "[400]\ttrain-mlogloss:1.10344\tval-mlogloss:1.10725\n",
            "[500]\ttrain-mlogloss:1.09911\tval-mlogloss:1.10425\n",
            "[600]\ttrain-mlogloss:1.09562\tval-mlogloss:1.10212\n",
            "[700]\ttrain-mlogloss:1.09264\tval-mlogloss:1.10051\n",
            "[800]\ttrain-mlogloss:1.08997\tval-mlogloss:1.09916\n",
            "[900]\ttrain-mlogloss:1.08762\tval-mlogloss:1.09805\n",
            "[1000]\ttrain-mlogloss:1.08547\tval-mlogloss:1.09716\n",
            "[1100]\ttrain-mlogloss:1.08352\tval-mlogloss:1.09645\n",
            "[1200]\ttrain-mlogloss:1.08160\tval-mlogloss:1.09584\n",
            "[1300]\ttrain-mlogloss:1.07980\tval-mlogloss:1.09534\n",
            "[1400]\ttrain-mlogloss:1.07818\tval-mlogloss:1.09491\n",
            "[1500]\ttrain-mlogloss:1.07661\tval-mlogloss:1.09455\n",
            "[1600]\ttrain-mlogloss:1.07515\tval-mlogloss:1.09426\n",
            "[1700]\ttrain-mlogloss:1.07373\tval-mlogloss:1.09403\n",
            "[1800]\ttrain-mlogloss:1.07237\tval-mlogloss:1.09384\n",
            "[1900]\ttrain-mlogloss:1.07106\tval-mlogloss:1.09367\n",
            "[2000]\ttrain-mlogloss:1.06985\tval-mlogloss:1.09355\n",
            "[2100]\ttrain-mlogloss:1.06866\tval-mlogloss:1.09346\n",
            "[2200]\ttrain-mlogloss:1.06754\tval-mlogloss:1.09340\n",
            "[2300]\ttrain-mlogloss:1.06642\tval-mlogloss:1.09335\n",
            "[2400]\ttrain-mlogloss:1.06531\tval-mlogloss:1.09332\n",
            "[2500]\ttrain-mlogloss:1.06426\tval-mlogloss:1.09329\n",
            "[2600]\ttrain-mlogloss:1.06323\tval-mlogloss:1.09328\n",
            "[2662]\ttrain-mlogloss:1.06257\tval-mlogloss:1.09329\n",
            "[17:23:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-mlogloss:1.38231\tval-mlogloss:1.38231\n",
            "[100]\ttrain-mlogloss:1.17789\tval-mlogloss:1.17855\n",
            "[200]\ttrain-mlogloss:1.12639\tval-mlogloss:1.12789\n",
            "[300]\ttrain-mlogloss:1.11043\tval-mlogloss:1.11300\n",
            "[400]\ttrain-mlogloss:1.10339\tval-mlogloss:1.10728\n",
            "[500]\ttrain-mlogloss:1.09895\tval-mlogloss:1.10417\n",
            "[600]\ttrain-mlogloss:1.09553\tval-mlogloss:1.10211\n",
            "[700]\ttrain-mlogloss:1.09253\tval-mlogloss:1.10048\n",
            "[800]\ttrain-mlogloss:1.08981\tval-mlogloss:1.09914\n",
            "[900]\ttrain-mlogloss:1.08745\tval-mlogloss:1.09808\n",
            "[1000]\ttrain-mlogloss:1.08521\tval-mlogloss:1.09720\n",
            "[1100]\ttrain-mlogloss:1.08323\tval-mlogloss:1.09650\n",
            "[1200]\ttrain-mlogloss:1.08139\tval-mlogloss:1.09590\n",
            "[1300]\ttrain-mlogloss:1.07965\tval-mlogloss:1.09540\n",
            "[1400]\ttrain-mlogloss:1.07801\tval-mlogloss:1.09500\n",
            "[1500]\ttrain-mlogloss:1.07646\tval-mlogloss:1.09463\n",
            "[1600]\ttrain-mlogloss:1.07501\tval-mlogloss:1.09430\n",
            "[1700]\ttrain-mlogloss:1.07361\tval-mlogloss:1.09406\n",
            "[1800]\ttrain-mlogloss:1.07231\tval-mlogloss:1.09387\n",
            "[1900]\ttrain-mlogloss:1.07103\tval-mlogloss:1.09372\n",
            "[2000]\ttrain-mlogloss:1.06984\tval-mlogloss:1.09361\n",
            "[2100]\ttrain-mlogloss:1.06861\tval-mlogloss:1.09351\n",
            "[2200]\ttrain-mlogloss:1.06743\tval-mlogloss:1.09341\n",
            "[2300]\ttrain-mlogloss:1.06632\tval-mlogloss:1.09337\n",
            "[2400]\ttrain-mlogloss:1.06522\tval-mlogloss:1.09334\n",
            "[2500]\ttrain-mlogloss:1.06412\tval-mlogloss:1.09331\n",
            "[2600]\ttrain-mlogloss:1.06310\tval-mlogloss:1.09328\n",
            "[2700]\ttrain-mlogloss:1.06209\tval-mlogloss:1.09329\n",
            "[2704]\ttrain-mlogloss:1.06205\tval-mlogloss:1.09328\n",
            "[17:24:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-mlogloss:1.38227\tval-mlogloss:1.38228\n",
            "[100]\ttrain-mlogloss:1.17807\tval-mlogloss:1.17868\n",
            "[200]\ttrain-mlogloss:1.12652\tval-mlogloss:1.12801\n",
            "[300]\ttrain-mlogloss:1.11053\tval-mlogloss:1.11308\n",
            "[400]\ttrain-mlogloss:1.10351\tval-mlogloss:1.10728\n",
            "[500]\ttrain-mlogloss:1.09906\tval-mlogloss:1.10420\n",
            "[600]\ttrain-mlogloss:1.09568\tval-mlogloss:1.10212\n",
            "[700]\ttrain-mlogloss:1.09267\tval-mlogloss:1.10051\n",
            "[800]\ttrain-mlogloss:1.09003\tval-mlogloss:1.09919\n",
            "[900]\ttrain-mlogloss:1.08768\tval-mlogloss:1.09814\n",
            "[1000]\ttrain-mlogloss:1.08545\tval-mlogloss:1.09726\n",
            "[1100]\ttrain-mlogloss:1.08341\tval-mlogloss:1.09652\n",
            "[1200]\ttrain-mlogloss:1.08156\tval-mlogloss:1.09591\n",
            "[1300]\ttrain-mlogloss:1.07987\tval-mlogloss:1.09539\n",
            "[1400]\ttrain-mlogloss:1.07821\tval-mlogloss:1.09494\n",
            "[1500]\ttrain-mlogloss:1.07660\tval-mlogloss:1.09458\n",
            "[1600]\ttrain-mlogloss:1.07512\tval-mlogloss:1.09428\n",
            "[1700]\ttrain-mlogloss:1.07374\tval-mlogloss:1.09405\n",
            "[1800]\ttrain-mlogloss:1.07239\tval-mlogloss:1.09382\n",
            "[1900]\ttrain-mlogloss:1.07112\tval-mlogloss:1.09364\n",
            "[2000]\ttrain-mlogloss:1.06993\tval-mlogloss:1.09352\n",
            "[2100]\ttrain-mlogloss:1.06871\tval-mlogloss:1.09341\n",
            "[2200]\ttrain-mlogloss:1.06756\tval-mlogloss:1.09328\n",
            "[2300]\ttrain-mlogloss:1.06644\tval-mlogloss:1.09320\n",
            "[2400]\ttrain-mlogloss:1.06534\tval-mlogloss:1.09318\n",
            "[2500]\ttrain-mlogloss:1.06426\tval-mlogloss:1.09317\n",
            "[2600]\ttrain-mlogloss:1.06319\tval-mlogloss:1.09316\n",
            "[2700]\ttrain-mlogloss:1.06215\tval-mlogloss:1.09316\n",
            "[2703]\ttrain-mlogloss:1.06213\tval-mlogloss:1.09316\n",
            "fold: 2,log_loss: 1.093195938907314\n",
            "[17:25:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-mlogloss:1.38230\tval-mlogloss:1.38230\n",
            "[100]\ttrain-mlogloss:1.17819\tval-mlogloss:1.17865\n",
            "[200]\ttrain-mlogloss:1.12681\tval-mlogloss:1.12792\n",
            "[300]\ttrain-mlogloss:1.11099\tval-mlogloss:1.11281\n",
            "[400]\ttrain-mlogloss:1.10420\tval-mlogloss:1.10689\n",
            "[500]\ttrain-mlogloss:1.09986\tval-mlogloss:1.10345\n",
            "[600]\ttrain-mlogloss:1.09651\tval-mlogloss:1.10109\n",
            "[700]\ttrain-mlogloss:1.09359\tval-mlogloss:1.09914\n",
            "[800]\ttrain-mlogloss:1.09104\tval-mlogloss:1.09756\n",
            "[900]\ttrain-mlogloss:1.08875\tval-mlogloss:1.09626\n",
            "[1000]\ttrain-mlogloss:1.08658\tval-mlogloss:1.09509\n",
            "[1100]\ttrain-mlogloss:1.08464\tval-mlogloss:1.09409\n",
            "[1200]\ttrain-mlogloss:1.08283\tval-mlogloss:1.09324\n",
            "[1300]\ttrain-mlogloss:1.08113\tval-mlogloss:1.09253\n",
            "[1400]\ttrain-mlogloss:1.07945\tval-mlogloss:1.09187\n",
            "[1500]\ttrain-mlogloss:1.07797\tval-mlogloss:1.09134\n",
            "[1600]\ttrain-mlogloss:1.07648\tval-mlogloss:1.09089\n",
            "[1700]\ttrain-mlogloss:1.07506\tval-mlogloss:1.09053\n",
            "[1800]\ttrain-mlogloss:1.07372\tval-mlogloss:1.09021\n",
            "[1900]\ttrain-mlogloss:1.07250\tval-mlogloss:1.08988\n",
            "[2000]\ttrain-mlogloss:1.07124\tval-mlogloss:1.08960\n",
            "[2100]\ttrain-mlogloss:1.07012\tval-mlogloss:1.08942\n",
            "[2200]\ttrain-mlogloss:1.06900\tval-mlogloss:1.08922\n",
            "[2300]\ttrain-mlogloss:1.06790\tval-mlogloss:1.08906\n",
            "[2400]\ttrain-mlogloss:1.06682\tval-mlogloss:1.08890\n",
            "[2500]\ttrain-mlogloss:1.06578\tval-mlogloss:1.08877\n",
            "[2600]\ttrain-mlogloss:1.06471\tval-mlogloss:1.08866\n",
            "[2700]\ttrain-mlogloss:1.06367\tval-mlogloss:1.08857\n",
            "[2800]\ttrain-mlogloss:1.06269\tval-mlogloss:1.08848\n",
            "[2900]\ttrain-mlogloss:1.06170\tval-mlogloss:1.08841\n",
            "[3000]\ttrain-mlogloss:1.06072\tval-mlogloss:1.08839\n",
            "[3100]\ttrain-mlogloss:1.05974\tval-mlogloss:1.08833\n",
            "[3200]\ttrain-mlogloss:1.05880\tval-mlogloss:1.08830\n",
            "[3300]\ttrain-mlogloss:1.05787\tval-mlogloss:1.08829\n",
            "[3400]\ttrain-mlogloss:1.05700\tval-mlogloss:1.08826\n",
            "[3500]\ttrain-mlogloss:1.05610\tval-mlogloss:1.08823\n",
            "[3600]\ttrain-mlogloss:1.05521\tval-mlogloss:1.08821\n",
            "[3700]\ttrain-mlogloss:1.05435\tval-mlogloss:1.08820\n",
            "[3751]\ttrain-mlogloss:1.05392\tval-mlogloss:1.08820\n",
            "[17:26:53] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-mlogloss:1.38230\tval-mlogloss:1.38230\n",
            "[100]\ttrain-mlogloss:1.17812\tval-mlogloss:1.17858\n",
            "[200]\ttrain-mlogloss:1.12682\tval-mlogloss:1.12782\n",
            "[300]\ttrain-mlogloss:1.11093\tval-mlogloss:1.11262\n",
            "[400]\ttrain-mlogloss:1.10411\tval-mlogloss:1.10662\n",
            "[500]\ttrain-mlogloss:1.09984\tval-mlogloss:1.10328\n",
            "[600]\ttrain-mlogloss:1.09634\tval-mlogloss:1.10078\n",
            "[700]\ttrain-mlogloss:1.09354\tval-mlogloss:1.09895\n",
            "[800]\ttrain-mlogloss:1.09097\tval-mlogloss:1.09739\n",
            "[900]\ttrain-mlogloss:1.08865\tval-mlogloss:1.09607\n",
            "[1000]\ttrain-mlogloss:1.08651\tval-mlogloss:1.09496\n",
            "[1100]\ttrain-mlogloss:1.08451\tval-mlogloss:1.09394\n",
            "[1200]\ttrain-mlogloss:1.08268\tval-mlogloss:1.09312\n",
            "[1300]\ttrain-mlogloss:1.08098\tval-mlogloss:1.09239\n",
            "[1400]\ttrain-mlogloss:1.07935\tval-mlogloss:1.09180\n",
            "[1500]\ttrain-mlogloss:1.07784\tval-mlogloss:1.09126\n",
            "[1600]\ttrain-mlogloss:1.07641\tval-mlogloss:1.09074\n",
            "[1700]\ttrain-mlogloss:1.07503\tval-mlogloss:1.09036\n",
            "[1800]\ttrain-mlogloss:1.07364\tval-mlogloss:1.08999\n",
            "[1900]\ttrain-mlogloss:1.07232\tval-mlogloss:1.08971\n",
            "[2000]\ttrain-mlogloss:1.07106\tval-mlogloss:1.08942\n",
            "[2100]\ttrain-mlogloss:1.06985\tval-mlogloss:1.08915\n",
            "[2200]\ttrain-mlogloss:1.06866\tval-mlogloss:1.08895\n",
            "[2300]\ttrain-mlogloss:1.06756\tval-mlogloss:1.08879\n",
            "[2400]\ttrain-mlogloss:1.06648\tval-mlogloss:1.08868\n",
            "[2500]\ttrain-mlogloss:1.06540\tval-mlogloss:1.08854\n",
            "[2600]\ttrain-mlogloss:1.06438\tval-mlogloss:1.08845\n",
            "[2700]\ttrain-mlogloss:1.06334\tval-mlogloss:1.08837\n",
            "[2800]\ttrain-mlogloss:1.06236\tval-mlogloss:1.08830\n",
            "[2900]\ttrain-mlogloss:1.06136\tval-mlogloss:1.08822\n",
            "[3000]\ttrain-mlogloss:1.06041\tval-mlogloss:1.08812\n",
            "[3100]\ttrain-mlogloss:1.05944\tval-mlogloss:1.08808\n",
            "[3200]\ttrain-mlogloss:1.05852\tval-mlogloss:1.08805\n",
            "[3300]\ttrain-mlogloss:1.05762\tval-mlogloss:1.08803\n",
            "[3400]\ttrain-mlogloss:1.05673\tval-mlogloss:1.08800\n",
            "[3500]\ttrain-mlogloss:1.05583\tval-mlogloss:1.08802\n",
            "[3528]\ttrain-mlogloss:1.05560\tval-mlogloss:1.08804\n",
            "[17:28:16] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-mlogloss:1.38227\tval-mlogloss:1.38228\n",
            "[100]\ttrain-mlogloss:1.17812\tval-mlogloss:1.17855\n",
            "[200]\ttrain-mlogloss:1.12669\tval-mlogloss:1.12768\n",
            "[300]\ttrain-mlogloss:1.11088\tval-mlogloss:1.11259\n",
            "[400]\ttrain-mlogloss:1.10404\tval-mlogloss:1.10662\n",
            "[500]\ttrain-mlogloss:1.09973\tval-mlogloss:1.10325\n",
            "[600]\ttrain-mlogloss:1.09631\tval-mlogloss:1.10084\n",
            "[700]\ttrain-mlogloss:1.09346\tval-mlogloss:1.09899\n",
            "[800]\ttrain-mlogloss:1.09087\tval-mlogloss:1.09741\n",
            "[900]\ttrain-mlogloss:1.08847\tval-mlogloss:1.09601\n",
            "[1000]\ttrain-mlogloss:1.08638\tval-mlogloss:1.09490\n",
            "[1100]\ttrain-mlogloss:1.08442\tval-mlogloss:1.09391\n",
            "[1200]\ttrain-mlogloss:1.08262\tval-mlogloss:1.09312\n",
            "[1300]\ttrain-mlogloss:1.08096\tval-mlogloss:1.09246\n",
            "[1400]\ttrain-mlogloss:1.07937\tval-mlogloss:1.09186\n",
            "[1500]\ttrain-mlogloss:1.07786\tval-mlogloss:1.09132\n",
            "[1600]\ttrain-mlogloss:1.07640\tval-mlogloss:1.09084\n",
            "[1700]\ttrain-mlogloss:1.07499\tval-mlogloss:1.09041\n",
            "[1800]\ttrain-mlogloss:1.07365\tval-mlogloss:1.09007\n",
            "[1900]\ttrain-mlogloss:1.07236\tval-mlogloss:1.08977\n",
            "[2000]\ttrain-mlogloss:1.07110\tval-mlogloss:1.08951\n",
            "[2100]\ttrain-mlogloss:1.06990\tval-mlogloss:1.08927\n",
            "[2200]\ttrain-mlogloss:1.06877\tval-mlogloss:1.08906\n",
            "[2300]\ttrain-mlogloss:1.06765\tval-mlogloss:1.08891\n",
            "[2400]\ttrain-mlogloss:1.06652\tval-mlogloss:1.08872\n",
            "[2500]\ttrain-mlogloss:1.06548\tval-mlogloss:1.08856\n",
            "[2600]\ttrain-mlogloss:1.06444\tval-mlogloss:1.08845\n",
            "[2700]\ttrain-mlogloss:1.06345\tval-mlogloss:1.08838\n",
            "[2800]\ttrain-mlogloss:1.06248\tval-mlogloss:1.08830\n",
            "[2900]\ttrain-mlogloss:1.06149\tval-mlogloss:1.08822\n",
            "[3000]\ttrain-mlogloss:1.06055\tval-mlogloss:1.08815\n",
            "[3100]\ttrain-mlogloss:1.05959\tval-mlogloss:1.08811\n",
            "[3200]\ttrain-mlogloss:1.05866\tval-mlogloss:1.08810\n",
            "[3300]\ttrain-mlogloss:1.05771\tval-mlogloss:1.08809\n",
            "[3400]\ttrain-mlogloss:1.05680\tval-mlogloss:1.08807\n",
            "[3472]\ttrain-mlogloss:1.05618\tval-mlogloss:1.08807\n",
            "fold: 3,log_loss: 1.0880452967127974\n",
            "[17:29:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-mlogloss:1.38226\tval-mlogloss:1.38226\n",
            "[100]\ttrain-mlogloss:1.17817\tval-mlogloss:1.17858\n",
            "[200]\ttrain-mlogloss:1.12669\tval-mlogloss:1.12769\n",
            "[300]\ttrain-mlogloss:1.11077\tval-mlogloss:1.11253\n",
            "[400]\ttrain-mlogloss:1.10384\tval-mlogloss:1.10647\n",
            "[500]\ttrain-mlogloss:1.09956\tval-mlogloss:1.10317\n",
            "[600]\ttrain-mlogloss:1.09617\tval-mlogloss:1.10086\n",
            "[700]\ttrain-mlogloss:1.09324\tval-mlogloss:1.09900\n",
            "[800]\ttrain-mlogloss:1.09067\tval-mlogloss:1.09746\n",
            "[900]\ttrain-mlogloss:1.08831\tval-mlogloss:1.09615\n",
            "[1000]\ttrain-mlogloss:1.08617\tval-mlogloss:1.09510\n",
            "[1100]\ttrain-mlogloss:1.08418\tval-mlogloss:1.09418\n",
            "[1200]\ttrain-mlogloss:1.08235\tval-mlogloss:1.09347\n",
            "[1300]\ttrain-mlogloss:1.08060\tval-mlogloss:1.09283\n",
            "[1400]\ttrain-mlogloss:1.07899\tval-mlogloss:1.09225\n",
            "[1500]\ttrain-mlogloss:1.07746\tval-mlogloss:1.09173\n",
            "[1600]\ttrain-mlogloss:1.07604\tval-mlogloss:1.09135\n",
            "[1700]\ttrain-mlogloss:1.07467\tval-mlogloss:1.09103\n",
            "[1800]\ttrain-mlogloss:1.07331\tval-mlogloss:1.09074\n",
            "[1900]\ttrain-mlogloss:1.07202\tval-mlogloss:1.09046\n",
            "[2000]\ttrain-mlogloss:1.07077\tval-mlogloss:1.09028\n",
            "[2100]\ttrain-mlogloss:1.06960\tval-mlogloss:1.09008\n",
            "[2200]\ttrain-mlogloss:1.06844\tval-mlogloss:1.08993\n",
            "[2300]\ttrain-mlogloss:1.06733\tval-mlogloss:1.08980\n",
            "[2400]\ttrain-mlogloss:1.06627\tval-mlogloss:1.08970\n",
            "[2500]\ttrain-mlogloss:1.06519\tval-mlogloss:1.08961\n",
            "[2600]\ttrain-mlogloss:1.06415\tval-mlogloss:1.08953\n",
            "[2700]\ttrain-mlogloss:1.06313\tval-mlogloss:1.08946\n",
            "[2800]\ttrain-mlogloss:1.06211\tval-mlogloss:1.08945\n",
            "[2900]\ttrain-mlogloss:1.06112\tval-mlogloss:1.08941\n",
            "[3000]\ttrain-mlogloss:1.06014\tval-mlogloss:1.08936\n",
            "[3100]\ttrain-mlogloss:1.05921\tval-mlogloss:1.08933\n",
            "[3200]\ttrain-mlogloss:1.05829\tval-mlogloss:1.08932\n",
            "[3300]\ttrain-mlogloss:1.05737\tval-mlogloss:1.08931\n",
            "[3325]\ttrain-mlogloss:1.05714\tval-mlogloss:1.08933\n",
            "[17:30:55] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-mlogloss:1.38230\tval-mlogloss:1.38232\n",
            "[100]\ttrain-mlogloss:1.17812\tval-mlogloss:1.17852\n",
            "[200]\ttrain-mlogloss:1.12678\tval-mlogloss:1.12772\n",
            "[300]\ttrain-mlogloss:1.11095\tval-mlogloss:1.11268\n",
            "[400]\ttrain-mlogloss:1.10400\tval-mlogloss:1.10666\n",
            "[500]\ttrain-mlogloss:1.09966\tval-mlogloss:1.10329\n",
            "[600]\ttrain-mlogloss:1.09623\tval-mlogloss:1.10091\n",
            "[700]\ttrain-mlogloss:1.09329\tval-mlogloss:1.09909\n",
            "[800]\ttrain-mlogloss:1.09066\tval-mlogloss:1.09755\n",
            "[900]\ttrain-mlogloss:1.08826\tval-mlogloss:1.09625\n",
            "[1000]\ttrain-mlogloss:1.08613\tval-mlogloss:1.09515\n",
            "[1100]\ttrain-mlogloss:1.08410\tval-mlogloss:1.09426\n",
            "[1200]\ttrain-mlogloss:1.08222\tval-mlogloss:1.09343\n",
            "[1300]\ttrain-mlogloss:1.08053\tval-mlogloss:1.09279\n",
            "[1400]\ttrain-mlogloss:1.07893\tval-mlogloss:1.09224\n",
            "[1500]\ttrain-mlogloss:1.07736\tval-mlogloss:1.09173\n",
            "[1600]\ttrain-mlogloss:1.07587\tval-mlogloss:1.09132\n",
            "[1700]\ttrain-mlogloss:1.07449\tval-mlogloss:1.09097\n",
            "[1800]\ttrain-mlogloss:1.07317\tval-mlogloss:1.09067\n",
            "[1900]\ttrain-mlogloss:1.07189\tval-mlogloss:1.09042\n",
            "[2000]\ttrain-mlogloss:1.07067\tval-mlogloss:1.09017\n",
            "[2100]\ttrain-mlogloss:1.06949\tval-mlogloss:1.08997\n",
            "[2200]\ttrain-mlogloss:1.06834\tval-mlogloss:1.08978\n",
            "[2300]\ttrain-mlogloss:1.06723\tval-mlogloss:1.08965\n",
            "[2400]\ttrain-mlogloss:1.06611\tval-mlogloss:1.08956\n",
            "[2500]\ttrain-mlogloss:1.06502\tval-mlogloss:1.08943\n",
            "[2600]\ttrain-mlogloss:1.06394\tval-mlogloss:1.08937\n",
            "[2700]\ttrain-mlogloss:1.06293\tval-mlogloss:1.08932\n",
            "[2800]\ttrain-mlogloss:1.06193\tval-mlogloss:1.08929\n",
            "[2900]\ttrain-mlogloss:1.06094\tval-mlogloss:1.08927\n",
            "[2979]\ttrain-mlogloss:1.06020\tval-mlogloss:1.08929\n",
            "[17:32:04] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-mlogloss:1.38228\tval-mlogloss:1.38229\n",
            "[100]\ttrain-mlogloss:1.17814\tval-mlogloss:1.17854\n",
            "[200]\ttrain-mlogloss:1.12683\tval-mlogloss:1.12775\n",
            "[300]\ttrain-mlogloss:1.11097\tval-mlogloss:1.11263\n",
            "[400]\ttrain-mlogloss:1.10411\tval-mlogloss:1.10670\n",
            "[500]\ttrain-mlogloss:1.09985\tval-mlogloss:1.10340\n",
            "[600]\ttrain-mlogloss:1.09637\tval-mlogloss:1.10102\n",
            "[700]\ttrain-mlogloss:1.09337\tval-mlogloss:1.09913\n",
            "[800]\ttrain-mlogloss:1.09074\tval-mlogloss:1.09756\n",
            "[900]\ttrain-mlogloss:1.08836\tval-mlogloss:1.09627\n",
            "[1000]\ttrain-mlogloss:1.08618\tval-mlogloss:1.09520\n",
            "[1100]\ttrain-mlogloss:1.08416\tval-mlogloss:1.09430\n",
            "[1200]\ttrain-mlogloss:1.08229\tval-mlogloss:1.09352\n",
            "[1300]\ttrain-mlogloss:1.08057\tval-mlogloss:1.09290\n",
            "[1400]\ttrain-mlogloss:1.07892\tval-mlogloss:1.09232\n",
            "[1500]\ttrain-mlogloss:1.07740\tval-mlogloss:1.09186\n",
            "[1600]\ttrain-mlogloss:1.07592\tval-mlogloss:1.09142\n",
            "[1700]\ttrain-mlogloss:1.07456\tval-mlogloss:1.09108\n",
            "[1800]\ttrain-mlogloss:1.07324\tval-mlogloss:1.09075\n",
            "[1900]\ttrain-mlogloss:1.07192\tval-mlogloss:1.09051\n",
            "[2000]\ttrain-mlogloss:1.07071\tval-mlogloss:1.09033\n",
            "[2100]\ttrain-mlogloss:1.06952\tval-mlogloss:1.09013\n",
            "[2200]\ttrain-mlogloss:1.06835\tval-mlogloss:1.08996\n",
            "[2300]\ttrain-mlogloss:1.06723\tval-mlogloss:1.08981\n",
            "[2400]\ttrain-mlogloss:1.06611\tval-mlogloss:1.08969\n",
            "[2500]\ttrain-mlogloss:1.06505\tval-mlogloss:1.08957\n",
            "[2600]\ttrain-mlogloss:1.06398\tval-mlogloss:1.08952\n",
            "[2700]\ttrain-mlogloss:1.06296\tval-mlogloss:1.08947\n",
            "[2800]\ttrain-mlogloss:1.06194\tval-mlogloss:1.08940\n",
            "[2900]\ttrain-mlogloss:1.06096\tval-mlogloss:1.08937\n",
            "[3000]\ttrain-mlogloss:1.06003\tval-mlogloss:1.08935\n",
            "[3100]\ttrain-mlogloss:1.05906\tval-mlogloss:1.08934\n",
            "[3200]\ttrain-mlogloss:1.05816\tval-mlogloss:1.08933\n",
            "[3300]\ttrain-mlogloss:1.05725\tval-mlogloss:1.08931\n",
            "[3390]\ttrain-mlogloss:1.05642\tval-mlogloss:1.08933\n",
            "fold: 4,log_loss: 1.0892551404672641\n",
            "[17:33:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-mlogloss:1.38228\tval-mlogloss:1.38229\n",
            "[100]\ttrain-mlogloss:1.17811\tval-mlogloss:1.17850\n",
            "[200]\ttrain-mlogloss:1.12661\tval-mlogloss:1.12760\n",
            "[300]\ttrain-mlogloss:1.11082\tval-mlogloss:1.11261\n",
            "[400]\ttrain-mlogloss:1.10385\tval-mlogloss:1.10659\n",
            "[500]\ttrain-mlogloss:1.09945\tval-mlogloss:1.10328\n",
            "[600]\ttrain-mlogloss:1.09595\tval-mlogloss:1.10091\n",
            "[700]\ttrain-mlogloss:1.09303\tval-mlogloss:1.09911\n",
            "[800]\ttrain-mlogloss:1.09042\tval-mlogloss:1.09764\n",
            "[900]\ttrain-mlogloss:1.08803\tval-mlogloss:1.09645\n",
            "[1000]\ttrain-mlogloss:1.08582\tval-mlogloss:1.09541\n",
            "[1100]\ttrain-mlogloss:1.08387\tval-mlogloss:1.09458\n",
            "[1200]\ttrain-mlogloss:1.08206\tval-mlogloss:1.09386\n",
            "[1300]\ttrain-mlogloss:1.08034\tval-mlogloss:1.09323\n",
            "[1400]\ttrain-mlogloss:1.07872\tval-mlogloss:1.09271\n",
            "[1500]\ttrain-mlogloss:1.07715\tval-mlogloss:1.09223\n",
            "[1600]\ttrain-mlogloss:1.07565\tval-mlogloss:1.09188\n",
            "[1700]\ttrain-mlogloss:1.07430\tval-mlogloss:1.09157\n",
            "[1800]\ttrain-mlogloss:1.07292\tval-mlogloss:1.09128\n",
            "[1900]\ttrain-mlogloss:1.07165\tval-mlogloss:1.09108\n",
            "[2000]\ttrain-mlogloss:1.07039\tval-mlogloss:1.09091\n",
            "[2100]\ttrain-mlogloss:1.06919\tval-mlogloss:1.09074\n",
            "[2200]\ttrain-mlogloss:1.06801\tval-mlogloss:1.09061\n",
            "[2300]\ttrain-mlogloss:1.06687\tval-mlogloss:1.09051\n",
            "[2400]\ttrain-mlogloss:1.06578\tval-mlogloss:1.09041\n",
            "[2500]\ttrain-mlogloss:1.06469\tval-mlogloss:1.09037\n",
            "[2600]\ttrain-mlogloss:1.06363\tval-mlogloss:1.09036\n",
            "[2700]\ttrain-mlogloss:1.06264\tval-mlogloss:1.09029\n",
            "[2800]\ttrain-mlogloss:1.06165\tval-mlogloss:1.09031\n",
            "[2802]\ttrain-mlogloss:1.06163\tval-mlogloss:1.09031\n",
            "[17:34:29] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-mlogloss:1.38225\tval-mlogloss:1.38226\n",
            "[100]\ttrain-mlogloss:1.17797\tval-mlogloss:1.17841\n",
            "[200]\ttrain-mlogloss:1.12654\tval-mlogloss:1.12750\n",
            "[300]\ttrain-mlogloss:1.11071\tval-mlogloss:1.11244\n",
            "[400]\ttrain-mlogloss:1.10387\tval-mlogloss:1.10649\n",
            "[500]\ttrain-mlogloss:1.09953\tval-mlogloss:1.10320\n",
            "[600]\ttrain-mlogloss:1.09613\tval-mlogloss:1.10087\n",
            "[700]\ttrain-mlogloss:1.09311\tval-mlogloss:1.09908\n",
            "[800]\ttrain-mlogloss:1.09053\tval-mlogloss:1.09766\n",
            "[900]\ttrain-mlogloss:1.08819\tval-mlogloss:1.09648\n",
            "[1000]\ttrain-mlogloss:1.08599\tval-mlogloss:1.09545\n",
            "[1100]\ttrain-mlogloss:1.08395\tval-mlogloss:1.09457\n",
            "[1200]\ttrain-mlogloss:1.08214\tval-mlogloss:1.09384\n",
            "[1300]\ttrain-mlogloss:1.08040\tval-mlogloss:1.09323\n",
            "[1400]\ttrain-mlogloss:1.07880\tval-mlogloss:1.09272\n",
            "[1500]\ttrain-mlogloss:1.07722\tval-mlogloss:1.09224\n",
            "[1600]\ttrain-mlogloss:1.07576\tval-mlogloss:1.09187\n",
            "[1700]\ttrain-mlogloss:1.07437\tval-mlogloss:1.09158\n",
            "[1800]\ttrain-mlogloss:1.07305\tval-mlogloss:1.09129\n",
            "[1900]\ttrain-mlogloss:1.07174\tval-mlogloss:1.09105\n",
            "[2000]\ttrain-mlogloss:1.07052\tval-mlogloss:1.09089\n",
            "[2100]\ttrain-mlogloss:1.06934\tval-mlogloss:1.09071\n",
            "[2200]\ttrain-mlogloss:1.06818\tval-mlogloss:1.09058\n",
            "[2300]\ttrain-mlogloss:1.06706\tval-mlogloss:1.09050\n",
            "[2400]\ttrain-mlogloss:1.06597\tval-mlogloss:1.09041\n",
            "[2500]\ttrain-mlogloss:1.06487\tval-mlogloss:1.09033\n",
            "[2600]\ttrain-mlogloss:1.06383\tval-mlogloss:1.09029\n",
            "[2700]\ttrain-mlogloss:1.06280\tval-mlogloss:1.09025\n",
            "[2800]\ttrain-mlogloss:1.06181\tval-mlogloss:1.09023\n",
            "[2900]\ttrain-mlogloss:1.06085\tval-mlogloss:1.09023\n",
            "[2922]\ttrain-mlogloss:1.06064\tval-mlogloss:1.09024\n",
            "[17:35:36] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-mlogloss:1.38227\tval-mlogloss:1.38227\n",
            "[100]\ttrain-mlogloss:1.17808\tval-mlogloss:1.17842\n",
            "[200]\ttrain-mlogloss:1.12678\tval-mlogloss:1.12772\n",
            "[300]\ttrain-mlogloss:1.11083\tval-mlogloss:1.11260\n",
            "[400]\ttrain-mlogloss:1.10392\tval-mlogloss:1.10666\n",
            "[500]\ttrain-mlogloss:1.09955\tval-mlogloss:1.10335\n",
            "[600]\ttrain-mlogloss:1.09616\tval-mlogloss:1.10112\n",
            "[700]\ttrain-mlogloss:1.09313\tval-mlogloss:1.09927\n",
            "[800]\ttrain-mlogloss:1.09051\tval-mlogloss:1.09778\n",
            "[900]\ttrain-mlogloss:1.08817\tval-mlogloss:1.09657\n",
            "[1000]\ttrain-mlogloss:1.08604\tval-mlogloss:1.09553\n",
            "[1100]\ttrain-mlogloss:1.08405\tval-mlogloss:1.09463\n",
            "[1200]\ttrain-mlogloss:1.08220\tval-mlogloss:1.09388\n",
            "[1300]\ttrain-mlogloss:1.08052\tval-mlogloss:1.09327\n",
            "[1400]\ttrain-mlogloss:1.07889\tval-mlogloss:1.09271\n",
            "[1500]\ttrain-mlogloss:1.07734\tval-mlogloss:1.09226\n",
            "[1600]\ttrain-mlogloss:1.07595\tval-mlogloss:1.09192\n",
            "[1700]\ttrain-mlogloss:1.07452\tval-mlogloss:1.09155\n",
            "[1800]\ttrain-mlogloss:1.07316\tval-mlogloss:1.09129\n",
            "[1900]\ttrain-mlogloss:1.07183\tval-mlogloss:1.09102\n",
            "[2000]\ttrain-mlogloss:1.07061\tval-mlogloss:1.09084\n",
            "[2100]\ttrain-mlogloss:1.06949\tval-mlogloss:1.09069\n",
            "[2200]\ttrain-mlogloss:1.06833\tval-mlogloss:1.09059\n",
            "[2300]\ttrain-mlogloss:1.06715\tval-mlogloss:1.09046\n",
            "[2400]\ttrain-mlogloss:1.06604\tval-mlogloss:1.09037\n",
            "[2500]\ttrain-mlogloss:1.06498\tval-mlogloss:1.09033\n",
            "[2600]\ttrain-mlogloss:1.06396\tval-mlogloss:1.09026\n",
            "[2700]\ttrain-mlogloss:1.06297\tval-mlogloss:1.09024\n",
            "[2800]\ttrain-mlogloss:1.06196\tval-mlogloss:1.09019\n",
            "[2900]\ttrain-mlogloss:1.06098\tval-mlogloss:1.09016\n",
            "[3000]\ttrain-mlogloss:1.06001\tval-mlogloss:1.09015\n",
            "[3100]\ttrain-mlogloss:1.05905\tval-mlogloss:1.09017\n",
            "[3121]\ttrain-mlogloss:1.05885\tval-mlogloss:1.09016\n",
            "fold: 5,log_loss: 1.0901800111292155\n",
            "xgboost_3seeds_5fold ,log_loss: 1.0898559310517395\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1a8edcfa-9ccb-401d-b649-40ce1cd6f1ad\", \"xgboost_3seeds_5fold_oof.txt\", 3200161)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_ab4aef82-8c38-4630-b0b6-4fa10bd6dea6\", \"xgboost_3seeds_5fold_test.csv\", 4260959)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F66lK6p6P045"
      },
      "source": [
        "# XGBoost Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOj-B9m1NaoO"
      },
      "source": [
        "X = df_all.drop(labels=['id','target'],axis=1,inplace=False).copy()\n",
        "y = df_all['target'].map({\"Class_1\":0,\"Class_2\":1,\"Class_3\":2,\"Class_4\":3}).values\n",
        "X_test = df_test.drop(labels=['id'],axis=1,inplace=False).copy()\n",
        "random_seed = 0\n",
        "\n",
        "encoder = OrdinalEncoder()\n",
        "all_encoded = encoder.fit_transform(X.append(X_test))\n",
        "X = all_encoded[0:len(X)]\n",
        "X_test = all_encoded[len(X):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP-UBgYTP9U9"
      },
      "source": [
        "# for the fixed learning rate, use the opt n iterations and tune the tree hyperparameters\n",
        "def objective(trial,data=X,target=y):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  param_space = { \n",
        "               'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
        "                'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
        "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 0.9),\n",
        "                'colsample_bynode': trial.suggest_float('colsample_bynode', 0.1, 0.9),\n",
        "                'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.1, 0.9),\n",
        "                'subsample': trial.suggest_float('subsample', 0.1, 0.9),\n",
        "                'eta':trial.suggest_float('eta', 1e-2, 1e-2),\n",
        "                'grow_policy': trial.suggest_categorical(\"grow_policy\", ['depthwise','lossguide']),\n",
        "                'max_depth': trial.suggest_int('max_depth',2,25),\n",
        "                'seed': 0,\n",
        "                'min_child_weight': trial.suggest_int('min_child_weight', 0, 300),\n",
        "                'max_bin': trial.suggest_int('max_bin', 256, 512),\n",
        "                'deterministic_histogram':trial.suggest_categorical('deterministic_histogram',[False]),\n",
        "                \"tree_method\" : \"gpu_hist\",\n",
        "                \"predictor\" : 'gpu_predictor',\n",
        "                \"objective\" : 'multi:softprob',\n",
        "                 \"num_class\":4\n",
        "                }\n",
        "            \n",
        "  #X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=.1,random_state=2021,stratify=y)\n",
        "  k=5\n",
        "  seed_list=[0]\n",
        "  kf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\n",
        "  oof = np.zeros((len(df_all),4))\n",
        "  score_list = []\n",
        "  fold=1\n",
        "  \n",
        "  splits = list(kf.split(X,y))\n",
        "  for train_idx, val_idx in splits:\n",
        "    X_train, X_val = X[train_idx,:], X[val_idx,:]\n",
        "    y_train, y_val = y[train_idx], y[val_idx]\n",
        "  \n",
        "    val_preds_list = []\n",
        "  \n",
        "    for seed in seed_list:\n",
        "      # fit and run model\n",
        "      param_space['seed'] = seed\n",
        "      dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
        "      dval = xgb.DMatrix(data=X_val, label=y_val)\n",
        "      dtest = xgb.DMatrix(data=X_test)\n",
        "      xgb.set_config(verbosity=0)\n",
        "\n",
        "      \n",
        "      model = xgb.train(param_space, dtrain,\\\n",
        "                       evals=[(dtrain,'train'),(dval,'val')],\\\n",
        "                       verbose_eval=False,\n",
        "                       early_stopping_rounds=100,\n",
        "                       num_boost_round=100000)\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "      val_preds_list.append(model.predict(dval))\n",
        "     #test_preds_list.append(model.predict_proba(X_test)[:,1])\n",
        "    \n",
        "    oof[val_idx] = np.mean(val_preds_list,axis=0)\n",
        "    score = log_loss(y_val, oof[val_idx])\n",
        "    #print(f\"fold: {fold},logloss: {score}\")\n",
        "    score_list.append(score)\n",
        "    fold +=1\n",
        "  \n",
        "  cv_logloss = np.mean(score_list)\n",
        "  \n",
        "  return cv_logloss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd2a6BOsQ4_a",
        "outputId": "2e34f5fe-305d-4f2b-80f1-c0558ba12534"
      },
      "source": [
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective,n_trials= 30)\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:', study.best_trial.params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-23 05:00:20,778]\u001b[0m A new study created in memory with name: no-name-e60db3ba-ce7c-4f56-bd84-5f8d0c47fce7\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 05:08:05,253]\u001b[0m Trial 0 finished with value: 1.0923741059530983 and parameters: {'lambda': 0.06661146995477027, 'alpha': 0.07848005248610329, 'colsample_bytree': 0.341013686587177, 'colsample_bynode': 0.5247363715016623, 'colsample_bylevel': 0.5698965984910002, 'subsample': 0.8495747203059043, 'eta': 0.01, 'grow_policy': 'depthwise', 'max_depth': 21, 'min_child_weight': 239, 'max_bin': 430, 'deterministic_histogram': False}. Best is trial 0 with value: 1.0923741059530983.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 05:53:46,229]\u001b[0m Trial 1 finished with value: 1.0912136118507059 and parameters: {'lambda': 0.15140190027219924, 'alpha': 1.7842160095709958, 'colsample_bytree': 0.30377579151729056, 'colsample_bynode': 0.5337136888830134, 'colsample_bylevel': 0.8068372064038368, 'subsample': 0.8130822433645674, 'eta': 0.01, 'grow_policy': 'lossguide', 'max_depth': 25, 'min_child_weight': 83, 'max_bin': 481, 'deterministic_histogram': False}. Best is trial 1 with value: 1.0912136118507059.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 05:56:46,224]\u001b[0m Trial 2 finished with value: 1.0921702366535428 and parameters: {'lambda': 0.0068863467893665745, 'alpha': 0.004300442295039011, 'colsample_bytree': 0.6373262342020116, 'colsample_bynode': 0.7881886446955088, 'colsample_bylevel': 0.8394300818324578, 'subsample': 0.7914084474418107, 'eta': 0.01, 'grow_policy': 'depthwise', 'max_depth': 12, 'min_child_weight': 139, 'max_bin': 422, 'deterministic_histogram': False}. Best is trial 1 with value: 1.0912136118507059.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 06:01:48,557]\u001b[0m Trial 3 finished with value: 1.0918291987385285 and parameters: {'lambda': 5.738547890295849, 'alpha': 4.075524501105578, 'colsample_bytree': 0.775028517278754, 'colsample_bynode': 0.2833330459408179, 'colsample_bylevel': 0.29801750988437015, 'subsample': 0.8218379611919294, 'eta': 0.01, 'grow_policy': 'depthwise', 'max_depth': 20, 'min_child_weight': 171, 'max_bin': 299, 'deterministic_histogram': False}. Best is trial 1 with value: 1.0912136118507059.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 06:33:52,454]\u001b[0m Trial 4 finished with value: 1.093014340607533 and parameters: {'lambda': 2.5860281881899256, 'alpha': 0.00400336795315287, 'colsample_bytree': 0.6872000466029804, 'colsample_bynode': 0.27706501022232344, 'colsample_bylevel': 0.5905812069754144, 'subsample': 0.7022304742523157, 'eta': 0.01, 'grow_policy': 'depthwise', 'max_depth': 25, 'min_child_weight': 15, 'max_bin': 476, 'deterministic_histogram': False}. Best is trial 1 with value: 1.0912136118507059.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 06:36:34,071]\u001b[0m Trial 5 finished with value: 1.0923668871762053 and parameters: {'lambda': 0.021510298041984743, 'alpha': 0.635104262655444, 'colsample_bytree': 0.6255640649036491, 'colsample_bynode': 0.292339471001569, 'colsample_bylevel': 0.7999750772730241, 'subsample': 0.2716744319789034, 'eta': 0.01, 'grow_policy': 'lossguide', 'max_depth': 9, 'min_child_weight': 249, 'max_bin': 375, 'deterministic_histogram': False}. Best is trial 1 with value: 1.0912136118507059.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 06:45:53,272]\u001b[0m Trial 6 finished with value: 1.0933590329019842 and parameters: {'lambda': 0.00843587087742431, 'alpha': 0.004971126764443037, 'colsample_bytree': 0.3744614548123365, 'colsample_bynode': 0.2704106758201017, 'colsample_bylevel': 0.2000443063065344, 'subsample': 0.8210810592701447, 'eta': 0.01, 'grow_policy': 'depthwise', 'max_depth': 13, 'min_child_weight': 210, 'max_bin': 387, 'deterministic_histogram': False}. Best is trial 1 with value: 1.0912136118507059.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 06:49:20,803]\u001b[0m Trial 7 finished with value: 1.0915419622885707 and parameters: {'lambda': 0.004324066812865189, 'alpha': 0.007237379394144321, 'colsample_bytree': 0.8184394216764408, 'colsample_bynode': 0.4282393687815439, 'colsample_bylevel': 0.298675900361844, 'subsample': 0.7357423141411585, 'eta': 0.01, 'grow_policy': 'lossguide', 'max_depth': 8, 'min_child_weight': 98, 'max_bin': 394, 'deterministic_histogram': False}. Best is trial 1 with value: 1.0912136118507059.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 06:55:35,560]\u001b[0m Trial 8 finished with value: 1.0915409502402094 and parameters: {'lambda': 0.033998699177614326, 'alpha': 0.028095945754983462, 'colsample_bytree': 0.23418885955388316, 'colsample_bynode': 0.10895215623127381, 'colsample_bylevel': 0.11886494133070738, 'subsample': 0.40329611676746235, 'eta': 0.01, 'grow_policy': 'depthwise', 'max_depth': 13, 'min_child_weight': 46, 'max_bin': 284, 'deterministic_histogram': False}. Best is trial 1 with value: 1.0912136118507059.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 06:58:39,351]\u001b[0m Trial 9 finished with value: 1.091560542866003 and parameters: {'lambda': 2.9804595310624133, 'alpha': 0.0034697866194672226, 'colsample_bytree': 0.6909674605494133, 'colsample_bynode': 0.847780352249378, 'colsample_bylevel': 0.2574222382773479, 'subsample': 0.22518311268249855, 'eta': 0.01, 'grow_policy': 'depthwise', 'max_depth': 18, 'min_child_weight': 59, 'max_bin': 494, 'deterministic_histogram': False}. Best is trial 1 with value: 1.0912136118507059.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 07:05:43,384]\u001b[0m Trial 10 finished with value: 1.0918240362134102 and parameters: {'lambda': 0.3827161552202403, 'alpha': 1.9996811055137431, 'colsample_bytree': 0.10506575929401762, 'colsample_bynode': 0.6534266871922751, 'colsample_bylevel': 0.7264514204563008, 'subsample': 0.5547158102827924, 'eta': 0.01, 'grow_policy': 'lossguide', 'max_depth': 3, 'min_child_weight': 115, 'max_bin': 503, 'deterministic_histogram': False}. Best is trial 1 with value: 1.0912136118507059.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 07:11:40,972]\u001b[0m Trial 11 finished with value: 1.0909226246044361 and parameters: {'lambda': 0.21088904905702896, 'alpha': 0.06972556713418118, 'colsample_bytree': 0.13452417452891222, 'colsample_bynode': 0.10516667165834055, 'colsample_bylevel': 0.42614794530854494, 'subsample': 0.4238949955735059, 'eta': 0.01, 'grow_policy': 'lossguide', 'max_depth': 16, 'min_child_weight': 3, 'max_bin': 276, 'deterministic_histogram': False}. Best is trial 11 with value: 1.0909226246044361.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 09:51:31,154]\u001b[0m Trial 12 finished with value: 1.0904356388492278 and parameters: {'lambda': 0.368597410615471, 'alpha': 0.3670142886668136, 'colsample_bytree': 0.10533230021217582, 'colsample_bynode': 0.5707965407842658, 'colsample_bylevel': 0.4489374238328876, 'subsample': 0.5327720958387568, 'eta': 0.01, 'grow_policy': 'lossguide', 'max_depth': 25, 'min_child_weight': 11, 'max_bin': 329, 'deterministic_histogram': False}. Best is trial 12 with value: 1.0904356388492278.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 09:57:31,729]\u001b[0m Trial 13 finished with value: 1.090429475844946 and parameters: {'lambda': 0.557560270590317, 'alpha': 0.2297975645020217, 'colsample_bytree': 0.11200754097415926, 'colsample_bynode': 0.6902832824017952, 'colsample_bylevel': 0.4209586572479429, 'subsample': 0.5393288036868922, 'eta': 0.01, 'grow_policy': 'lossguide', 'max_depth': 17, 'min_child_weight': 12, 'max_bin': 325, 'deterministic_histogram': False}. Best is trial 13 with value: 1.090429475844946.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 10:14:49,797]\u001b[0m Trial 14 finished with value: 1.0930884786622497 and parameters: {'lambda': 0.7552638810094825, 'alpha': 0.4279675058667481, 'colsample_bytree': 0.4877925151990184, 'colsample_bynode': 0.6970272416410941, 'colsample_bylevel': 0.42450676892883843, 'subsample': 0.5750003531471143, 'eta': 0.01, 'grow_policy': 'lossguide', 'max_depth': 23, 'min_child_weight': 9, 'max_bin': 331, 'deterministic_histogram': False}. Best is trial 13 with value: 1.090429475844946.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 10:21:48,704]\u001b[0m Trial 15 finished with value: 1.0907170469862326 and parameters: {'lambda': 0.7189039569325926, 'alpha': 0.34713075410674554, 'colsample_bytree': 0.17117665312498243, 'colsample_bynode': 0.6612204919177666, 'colsample_bylevel': 0.4595556637559996, 'subsample': 0.6325763940742035, 'eta': 0.01, 'grow_policy': 'lossguide', 'max_depth': 17, 'min_child_weight': 41, 'max_bin': 334, 'deterministic_histogram': False}. Best is trial 13 with value: 1.090429475844946.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 10:25:52,052]\u001b[0m Trial 16 finished with value: 1.09146435828228 and parameters: {'lambda': 1.1394709129308302, 'alpha': 0.21763129014722718, 'colsample_bytree': 0.46491079511739564, 'colsample_bynode': 0.7526006802357199, 'colsample_bylevel': 0.5912685670548745, 'subsample': 0.4275219072392647, 'eta': 0.01, 'grow_policy': 'lossguide', 'max_depth': 2, 'min_child_weight': 7, 'max_bin': 325, 'deterministic_histogram': False}. Best is trial 13 with value: 1.090429475844946.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 10:48:54,920]\u001b[0m Trial 17 finished with value: 1.0993670680854981 and parameters: {'lambda': 0.0012377076777001239, 'alpha': 7.565850147877658, 'colsample_bytree': 0.2448387089250258, 'colsample_bynode': 0.592827645142807, 'colsample_bylevel': 0.3714471574751909, 'subsample': 0.10501824256618408, 'eta': 0.01, 'grow_policy': 'lossguide', 'max_depth': 21, 'min_child_weight': 291, 'max_bin': 260, 'deterministic_histogram': False}. Best is trial 13 with value: 1.090429475844946.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 10:55:39,699]\u001b[0m Trial 18 finished with value: 1.0917577608365976 and parameters: {'lambda': 0.08219747173790856, 'alpha': 0.03185698375322278, 'colsample_bytree': 0.18518181929713695, 'colsample_bynode': 0.4000983852838869, 'colsample_bylevel': 0.5249993121986806, 'subsample': 0.5069734769271637, 'eta': 0.01, 'grow_policy': 'lossguide', 'max_depth': 7, 'min_child_weight': 69, 'max_bin': 355, 'deterministic_histogram': False}. Best is trial 13 with value: 1.090429475844946.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 12:50:58,794]\u001b[0m Trial 19 finished with value: 1.0900543064603903 and parameters: {'lambda': 8.92790949392708, 'alpha': 1.6473197977653538, 'colsample_bytree': 0.10071072582408166, 'colsample_bynode': 0.8501812115656513, 'colsample_bylevel': 0.6676915198851845, 'subsample': 0.323509327667382, 'eta': 0.01, 'grow_policy': 'lossguide', 'max_depth': 25, 'min_child_weight': 35, 'max_bin': 307, 'deterministic_histogram': False}. Best is trial 19 with value: 1.0900543064603903.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 12:53:43,083]\u001b[0m Trial 20 finished with value: 1.092650591979235 and parameters: {'lambda': 9.539915719251317, 'alpha': 1.154293550392285, 'colsample_bytree': 0.8972084764061892, 'colsample_bynode': 0.887591444806768, 'colsample_bylevel': 0.6908179353939521, 'subsample': 0.32115797676582536, 'eta': 0.01, 'grow_policy': 'lossguide', 'max_depth': 15, 'min_child_weight': 166, 'max_bin': 303, 'deterministic_histogram': False}. Best is trial 19 with value: 1.0900543064603903.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 14:58:21,811]\u001b[0m Trial 21 finished with value: 1.0906289994759137 and parameters: {'lambda': 2.74807912456943, 'alpha': 0.15530775460941945, 'colsample_bytree': 0.10050750547240218, 'colsample_bynode': 0.7938951329267365, 'colsample_bylevel': 0.6635194629877261, 'subsample': 0.16906817209272856, 'eta': 0.01, 'grow_policy': 'lossguide', 'max_depth': 25, 'min_child_weight': 31, 'max_bin': 354, 'deterministic_histogram': False}. Best is trial 19 with value: 1.0900543064603903.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 15:33:14,484]\u001b[0m Trial 22 finished with value: 1.0908403311092285 and parameters: {'lambda': 0.37918933300221386, 'alpha': 0.8042435247401413, 'colsample_bytree': 0.1053543012627179, 'colsample_bynode': 0.5903125233938059, 'colsample_bylevel': 0.5100639676142348, 'subsample': 0.34894583544298063, 'eta': 0.01, 'grow_policy': 'lossguide', 'max_depth': 23, 'min_child_weight': 2, 'max_bin': 309, 'deterministic_histogram': False}. Best is trial 19 with value: 1.0900543064603903.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 15:40:10,106]\u001b[0m Trial 23 finished with value: 1.089990417199329 and parameters: {'lambda': 1.3718620937297796, 'alpha': 6.395781966352342, 'colsample_bytree': 0.2390564723786096, 'colsample_bynode': 0.7459555518737353, 'colsample_bylevel': 0.36002014547566097, 'subsample': 0.6302863949739616, 'eta': 0.01, 'grow_policy': 'lossguide', 'max_depth': 19, 'min_child_weight': 28, 'max_bin': 258, 'deterministic_histogram': False}. Best is trial 23 with value: 1.089990417199329.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 15:47:02,317]\u001b[0m Trial 24 finished with value: 1.0900820285811692 and parameters: {'lambda': 9.296937529562435, 'alpha': 6.647551610170594, 'colsample_bytree': 0.2328605487568071, 'colsample_bynode': 0.8912444844578498, 'colsample_bylevel': 0.3728107395821004, 'subsample': 0.6318393153071127, 'eta': 0.01, 'grow_policy': 'lossguide', 'max_depth': 19, 'min_child_weight': 33, 'max_bin': 257, 'deterministic_histogram': False}. Best is trial 23 with value: 1.089990417199329.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 15:52:04,600]\u001b[0m Trial 25 finished with value: 1.091254013573003 and parameters: {'lambda': 9.910411087554717, 'alpha': 6.3205911108251085, 'colsample_bytree': 0.41455135601107773, 'colsample_bynode': 0.8804008832358284, 'colsample_bylevel': 0.35756044265369136, 'subsample': 0.6571309931569667, 'eta': 0.01, 'grow_policy': 'lossguide', 'max_depth': 19, 'min_child_weight': 106, 'max_bin': 257, 'deterministic_histogram': False}. Best is trial 23 with value: 1.089990417199329.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 16:51:51,978]\u001b[0m Trial 26 finished with value: 1.090783090359575 and parameters: {'lambda': 5.508660914966374, 'alpha': 3.7644638410756457, 'colsample_bytree': 0.2578664450748614, 'colsample_bynode': 0.8299311934371348, 'colsample_bylevel': 0.19656235028221125, 'subsample': 0.6540496068897135, 'eta': 0.01, 'grow_policy': 'lossguide', 'max_depth': 23, 'min_child_weight': 73, 'max_bin': 273, 'deterministic_histogram': False}. Best is trial 23 with value: 1.089990417199329.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 17:02:23,102]\u001b[0m Trial 27 finished with value: 1.0900473801474617 and parameters: {'lambda': 1.604346776216664, 'alpha': 7.771292560411, 'colsample_bytree': 0.1874172686736823, 'colsample_bynode': 0.7579797684322918, 'colsample_bylevel': 0.8968486352005596, 'subsample': 0.6158821620909498, 'eta': 0.01, 'grow_policy': 'lossguide', 'max_depth': 21, 'min_child_weight': 35, 'max_bin': 263, 'deterministic_histogram': False}. Best is trial 23 with value: 1.089990417199329.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 17:16:55,351]\u001b[0m Trial 28 finished with value: 1.090828267697224 and parameters: {'lambda': 1.6958181625695843, 'alpha': 2.875200234072891, 'colsample_bytree': 0.17708414446382376, 'colsample_bynode': 0.7432273236224128, 'colsample_bylevel': 0.8801236063172568, 'subsample': 0.4715226994839321, 'eta': 0.01, 'grow_policy': 'lossguide', 'max_depth': 22, 'min_child_weight': 135, 'max_bin': 285, 'deterministic_histogram': False}. Best is trial 23 with value: 1.089990417199329.\u001b[0m\n",
            "\u001b[32m[I 2021-05-23 17:23:23,314]\u001b[0m Trial 29 finished with value: 1.0910486823160093 and parameters: {'lambda': 4.864202677642112, 'alpha': 9.367015136830158, 'colsample_bytree': 0.3294505444199172, 'colsample_bynode': 0.7526267505665372, 'colsample_bylevel': 0.746757085216219, 'subsample': 0.7087728613042341, 'eta': 0.01, 'grow_policy': 'lossguide', 'max_depth': 20, 'min_child_weight': 49, 'max_bin': 256, 'deterministic_histogram': False}. Best is trial 23 with value: 1.089990417199329.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of finished trials: 30\n",
            "Best trial: {'lambda': 1.3718620937297796, 'alpha': 6.395781966352342, 'colsample_bytree': 0.2390564723786096, 'colsample_bynode': 0.7459555518737353, 'colsample_bylevel': 0.36002014547566097, 'subsample': 0.6302863949739616, 'eta': 0.01, 'grow_policy': 'lossguide', 'max_depth': 19, 'min_child_weight': 28, 'max_bin': 258, 'deterministic_histogram': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROq2hyTjfdyM"
      },
      "source": [
        "# Catboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFuSRL2iTDfo"
      },
      "source": [
        "# X = df_all.drop(labels=['id','target'],axis=1,inplace=False).copy()\n",
        "# y = df_all['target'].map({\"Class_1\":0,\"Class_2\":1,\"Class_3\":2,\"Class_4\":3}).values\n",
        "# X_test = df_test.drop(labels=['id'],axis=1,inplace=False).copy()\n",
        "# random_seed = 0\n",
        "\n",
        "# encoder = OrdinalEncoder()\n",
        "# all_encoded = encoder.fit_transform(X.append(X_test))\n",
        "# X = all_encoded[0:len(X)]\n",
        "# X_test = all_encoded[len(X):]\n",
        "\n",
        "# X = X.astype(int)\n",
        "# X_test = X_test.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZfKczszhoSN"
      },
      "source": [
        "X = df_all.drop(labels=['id','target'],axis=1,inplace=False).copy()\n",
        "y = df_all['target'].values\n",
        "X_test = df_test.drop(labels=['id'],axis=1,inplace=False).copy()\n",
        "random_seed = 0\n",
        "\n",
        "encoder = OrdinalEncoder()\n",
        "all_encoded = encoder.fit_transform(X.append(X_test))\n",
        "X = all_encoded[0:len(X)]\n",
        "X_test = all_encoded[len(X):]\n",
        "\n",
        "X = X.astype(int)\n",
        "X_test = X_test.astype(int)\n",
        "cat_features = np.arange(0,X.shape[1]).tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t2B5ozzfo_N"
      },
      "source": [
        "# 'cat_features': cat_features,\n",
        "\n",
        "\n",
        "# params = {'loss_function':'MultiClass',\n",
        "#                   'eval_metric':'MultiClass', \n",
        "#                   'verbose': 500,\n",
        "#           'depth': 6, \n",
        "#           'bootstrap_type': 'Bernoulli',\n",
        "#           'l2_leaf_reg': 0.0006507380912214574, \n",
        "#           'random_strength': 8, \n",
        "#           'border_count': 55, \n",
        "#           'grow_policy': 'SymmetricTree', \n",
        "#           'learning_rate': 0.01, \n",
        "#           'min_data_in_leaf': 51, \n",
        "#           'subsample': 0.4635282300396178}\n",
        "\n",
        "# params = {'learning_rate': 0.04, \n",
        "#           'depth': 5, \n",
        "#           'l2_leaf_reg': 993.0052814277057, \n",
        "#           'random_strength': 1.9065414654052146, \n",
        "#           'border_count': 128, \n",
        "#           'grow_policy': 'Depthwise', \n",
        "#           'min_data_in_leaf': 257}\n",
        "\n",
        "params =   {'learning_rate': 0.03470328317940195, \n",
        "           'depth': 2, \n",
        "           'l2_leaf_reg': 820.7804346737378, \n",
        "           'random_strength': 0.336019499813798, \n",
        "           'border_count': 128,\n",
        "           'grow_policy': 'Lossguide',\n",
        "           'min_data_in_leaf': 267}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PsTBA_7Wf70A",
        "outputId": "79ce1f89-65b2-4bc6-813c-990151b49220"
      },
      "source": [
        "params_cb = params\n",
        "\n",
        "#params_cb[\"cat_features\"] = cat_features\n",
        "#params_cb [\"learning_rate\"] = 0.01\n",
        "#params_cb [\"depth\"] = 4\n",
        "params_cb [\"loss_function\"] = 'MultiClass'\n",
        "params_cb [\"od_wait\"] = 1000\n",
        "params_cb [\"od_type\"] = 'Iter'\n",
        "#params_cb [\"min_data_in_leaf\"] = 1\n",
        "#params_cb [\"max_ctr_complexity\"] = 15\n",
        "params_cb [\"task_type\"] = \"GPU\"\n",
        "params_cb[\"cat_features\"] = cat_features\n",
        "\n",
        "\n",
        "\n",
        "                      \n",
        "\n",
        "name = 'catboost_3seeds_5fold'\n",
        "k=5\n",
        "seed_list=[0,1,2]\n",
        "kf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\n",
        "oof = np.zeros((len(df_all),4))\n",
        "test_preds_list = []\n",
        "score_list = []\n",
        "fold=1\n",
        "  \n",
        "splits = list(kf.split(X,y))\n",
        "fold = 1\n",
        "for train_idx, val_idx in splits:\n",
        "  X_train, X_val = X[train_idx], X[val_idx]\n",
        "  y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "  val_preds_list = []\n",
        "\n",
        "  for seed in seed_list:\n",
        "    \n",
        "    # fit and run model\n",
        "    params_cb['random_state'] = seed\n",
        "        \n",
        "    model = CatBoostClassifier(**params_cb,\n",
        "            iterations=50000,\n",
        "            use_best_model=True,\n",
        ")\n",
        "\n",
        "    model.fit(X_train,y=y_train,\n",
        "              use_best_model=True,\n",
        "              eval_set=[(X_val,y_val)],\n",
        "              verbose=100)\n",
        "    \n",
        "\n",
        "    \n",
        "    val_preds_list.append(model.predict_proba(X_val))\n",
        "    test_preds_list.append(model.predict_proba(X_test))\n",
        "    \n",
        "  oof[val_idx] = np.mean(val_preds_list,axis=0)\n",
        "  score = log_loss(y_val, oof[val_idx])\n",
        "  print(f\"fold: {fold},log_loss: {score}\")\n",
        "  score_list.append(score)\n",
        "  # print(f\"fold: {fold}, class0 tr %: {y_train.value_counts()[0]/len(y_train)}, class0 val %: {y_val.value_counts()[0]/len(y_val)} \")\n",
        "  fold +=1\n",
        "  \n",
        "cv_logloss = np.mean(score_list)\n",
        "print(f\"{name} ,log_loss: {cv_logloss}\")\n",
        "\n",
        "preds= np.mean(test_preds_list,axis=0)\n",
        "\n",
        "\n",
        "file_name_oof = name + \"_oof.txt\"\n",
        "file_name_test = name + \"_test.csv\"\n",
        "with open(file_name_oof, \"wb\") as fp:\n",
        "      pickle.dump(oof, fp)\n",
        "\n",
        "files.download(file_name_oof)\n",
        "\n",
        "df_submission[['Class_1','Class_2','Class_3','Class_4']] = preds\n",
        "df_submission.to_csv(file_name_test,index=None)\n",
        "files.download(file_name_test) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 1.3669102\ttest: 1.3669437\tbest: 1.3669437 (0)\ttotal: 5.39ms\tremaining: 4m 29s\n",
            "100:\tlearn: 1.1115751\ttest: 1.1121498\tbest: 1.1121498 (100)\ttotal: 441ms\tremaining: 3m 37s\n",
            "200:\tlearn: 1.1066347\ttest: 1.1076026\tbest: 1.1076026 (200)\ttotal: 891ms\tremaining: 3m 40s\n",
            "300:\tlearn: 1.1034459\ttest: 1.1046238\tbest: 1.1046238 (300)\ttotal: 1.36s\tremaining: 3m 45s\n",
            "400:\tlearn: 1.1010074\ttest: 1.1023501\tbest: 1.1023501 (400)\ttotal: 1.9s\tremaining: 3m 55s\n",
            "500:\tlearn: 1.0990904\ttest: 1.1005899\tbest: 1.1005899 (500)\ttotal: 2.45s\tremaining: 4m 2s\n",
            "600:\tlearn: 1.0974832\ttest: 1.0990813\tbest: 1.0990813 (600)\ttotal: 3s\tremaining: 4m 6s\n",
            "700:\tlearn: 1.0961672\ttest: 1.0979376\tbest: 1.0979376 (700)\ttotal: 3.52s\tremaining: 4m 7s\n",
            "800:\tlearn: 1.0950668\ttest: 1.0970042\tbest: 1.0970042 (800)\ttotal: 4.06s\tremaining: 4m 9s\n",
            "900:\tlearn: 1.0940920\ttest: 1.0962171\tbest: 1.0962171 (900)\ttotal: 4.6s\tremaining: 4m 10s\n",
            "1000:\tlearn: 1.0932931\ttest: 1.0955559\tbest: 1.0955559 (1000)\ttotal: 5.14s\tremaining: 4m 11s\n",
            "1100:\tlearn: 1.0925813\ttest: 1.0950193\tbest: 1.0950193 (1100)\ttotal: 5.68s\tremaining: 4m 12s\n",
            "1200:\tlearn: 1.0919449\ttest: 1.0944966\tbest: 1.0944966 (1200)\ttotal: 6.2s\tremaining: 4m 11s\n",
            "1300:\tlearn: 1.0913961\ttest: 1.0940899\tbest: 1.0940899 (1300)\ttotal: 6.75s\tremaining: 4m 12s\n",
            "1400:\tlearn: 1.0908854\ttest: 1.0936958\tbest: 1.0936958 (1400)\ttotal: 7.28s\tremaining: 4m 12s\n",
            "1500:\tlearn: 1.0904037\ttest: 1.0933777\tbest: 1.0933767 (1499)\ttotal: 7.8s\tremaining: 4m 12s\n",
            "1600:\tlearn: 1.0899841\ttest: 1.0930872\tbest: 1.0930872 (1600)\ttotal: 8.32s\tremaining: 4m 11s\n",
            "1700:\tlearn: 1.0896059\ttest: 1.0928594\tbest: 1.0928577 (1698)\ttotal: 8.85s\tremaining: 4m 11s\n",
            "1800:\tlearn: 1.0892348\ttest: 1.0926043\tbest: 1.0926043 (1800)\ttotal: 9.37s\tremaining: 4m 10s\n",
            "1900:\tlearn: 1.0889279\ttest: 1.0923800\tbest: 1.0923800 (1900)\ttotal: 9.89s\tremaining: 4m 10s\n",
            "2000:\tlearn: 1.0886232\ttest: 1.0921791\tbest: 1.0921791 (2000)\ttotal: 10.4s\tremaining: 4m 9s\n",
            "2100:\tlearn: 1.0883510\ttest: 1.0920296\tbest: 1.0920296 (2100)\ttotal: 10.9s\tremaining: 4m 8s\n",
            "2200:\tlearn: 1.0880963\ttest: 1.0919192\tbest: 1.0919192 (2200)\ttotal: 11.4s\tremaining: 4m 8s\n",
            "2300:\tlearn: 1.0878240\ttest: 1.0917535\tbest: 1.0917500 (2296)\ttotal: 12s\tremaining: 4m 8s\n",
            "2400:\tlearn: 1.0875902\ttest: 1.0916265\tbest: 1.0916265 (2400)\ttotal: 12.5s\tremaining: 4m 7s\n",
            "2500:\tlearn: 1.0873507\ttest: 1.0914790\tbest: 1.0914790 (2500)\ttotal: 13s\tremaining: 4m 7s\n",
            "2600:\tlearn: 1.0871175\ttest: 1.0913412\tbest: 1.0913412 (2600)\ttotal: 13.6s\tremaining: 4m 7s\n",
            "2700:\tlearn: 1.0869048\ttest: 1.0912283\tbest: 1.0912283 (2700)\ttotal: 14.1s\tremaining: 4m 6s\n",
            "2800:\tlearn: 1.0867003\ttest: 1.0911003\tbest: 1.0911003 (2800)\ttotal: 14.6s\tremaining: 4m 6s\n",
            "2900:\tlearn: 1.0865127\ttest: 1.0910343\tbest: 1.0910343 (2900)\ttotal: 15.1s\tremaining: 4m 5s\n",
            "3000:\tlearn: 1.0863356\ttest: 1.0909671\tbest: 1.0909657 (2999)\ttotal: 15.6s\tremaining: 4m 5s\n",
            "3100:\tlearn: 1.0861608\ttest: 1.0908840\tbest: 1.0908840 (3099)\ttotal: 16.2s\tremaining: 4m 4s\n",
            "3200:\tlearn: 1.0859911\ttest: 1.0908046\tbest: 1.0908046 (3200)\ttotal: 16.7s\tremaining: 4m 4s\n",
            "3300:\tlearn: 1.0858194\ttest: 1.0907308\tbest: 1.0907308 (3300)\ttotal: 17.2s\tremaining: 4m 3s\n",
            "3400:\tlearn: 1.0856398\ttest: 1.0906635\tbest: 1.0906635 (3400)\ttotal: 17.8s\tremaining: 4m 3s\n",
            "3500:\tlearn: 1.0854786\ttest: 1.0905814\tbest: 1.0905813 (3499)\ttotal: 18.3s\tremaining: 4m 2s\n",
            "3600:\tlearn: 1.0853075\ttest: 1.0905436\tbest: 1.0905365 (3568)\ttotal: 18.8s\tremaining: 4m 2s\n",
            "3700:\tlearn: 1.0851592\ttest: 1.0904969\tbest: 1.0904969 (3700)\ttotal: 19.3s\tremaining: 4m 1s\n",
            "3800:\tlearn: 1.0850248\ttest: 1.0904386\tbest: 1.0904385 (3799)\ttotal: 19.9s\tremaining: 4m 1s\n",
            "3900:\tlearn: 1.0848769\ttest: 1.0903711\tbest: 1.0903711 (3900)\ttotal: 20.4s\tremaining: 4m\n",
            "4000:\tlearn: 1.0847472\ttest: 1.0903077\tbest: 1.0903073 (3999)\ttotal: 20.9s\tremaining: 4m\n",
            "4100:\tlearn: 1.0846096\ttest: 1.0902599\tbest: 1.0902588 (4098)\ttotal: 21.4s\tremaining: 3m 59s\n",
            "4200:\tlearn: 1.0844763\ttest: 1.0902205\tbest: 1.0902191 (4198)\ttotal: 22s\tremaining: 3m 59s\n",
            "4300:\tlearn: 1.0843375\ttest: 1.0901711\tbest: 1.0901711 (4300)\ttotal: 22.5s\tremaining: 3m 58s\n",
            "4400:\tlearn: 1.0842073\ttest: 1.0901400\tbest: 1.0901368 (4397)\ttotal: 23s\tremaining: 3m 58s\n",
            "4500:\tlearn: 1.0840777\ttest: 1.0901040\tbest: 1.0901035 (4498)\ttotal: 23.6s\tremaining: 3m 58s\n",
            "4600:\tlearn: 1.0839513\ttest: 1.0900662\tbest: 1.0900651 (4596)\ttotal: 24.1s\tremaining: 3m 57s\n",
            "4700:\tlearn: 1.0838209\ttest: 1.0900275\tbest: 1.0900268 (4699)\ttotal: 24.6s\tremaining: 3m 57s\n",
            "4800:\tlearn: 1.0836998\ttest: 1.0899788\tbest: 1.0899783 (4799)\ttotal: 25.2s\tremaining: 3m 56s\n",
            "4900:\tlearn: 1.0835854\ttest: 1.0899209\tbest: 1.0899209 (4899)\ttotal: 25.7s\tremaining: 3m 56s\n",
            "5000:\tlearn: 1.0834602\ttest: 1.0898858\tbest: 1.0898846 (4994)\ttotal: 26.2s\tremaining: 3m 55s\n",
            "5100:\tlearn: 1.0833429\ttest: 1.0898578\tbest: 1.0898578 (5100)\ttotal: 26.7s\tremaining: 3m 55s\n",
            "5200:\tlearn: 1.0832214\ttest: 1.0898323\tbest: 1.0898312 (5197)\ttotal: 27.3s\tremaining: 3m 54s\n",
            "5300:\tlearn: 1.0831020\ttest: 1.0897787\tbest: 1.0897778 (5296)\ttotal: 27.8s\tremaining: 3m 54s\n",
            "5400:\tlearn: 1.0829975\ttest: 1.0897707\tbest: 1.0897707 (5400)\ttotal: 28.3s\tremaining: 3m 53s\n",
            "5500:\tlearn: 1.0828997\ttest: 1.0897301\tbest: 1.0897298 (5492)\ttotal: 28.8s\tremaining: 3m 53s\n",
            "5600:\tlearn: 1.0827926\ttest: 1.0897046\tbest: 1.0897035 (5596)\ttotal: 29.3s\tremaining: 3m 52s\n",
            "5700:\tlearn: 1.0826843\ttest: 1.0896717\tbest: 1.0896703 (5670)\ttotal: 29.9s\tremaining: 3m 52s\n",
            "5800:\tlearn: 1.0825684\ttest: 1.0896444\tbest: 1.0896418 (5796)\ttotal: 30.4s\tremaining: 3m 51s\n",
            "5900:\tlearn: 1.0824705\ttest: 1.0896323\tbest: 1.0896320 (5895)\ttotal: 30.9s\tremaining: 3m 50s\n",
            "6000:\tlearn: 1.0823746\ttest: 1.0896202\tbest: 1.0896202 (6000)\ttotal: 31.4s\tremaining: 3m 50s\n",
            "6100:\tlearn: 1.0822679\ttest: 1.0895813\tbest: 1.0895785 (6096)\ttotal: 31.9s\tremaining: 3m 49s\n",
            "6200:\tlearn: 1.0821694\ttest: 1.0895642\tbest: 1.0895601 (6151)\ttotal: 32.5s\tremaining: 3m 49s\n",
            "6300:\tlearn: 1.0820707\ttest: 1.0895681\tbest: 1.0895586 (6223)\ttotal: 33s\tremaining: 3m 48s\n",
            "6400:\tlearn: 1.0819690\ttest: 1.0895563\tbest: 1.0895541 (6346)\ttotal: 33.5s\tremaining: 3m 48s\n",
            "6500:\tlearn: 1.0818655\ttest: 1.0895296\tbest: 1.0895239 (6485)\ttotal: 34s\tremaining: 3m 47s\n",
            "6600:\tlearn: 1.0817739\ttest: 1.0895043\tbest: 1.0895023 (6572)\ttotal: 34.6s\tremaining: 3m 47s\n",
            "6700:\tlearn: 1.0816841\ttest: 1.0894943\tbest: 1.0894933 (6691)\ttotal: 35.1s\tremaining: 3m 46s\n",
            "6800:\tlearn: 1.0815941\ttest: 1.0894878\tbest: 1.0894841 (6741)\ttotal: 35.6s\tremaining: 3m 46s\n",
            "6900:\tlearn: 1.0814943\ttest: 1.0894741\tbest: 1.0894741 (6900)\ttotal: 36.1s\tremaining: 3m 45s\n",
            "7000:\tlearn: 1.0814000\ttest: 1.0894634\tbest: 1.0894562 (6975)\ttotal: 36.6s\tremaining: 3m 44s\n",
            "7100:\tlearn: 1.0813072\ttest: 1.0894479\tbest: 1.0894424 (7092)\ttotal: 37.2s\tremaining: 3m 44s\n",
            "7200:\tlearn: 1.0812179\ttest: 1.0894452\tbest: 1.0894424 (7092)\ttotal: 37.7s\tremaining: 3m 44s\n",
            "7300:\tlearn: 1.0811366\ttest: 1.0894457\tbest: 1.0894400 (7262)\ttotal: 38.2s\tremaining: 3m 43s\n",
            "7400:\tlearn: 1.0810466\ttest: 1.0894352\tbest: 1.0894346 (7388)\ttotal: 38.7s\tremaining: 3m 42s\n",
            "7500:\tlearn: 1.0809553\ttest: 1.0894223\tbest: 1.0894207 (7476)\ttotal: 39.2s\tremaining: 3m 42s\n",
            "7600:\tlearn: 1.0808766\ttest: 1.0894197\tbest: 1.0894150 (7535)\ttotal: 39.8s\tremaining: 3m 41s\n",
            "7700:\tlearn: 1.0807839\ttest: 1.0894175\tbest: 1.0894087 (7672)\ttotal: 40.3s\tremaining: 3m 41s\n",
            "7800:\tlearn: 1.0806959\ttest: 1.0894174\tbest: 1.0894087 (7672)\ttotal: 40.8s\tremaining: 3m 40s\n",
            "7900:\tlearn: 1.0806194\ttest: 1.0893969\tbest: 1.0893943 (7895)\ttotal: 41.4s\tremaining: 3m 40s\n",
            "8000:\tlearn: 1.0805273\ttest: 1.0893786\tbest: 1.0893786 (8000)\ttotal: 41.9s\tremaining: 3m 40s\n",
            "8100:\tlearn: 1.0804351\ttest: 1.0893640\tbest: 1.0893592 (8090)\ttotal: 42.5s\tremaining: 3m 39s\n",
            "8200:\tlearn: 1.0803514\ttest: 1.0893426\tbest: 1.0893405 (8179)\ttotal: 43s\tremaining: 3m 39s\n",
            "8300:\tlearn: 1.0802705\ttest: 1.0893341\tbest: 1.0893335 (8296)\ttotal: 43.6s\tremaining: 3m 39s\n",
            "8400:\tlearn: 1.0801914\ttest: 1.0893174\tbest: 1.0893174 (8400)\ttotal: 44.2s\tremaining: 3m 38s\n",
            "8500:\tlearn: 1.0801063\ttest: 1.0893223\tbest: 1.0893129 (8453)\ttotal: 44.7s\tremaining: 3m 38s\n",
            "8600:\tlearn: 1.0800121\ttest: 1.0893237\tbest: 1.0893129 (8453)\ttotal: 45.3s\tremaining: 3m 38s\n",
            "8700:\tlearn: 1.0799303\ttest: 1.0893323\tbest: 1.0893129 (8453)\ttotal: 45.9s\tremaining: 3m 37s\n",
            "8800:\tlearn: 1.0798546\ttest: 1.0893400\tbest: 1.0893129 (8453)\ttotal: 46.5s\tremaining: 3m 37s\n",
            "8900:\tlearn: 1.0797688\ttest: 1.0893289\tbest: 1.0893129 (8453)\ttotal: 47s\tremaining: 3m 37s\n",
            "9000:\tlearn: 1.0796827\ttest: 1.0893155\tbest: 1.0893129 (8453)\ttotal: 47.6s\tremaining: 3m 36s\n",
            "9100:\tlearn: 1.0795969\ttest: 1.0893286\tbest: 1.0893129 (8453)\ttotal: 48.2s\tremaining: 3m 36s\n",
            "9200:\tlearn: 1.0795093\ttest: 1.0892954\tbest: 1.0892954 (9200)\ttotal: 48.7s\tremaining: 3m 36s\n",
            "9300:\tlearn: 1.0794369\ttest: 1.0892948\tbest: 1.0892917 (9247)\ttotal: 49.3s\tremaining: 3m 35s\n",
            "9400:\tlearn: 1.0793575\ttest: 1.0892991\tbest: 1.0892909 (9337)\ttotal: 49.9s\tremaining: 3m 35s\n",
            "9500:\tlearn: 1.0792754\ttest: 1.0892823\tbest: 1.0892769 (9485)\ttotal: 50.5s\tremaining: 3m 35s\n",
            "9600:\tlearn: 1.0791967\ttest: 1.0892711\tbest: 1.0892711 (9600)\ttotal: 51.1s\tremaining: 3m 34s\n",
            "9700:\tlearn: 1.0791299\ttest: 1.0892672\tbest: 1.0892634 (9680)\ttotal: 51.7s\tremaining: 3m 34s\n",
            "9800:\tlearn: 1.0790465\ttest: 1.0892513\tbest: 1.0892476 (9746)\ttotal: 52.2s\tremaining: 3m 34s\n",
            "9900:\tlearn: 1.0789711\ttest: 1.0892309\tbest: 1.0892309 (9900)\ttotal: 52.8s\tremaining: 3m 33s\n",
            "10000:\tlearn: 1.0788953\ttest: 1.0892304\tbest: 1.0892192 (9934)\ttotal: 53.4s\tremaining: 3m 33s\n",
            "10100:\tlearn: 1.0788135\ttest: 1.0892306\tbest: 1.0892192 (9934)\ttotal: 54s\tremaining: 3m 33s\n",
            "10200:\tlearn: 1.0787383\ttest: 1.0892226\tbest: 1.0892192 (9934)\ttotal: 54.5s\tremaining: 3m 32s\n",
            "10300:\tlearn: 1.0786556\ttest: 1.0892270\tbest: 1.0892180 (10258)\ttotal: 55.1s\tremaining: 3m 32s\n",
            "10400:\tlearn: 1.0785848\ttest: 1.0892338\tbest: 1.0892180 (10258)\ttotal: 55.7s\tremaining: 3m 32s\n",
            "10500:\tlearn: 1.0785055\ttest: 1.0892335\tbest: 1.0892180 (10258)\ttotal: 56.3s\tremaining: 3m 31s\n",
            "10600:\tlearn: 1.0784324\ttest: 1.0892258\tbest: 1.0892180 (10258)\ttotal: 56.8s\tremaining: 3m 31s\n",
            "10700:\tlearn: 1.0783562\ttest: 1.0892548\tbest: 1.0892180 (10258)\ttotal: 57.4s\tremaining: 3m 30s\n",
            "10800:\tlearn: 1.0782837\ttest: 1.0892475\tbest: 1.0892180 (10258)\ttotal: 58s\tremaining: 3m 30s\n",
            "10900:\tlearn: 1.0782080\ttest: 1.0892672\tbest: 1.0892180 (10258)\ttotal: 58.6s\tremaining: 3m 30s\n",
            "11000:\tlearn: 1.0781276\ttest: 1.0892786\tbest: 1.0892180 (10258)\ttotal: 59.1s\tremaining: 3m 29s\n",
            "11100:\tlearn: 1.0780505\ttest: 1.0892879\tbest: 1.0892180 (10258)\ttotal: 59.7s\tremaining: 3m 29s\n",
            "11200:\tlearn: 1.0779777\ttest: 1.0892889\tbest: 1.0892180 (10258)\ttotal: 1m\tremaining: 3m 28s\n",
            "bestTest = 1.089217969\n",
            "bestIteration = 10258\n",
            "Shrink model to first 10259 iterations.\n",
            "0:\tlearn: 1.3666686\ttest: 1.3666882\tbest: 1.3666882 (0)\ttotal: 6.62ms\tremaining: 5m 30s\n",
            "100:\tlearn: 1.1116278\ttest: 1.1122026\tbest: 1.1122026 (100)\ttotal: 506ms\tremaining: 4m 9s\n",
            "200:\tlearn: 1.1067339\ttest: 1.1076691\tbest: 1.1076691 (200)\ttotal: 936ms\tremaining: 3m 51s\n",
            "300:\tlearn: 1.1035041\ttest: 1.1046934\tbest: 1.1046934 (300)\ttotal: 1.39s\tremaining: 3m 50s\n",
            "400:\tlearn: 1.1010235\ttest: 1.1023781\tbest: 1.1023781 (400)\ttotal: 1.89s\tremaining: 3m 53s\n",
            "500:\tlearn: 1.0990179\ttest: 1.1005150\tbest: 1.1005150 (500)\ttotal: 2.38s\tremaining: 3m 55s\n",
            "600:\tlearn: 1.0974489\ttest: 1.0991130\tbest: 1.0991130 (600)\ttotal: 2.94s\tremaining: 4m 1s\n",
            "700:\tlearn: 1.0961674\ttest: 1.0979788\tbest: 1.0979788 (700)\ttotal: 3.51s\tremaining: 4m 7s\n",
            "800:\tlearn: 1.0950559\ttest: 1.0970145\tbest: 1.0970145 (800)\ttotal: 4.07s\tremaining: 4m 10s\n",
            "900:\tlearn: 1.0941376\ttest: 1.0961926\tbest: 1.0961926 (900)\ttotal: 4.64s\tremaining: 4m 12s\n",
            "1000:\tlearn: 1.0933019\ttest: 1.0955124\tbest: 1.0955124 (1000)\ttotal: 5.17s\tremaining: 4m 13s\n",
            "1100:\tlearn: 1.0926105\ttest: 1.0950119\tbest: 1.0950119 (1100)\ttotal: 5.68s\tremaining: 4m 12s\n",
            "1200:\tlearn: 1.0920024\ttest: 1.0945630\tbest: 1.0945630 (1200)\ttotal: 6.2s\tremaining: 4m 11s\n",
            "1300:\tlearn: 1.0914761\ttest: 1.0941682\tbest: 1.0941682 (1300)\ttotal: 6.7s\tremaining: 4m 10s\n",
            "1400:\tlearn: 1.0909893\ttest: 1.0937921\tbest: 1.0937921 (1400)\ttotal: 7.19s\tremaining: 4m 9s\n",
            "1500:\tlearn: 1.0905315\ttest: 1.0934873\tbest: 1.0934873 (1500)\ttotal: 7.69s\tremaining: 4m 8s\n",
            "1600:\tlearn: 1.0901104\ttest: 1.0931817\tbest: 1.0931817 (1600)\ttotal: 8.18s\tremaining: 4m 7s\n",
            "1700:\tlearn: 1.0897217\ttest: 1.0929039\tbest: 1.0929039 (1700)\ttotal: 8.74s\tremaining: 4m 8s\n",
            "1800:\tlearn: 1.0893608\ttest: 1.0926743\tbest: 1.0926743 (1800)\ttotal: 9.26s\tremaining: 4m 7s\n",
            "1900:\tlearn: 1.0890284\ttest: 1.0924844\tbest: 1.0924844 (1900)\ttotal: 9.82s\tremaining: 4m 8s\n",
            "2000:\tlearn: 1.0887194\ttest: 1.0922751\tbest: 1.0922751 (2000)\ttotal: 10.4s\tremaining: 4m 8s\n",
            "2100:\tlearn: 1.0884546\ttest: 1.0921301\tbest: 1.0921285 (2099)\ttotal: 10.9s\tremaining: 4m 9s\n",
            "2200:\tlearn: 1.0881877\ttest: 1.0919726\tbest: 1.0919723 (2198)\ttotal: 11.5s\tremaining: 4m 9s\n",
            "2300:\tlearn: 1.0879392\ttest: 1.0918160\tbest: 1.0918160 (2300)\ttotal: 12.1s\tremaining: 4m 9s\n",
            "2400:\tlearn: 1.0876851\ttest: 1.0916747\tbest: 1.0916747 (2400)\ttotal: 12.6s\tremaining: 4m 9s\n",
            "2500:\tlearn: 1.0874401\ttest: 1.0915466\tbest: 1.0915438 (2498)\ttotal: 13.2s\tremaining: 4m 9s\n",
            "2600:\tlearn: 1.0872034\ttest: 1.0914490\tbest: 1.0914486 (2599)\ttotal: 13.7s\tremaining: 4m 10s\n",
            "2700:\tlearn: 1.0869910\ttest: 1.0913261\tbest: 1.0913249 (2698)\ttotal: 14.3s\tremaining: 4m 9s\n",
            "2800:\tlearn: 1.0867928\ttest: 1.0912350\tbest: 1.0912335 (2797)\ttotal: 14.8s\tremaining: 4m 10s\n",
            "2900:\tlearn: 1.0865902\ttest: 1.0911353\tbest: 1.0911353 (2900)\ttotal: 15.4s\tremaining: 4m 9s\n",
            "3000:\tlearn: 1.0863878\ttest: 1.0910461\tbest: 1.0910461 (3000)\ttotal: 15.9s\tremaining: 4m 9s\n",
            "3100:\tlearn: 1.0862057\ttest: 1.0909723\tbest: 1.0909688 (3097)\ttotal: 16.5s\tremaining: 4m 9s\n",
            "3200:\tlearn: 1.0860235\ttest: 1.0908592\tbest: 1.0908592 (3200)\ttotal: 17s\tremaining: 4m 8s\n",
            "3300:\tlearn: 1.0858557\ttest: 1.0907907\tbest: 1.0907880 (3294)\ttotal: 17.6s\tremaining: 4m 8s\n",
            "3400:\tlearn: 1.0856769\ttest: 1.0907146\tbest: 1.0907139 (3399)\ttotal: 18.2s\tremaining: 4m 8s\n",
            "3500:\tlearn: 1.0855064\ttest: 1.0906437\tbest: 1.0906425 (3495)\ttotal: 18.7s\tremaining: 4m 8s\n",
            "3600:\tlearn: 1.0853451\ttest: 1.0905734\tbest: 1.0905704 (3597)\ttotal: 19.3s\tremaining: 4m 8s\n",
            "3700:\tlearn: 1.0851808\ttest: 1.0905057\tbest: 1.0905046 (3693)\ttotal: 19.8s\tremaining: 4m 8s\n",
            "3800:\tlearn: 1.0850344\ttest: 1.0904507\tbest: 1.0904485 (3797)\ttotal: 20.4s\tremaining: 4m 8s\n",
            "3900:\tlearn: 1.0848854\ttest: 1.0904009\tbest: 1.0903996 (3888)\ttotal: 21s\tremaining: 4m 7s\n",
            "4000:\tlearn: 1.0847273\ttest: 1.0903392\tbest: 1.0903392 (4000)\ttotal: 21.5s\tremaining: 4m 7s\n",
            "4100:\tlearn: 1.0845779\ttest: 1.0903071\tbest: 1.0903071 (4100)\ttotal: 22.1s\tremaining: 4m 7s\n",
            "4200:\tlearn: 1.0844492\ttest: 1.0902636\tbest: 1.0902636 (4200)\ttotal: 22.6s\tremaining: 4m 6s\n",
            "4300:\tlearn: 1.0843173\ttest: 1.0902158\tbest: 1.0902158 (4300)\ttotal: 23.2s\tremaining: 4m 6s\n",
            "4400:\tlearn: 1.0841903\ttest: 1.0901826\tbest: 1.0901811 (4399)\ttotal: 23.7s\tremaining: 4m 5s\n",
            "4500:\tlearn: 1.0840649\ttest: 1.0901491\tbest: 1.0901491 (4500)\ttotal: 24.3s\tremaining: 4m 5s\n",
            "4600:\tlearn: 1.0839389\ttest: 1.0900951\tbest: 1.0900940 (4586)\ttotal: 24.8s\tremaining: 4m 4s\n",
            "4700:\tlearn: 1.0837972\ttest: 1.0900578\tbest: 1.0900577 (4699)\ttotal: 25.3s\tremaining: 4m 3s\n",
            "4800:\tlearn: 1.0836630\ttest: 1.0900148\tbest: 1.0900143 (4793)\ttotal: 25.8s\tremaining: 4m 3s\n",
            "4900:\tlearn: 1.0835421\ttest: 1.0899833\tbest: 1.0899833 (4900)\ttotal: 26.3s\tremaining: 4m 2s\n",
            "5000:\tlearn: 1.0834227\ttest: 1.0899544\tbest: 1.0899544 (5000)\ttotal: 26.9s\tremaining: 4m 1s\n",
            "5100:\tlearn: 1.0832991\ttest: 1.0899100\tbest: 1.0899100 (5100)\ttotal: 27.4s\tremaining: 4m 1s\n",
            "5200:\tlearn: 1.0831822\ttest: 1.0898786\tbest: 1.0898773 (5198)\ttotal: 28s\tremaining: 4m 1s\n",
            "5300:\tlearn: 1.0830633\ttest: 1.0898572\tbest: 1.0898521 (5285)\ttotal: 28.5s\tremaining: 4m\n",
            "5400:\tlearn: 1.0829504\ttest: 1.0898069\tbest: 1.0898042 (5398)\ttotal: 29.1s\tremaining: 4m\n",
            "5500:\tlearn: 1.0828304\ttest: 1.0897917\tbest: 1.0897828 (5440)\ttotal: 29.6s\tremaining: 3m 59s\n",
            "5600:\tlearn: 1.0827209\ttest: 1.0897854\tbest: 1.0897819 (5585)\ttotal: 30.2s\tremaining: 3m 59s\n",
            "5700:\tlearn: 1.0826160\ttest: 1.0897607\tbest: 1.0897607 (5699)\ttotal: 30.8s\tremaining: 3m 58s\n",
            "5800:\tlearn: 1.0825061\ttest: 1.0897286\tbest: 1.0897286 (5799)\ttotal: 31.3s\tremaining: 3m 58s\n",
            "5900:\tlearn: 1.0823938\ttest: 1.0897055\tbest: 1.0897055 (5900)\ttotal: 31.9s\tremaining: 3m 58s\n",
            "6000:\tlearn: 1.0822971\ttest: 1.0896742\tbest: 1.0896721 (5995)\ttotal: 32.4s\tremaining: 3m 57s\n",
            "6100:\tlearn: 1.0821834\ttest: 1.0896501\tbest: 1.0896501 (6100)\ttotal: 33s\tremaining: 3m 57s\n",
            "6200:\tlearn: 1.0820796\ttest: 1.0896339\tbest: 1.0896331 (6199)\ttotal: 33.5s\tremaining: 3m 56s\n",
            "6300:\tlearn: 1.0819734\ttest: 1.0896449\tbest: 1.0896289 (6207)\ttotal: 34.1s\tremaining: 3m 56s\n",
            "6400:\tlearn: 1.0818687\ttest: 1.0896151\tbest: 1.0896126 (6394)\ttotal: 34.6s\tremaining: 3m 55s\n",
            "6500:\tlearn: 1.0817740\ttest: 1.0895947\tbest: 1.0895926 (6489)\ttotal: 35.2s\tremaining: 3m 55s\n",
            "6600:\tlearn: 1.0816710\ttest: 1.0895697\tbest: 1.0895681 (6594)\ttotal: 35.7s\tremaining: 3m 54s\n",
            "6700:\tlearn: 1.0815585\ttest: 1.0895360\tbest: 1.0895356 (6698)\ttotal: 36.3s\tremaining: 3m 54s\n",
            "6800:\tlearn: 1.0814613\ttest: 1.0895470\tbest: 1.0895356 (6698)\ttotal: 36.9s\tremaining: 3m 54s\n",
            "6900:\tlearn: 1.0813625\ttest: 1.0895546\tbest: 1.0895356 (6698)\ttotal: 37.4s\tremaining: 3m 53s\n",
            "7000:\tlearn: 1.0812583\ttest: 1.0895439\tbest: 1.0895356 (6698)\ttotal: 38s\tremaining: 3m 53s\n",
            "7100:\tlearn: 1.0811606\ttest: 1.0895316\tbest: 1.0895303 (7098)\ttotal: 38.6s\tremaining: 3m 53s\n",
            "7200:\tlearn: 1.0810634\ttest: 1.0895293\tbest: 1.0895187 (7171)\ttotal: 39.1s\tremaining: 3m 52s\n",
            "7300:\tlearn: 1.0809619\ttest: 1.0895123\tbest: 1.0895120 (7288)\ttotal: 39.7s\tremaining: 3m 52s\n",
            "7400:\tlearn: 1.0808595\ttest: 1.0894899\tbest: 1.0894899 (7400)\ttotal: 40.2s\tremaining: 3m 51s\n",
            "7500:\tlearn: 1.0807750\ttest: 1.0894811\tbest: 1.0894762 (7459)\ttotal: 40.8s\tremaining: 3m 51s\n",
            "7600:\tlearn: 1.0806871\ttest: 1.0894777\tbest: 1.0894735 (7590)\ttotal: 41.4s\tremaining: 3m 50s\n",
            "7700:\tlearn: 1.0806001\ttest: 1.0894756\tbest: 1.0894687 (7635)\ttotal: 41.9s\tremaining: 3m 50s\n",
            "7800:\tlearn: 1.0805009\ttest: 1.0894497\tbest: 1.0894497 (7800)\ttotal: 42.5s\tremaining: 3m 49s\n",
            "7900:\tlearn: 1.0804128\ttest: 1.0894345\tbest: 1.0894335 (7896)\ttotal: 43.1s\tremaining: 3m 49s\n",
            "8000:\tlearn: 1.0803251\ttest: 1.0894303\tbest: 1.0894272 (7995)\ttotal: 43.6s\tremaining: 3m 49s\n",
            "8100:\tlearn: 1.0802449\ttest: 1.0894339\tbest: 1.0894270 (8021)\ttotal: 44.2s\tremaining: 3m 48s\n",
            "8200:\tlearn: 1.0801565\ttest: 1.0894153\tbest: 1.0894153 (8199)\ttotal: 44.8s\tremaining: 3m 48s\n",
            "8300:\tlearn: 1.0800717\ttest: 1.0894263\tbest: 1.0894149 (8210)\ttotal: 45.4s\tremaining: 3m 47s\n",
            "8400:\tlearn: 1.0799953\ttest: 1.0894249\tbest: 1.0894149 (8210)\ttotal: 45.9s\tremaining: 3m 47s\n",
            "8500:\tlearn: 1.0799169\ttest: 1.0894143\tbest: 1.0894125 (8488)\ttotal: 46.5s\tremaining: 3m 46s\n",
            "8600:\tlearn: 1.0798300\ttest: 1.0894020\tbest: 1.0894020 (8600)\ttotal: 47.1s\tremaining: 3m 46s\n",
            "8700:\tlearn: 1.0797504\ttest: 1.0893952\tbest: 1.0893946 (8698)\ttotal: 47.6s\tremaining: 3m 46s\n",
            "8800:\tlearn: 1.0796714\ttest: 1.0893939\tbest: 1.0893897 (8783)\ttotal: 48.2s\tremaining: 3m 45s\n",
            "8900:\tlearn: 1.0795871\ttest: 1.0893810\tbest: 1.0893810 (8900)\ttotal: 48.7s\tremaining: 3m 44s\n",
            "9000:\tlearn: 1.0795106\ttest: 1.0893836\tbest: 1.0893766 (8933)\ttotal: 49.3s\tremaining: 3m 44s\n",
            "9100:\tlearn: 1.0794292\ttest: 1.0893723\tbest: 1.0893701 (9094)\ttotal: 49.8s\tremaining: 3m 43s\n",
            "9200:\tlearn: 1.0793390\ttest: 1.0893656\tbest: 1.0893656 (9200)\ttotal: 50.3s\tremaining: 3m 43s\n",
            "9300:\tlearn: 1.0792580\ttest: 1.0893626\tbest: 1.0893592 (9254)\ttotal: 50.9s\tremaining: 3m 42s\n",
            "9400:\tlearn: 1.0791750\ttest: 1.0893649\tbest: 1.0893557 (9349)\ttotal: 51.4s\tremaining: 3m 42s\n",
            "9500:\tlearn: 1.0790903\ttest: 1.0893675\tbest: 1.0893557 (9349)\ttotal: 52s\tremaining: 3m 41s\n",
            "9600:\tlearn: 1.0790162\ttest: 1.0893688\tbest: 1.0893557 (9349)\ttotal: 52.6s\tremaining: 3m 41s\n",
            "9700:\tlearn: 1.0789371\ttest: 1.0893611\tbest: 1.0893557 (9349)\ttotal: 53.2s\tremaining: 3m 40s\n",
            "9800:\tlearn: 1.0788552\ttest: 1.0893590\tbest: 1.0893504 (9761)\ttotal: 53.8s\tremaining: 3m 40s\n",
            "9900:\tlearn: 1.0787700\ttest: 1.0893773\tbest: 1.0893504 (9761)\ttotal: 54.3s\tremaining: 3m 40s\n",
            "10000:\tlearn: 1.0786905\ttest: 1.0893727\tbest: 1.0893504 (9761)\ttotal: 54.9s\tremaining: 3m 39s\n",
            "10100:\tlearn: 1.0786102\ttest: 1.0893802\tbest: 1.0893504 (9761)\ttotal: 55.5s\tremaining: 3m 39s\n",
            "10200:\tlearn: 1.0785327\ttest: 1.0893797\tbest: 1.0893504 (9761)\ttotal: 56s\tremaining: 3m 38s\n",
            "10300:\tlearn: 1.0784497\ttest: 1.0893729\tbest: 1.0893504 (9761)\ttotal: 56.6s\tremaining: 3m 38s\n",
            "10400:\tlearn: 1.0783679\ttest: 1.0893694\tbest: 1.0893504 (9761)\ttotal: 57.2s\tremaining: 3m 37s\n",
            "10500:\tlearn: 1.0782916\ttest: 1.0893705\tbest: 1.0893504 (9761)\ttotal: 57.8s\tremaining: 3m 37s\n",
            "10600:\tlearn: 1.0782115\ttest: 1.0893677\tbest: 1.0893504 (9761)\ttotal: 58.4s\tremaining: 3m 36s\n",
            "10700:\tlearn: 1.0781362\ttest: 1.0893690\tbest: 1.0893504 (9761)\ttotal: 59s\tremaining: 3m 36s\n",
            "bestTest = 1.089350391\n",
            "bestIteration = 9761\n",
            "Shrink model to first 9762 iterations.\n",
            "0:\tlearn: 1.3669120\ttest: 1.3669411\tbest: 1.3669411 (0)\ttotal: 5.53ms\tremaining: 4m 36s\n",
            "100:\tlearn: 1.1115642\ttest: 1.1121147\tbest: 1.1121147 (100)\ttotal: 433ms\tremaining: 3m 33s\n",
            "200:\tlearn: 1.1066904\ttest: 1.1075549\tbest: 1.1075549 (200)\ttotal: 867ms\tremaining: 3m 34s\n",
            "300:\tlearn: 1.1035890\ttest: 1.1047039\tbest: 1.1047039 (300)\ttotal: 1.32s\tremaining: 3m 38s\n",
            "400:\tlearn: 1.1011374\ttest: 1.1024125\tbest: 1.1024125 (400)\ttotal: 1.76s\tremaining: 3m 37s\n",
            "500:\tlearn: 1.0992135\ttest: 1.1006049\tbest: 1.1006049 (500)\ttotal: 2.26s\tremaining: 3m 43s\n",
            "600:\tlearn: 1.0976260\ttest: 1.0992076\tbest: 1.0992076 (600)\ttotal: 2.81s\tremaining: 3m 50s\n",
            "700:\tlearn: 1.0962881\ttest: 1.0980552\tbest: 1.0980552 (700)\ttotal: 3.32s\tremaining: 3m 53s\n",
            "800:\tlearn: 1.0951972\ttest: 1.0970911\tbest: 1.0970911 (800)\ttotal: 3.82s\tremaining: 3m 54s\n",
            "900:\tlearn: 1.0942746\ttest: 1.0962850\tbest: 1.0962850 (900)\ttotal: 4.32s\tremaining: 3m 55s\n",
            "1000:\tlearn: 1.0934755\ttest: 1.0956281\tbest: 1.0956281 (1000)\ttotal: 4.81s\tremaining: 3m 55s\n",
            "1100:\tlearn: 1.0927856\ttest: 1.0950832\tbest: 1.0950832 (1100)\ttotal: 5.31s\tremaining: 3m 55s\n",
            "1200:\tlearn: 1.0921779\ttest: 1.0946316\tbest: 1.0946316 (1200)\ttotal: 5.8s\tremaining: 3m 55s\n",
            "1300:\tlearn: 1.0916496\ttest: 1.0942412\tbest: 1.0942412 (1300)\ttotal: 6.3s\tremaining: 3m 55s\n",
            "1400:\tlearn: 1.0911174\ttest: 1.0938618\tbest: 1.0938618 (1400)\ttotal: 6.8s\tremaining: 3m 55s\n",
            "1500:\tlearn: 1.0906474\ttest: 1.0934762\tbest: 1.0934762 (1500)\ttotal: 7.3s\tremaining: 3m 55s\n",
            "1600:\tlearn: 1.0902279\ttest: 1.0931938\tbest: 1.0931938 (1600)\ttotal: 7.8s\tremaining: 3m 55s\n",
            "1700:\tlearn: 1.0898377\ttest: 1.0929074\tbest: 1.0929074 (1700)\ttotal: 8.29s\tremaining: 3m 55s\n",
            "1800:\tlearn: 1.0894790\ttest: 1.0926692\tbest: 1.0926692 (1800)\ttotal: 8.81s\tremaining: 3m 55s\n",
            "1900:\tlearn: 1.0891519\ttest: 1.0924591\tbest: 1.0924591 (1900)\ttotal: 9.32s\tremaining: 3m 55s\n",
            "2000:\tlearn: 1.0888479\ttest: 1.0922573\tbest: 1.0922546 (1999)\ttotal: 9.83s\tremaining: 3m 55s\n",
            "2100:\tlearn: 1.0885488\ttest: 1.0920563\tbest: 1.0920563 (2100)\ttotal: 10.3s\tremaining: 3m 55s\n",
            "2200:\tlearn: 1.0882715\ttest: 1.0918949\tbest: 1.0918949 (2200)\ttotal: 10.8s\tremaining: 3m 55s\n",
            "2300:\tlearn: 1.0880110\ttest: 1.0917482\tbest: 1.0917482 (2300)\ttotal: 11.3s\tremaining: 3m 54s\n",
            "2400:\tlearn: 1.0877838\ttest: 1.0915881\tbest: 1.0915873 (2398)\ttotal: 11.8s\tremaining: 3m 54s\n",
            "2500:\tlearn: 1.0875434\ttest: 1.0914563\tbest: 1.0914563 (2500)\ttotal: 12.3s\tremaining: 3m 54s\n",
            "2600:\tlearn: 1.0873292\ttest: 1.0913755\tbest: 1.0913745 (2599)\ttotal: 12.8s\tremaining: 3m 53s\n",
            "2700:\tlearn: 1.0871143\ttest: 1.0912343\tbest: 1.0912343 (2700)\ttotal: 13.3s\tremaining: 3m 52s\n",
            "2800:\tlearn: 1.0869062\ttest: 1.0911384\tbest: 1.0911384 (2800)\ttotal: 13.8s\tremaining: 3m 52s\n",
            "2900:\tlearn: 1.0867192\ttest: 1.0910524\tbest: 1.0910517 (2899)\ttotal: 14.3s\tremaining: 3m 51s\n",
            "3000:\tlearn: 1.0865270\ttest: 1.0909659\tbest: 1.0909613 (2993)\ttotal: 14.8s\tremaining: 3m 51s\n",
            "3100:\tlearn: 1.0863407\ttest: 1.0908712\tbest: 1.0908712 (3100)\ttotal: 15.2s\tremaining: 3m 50s\n",
            "3200:\tlearn: 1.0861573\ttest: 1.0907869\tbest: 1.0907869 (3200)\ttotal: 15.8s\tremaining: 3m 50s\n",
            "3300:\tlearn: 1.0859907\ttest: 1.0907074\tbest: 1.0907074 (3300)\ttotal: 16.3s\tremaining: 3m 50s\n",
            "3400:\tlearn: 1.0858362\ttest: 1.0906488\tbest: 1.0906488 (3400)\ttotal: 16.8s\tremaining: 3m 50s\n",
            "3500:\tlearn: 1.0856714\ttest: 1.0905656\tbest: 1.0905655 (3497)\ttotal: 17.4s\tremaining: 3m 50s\n",
            "3600:\tlearn: 1.0855053\ttest: 1.0904829\tbest: 1.0904829 (3600)\ttotal: 17.9s\tremaining: 3m 50s\n",
            "3700:\tlearn: 1.0853516\ttest: 1.0904329\tbest: 1.0904309 (3693)\ttotal: 18.4s\tremaining: 3m 50s\n",
            "3800:\tlearn: 1.0852021\ttest: 1.0903897\tbest: 1.0903885 (3784)\ttotal: 19s\tremaining: 3m 50s\n",
            "3900:\tlearn: 1.0850560\ttest: 1.0903163\tbest: 1.0903162 (3893)\ttotal: 19.5s\tremaining: 3m 50s\n",
            "4000:\tlearn: 1.0849081\ttest: 1.0902793\tbest: 1.0902782 (3996)\ttotal: 20.1s\tremaining: 3m 50s\n",
            "4100:\tlearn: 1.0847644\ttest: 1.0902378\tbest: 1.0902378 (4099)\ttotal: 20.6s\tremaining: 3m 51s\n",
            "4200:\tlearn: 1.0846300\ttest: 1.0902144\tbest: 1.0902094 (4176)\ttotal: 21.2s\tremaining: 3m 51s\n",
            "4300:\tlearn: 1.0844905\ttest: 1.0901724\tbest: 1.0901703 (4292)\ttotal: 21.8s\tremaining: 3m 51s\n",
            "4400:\tlearn: 1.0843480\ttest: 1.0901127\tbest: 1.0901127 (4400)\ttotal: 22.3s\tremaining: 3m 51s\n",
            "4500:\tlearn: 1.0842240\ttest: 1.0900817\tbest: 1.0900817 (4500)\ttotal: 22.9s\tremaining: 3m 51s\n",
            "4600:\tlearn: 1.0841053\ttest: 1.0900559\tbest: 1.0900502 (4586)\ttotal: 23.4s\tremaining: 3m 51s\n",
            "4700:\tlearn: 1.0839636\ttest: 1.0900199\tbest: 1.0900191 (4698)\ttotal: 24s\tremaining: 3m 51s\n",
            "4800:\tlearn: 1.0838369\ttest: 1.0899841\tbest: 1.0899841 (4800)\ttotal: 24.5s\tremaining: 3m 51s\n",
            "4900:\tlearn: 1.0837041\ttest: 1.0899361\tbest: 1.0899359 (4899)\ttotal: 25.1s\tremaining: 3m 50s\n",
            "5000:\tlearn: 1.0835829\ttest: 1.0898739\tbest: 1.0898712 (4991)\ttotal: 25.7s\tremaining: 3m 50s\n",
            "5100:\tlearn: 1.0834574\ttest: 1.0898299\tbest: 1.0898257 (5092)\ttotal: 26.2s\tremaining: 3m 50s\n",
            "5200:\tlearn: 1.0833348\ttest: 1.0897798\tbest: 1.0897790 (5197)\ttotal: 26.8s\tremaining: 3m 50s\n",
            "5300:\tlearn: 1.0832139\ttest: 1.0897430\tbest: 1.0897370 (5290)\ttotal: 27.3s\tremaining: 3m 50s\n",
            "5400:\tlearn: 1.0831033\ttest: 1.0897159\tbest: 1.0897140 (5391)\ttotal: 27.9s\tremaining: 3m 50s\n",
            "5500:\tlearn: 1.0829999\ttest: 1.0896872\tbest: 1.0896872 (5500)\ttotal: 28.4s\tremaining: 3m 49s\n",
            "5600:\tlearn: 1.0828906\ttest: 1.0896678\tbest: 1.0896643 (5595)\ttotal: 29s\tremaining: 3m 49s\n",
            "5700:\tlearn: 1.0827811\ttest: 1.0896468\tbest: 1.0896438 (5684)\ttotal: 29.6s\tremaining: 3m 49s\n",
            "5800:\tlearn: 1.0826811\ttest: 1.0896217\tbest: 1.0896217 (5799)\ttotal: 30.1s\tremaining: 3m 49s\n",
            "5900:\tlearn: 1.0825752\ttest: 1.0896220\tbest: 1.0896134 (5834)\ttotal: 30.7s\tremaining: 3m 49s\n",
            "6000:\tlearn: 1.0824717\ttest: 1.0896025\tbest: 1.0896010 (5992)\ttotal: 31.2s\tremaining: 3m 48s\n",
            "6100:\tlearn: 1.0823620\ttest: 1.0895841\tbest: 1.0895840 (6098)\ttotal: 31.7s\tremaining: 3m 48s\n",
            "6200:\tlearn: 1.0822657\ttest: 1.0895485\tbest: 1.0895468 (6196)\ttotal: 32.3s\tremaining: 3m 48s\n",
            "6300:\tlearn: 1.0821635\ttest: 1.0895251\tbest: 1.0895251 (6300)\ttotal: 32.8s\tremaining: 3m 47s\n",
            "6400:\tlearn: 1.0820610\ttest: 1.0895170\tbest: 1.0895154 (6392)\ttotal: 33.4s\tremaining: 3m 47s\n",
            "6500:\tlearn: 1.0819666\ttest: 1.0895042\tbest: 1.0894990 (6476)\ttotal: 33.9s\tremaining: 3m 47s\n",
            "6600:\tlearn: 1.0818760\ttest: 1.0894890\tbest: 1.0894846 (6582)\ttotal: 34.5s\tremaining: 3m 46s\n",
            "6700:\tlearn: 1.0817821\ttest: 1.0894840\tbest: 1.0894783 (6663)\ttotal: 35s\tremaining: 3m 46s\n",
            "6800:\tlearn: 1.0816917\ttest: 1.0894892\tbest: 1.0894779 (6705)\ttotal: 35.6s\tremaining: 3m 45s\n",
            "6900:\tlearn: 1.0816024\ttest: 1.0894672\tbest: 1.0894672 (6900)\ttotal: 36.1s\tremaining: 3m 45s\n",
            "7000:\tlearn: 1.0815174\ttest: 1.0894658\tbest: 1.0894566 (6933)\ttotal: 36.7s\tremaining: 3m 45s\n",
            "7100:\tlearn: 1.0814233\ttest: 1.0894307\tbest: 1.0894298 (7095)\ttotal: 37.3s\tremaining: 3m 45s\n",
            "7200:\tlearn: 1.0813324\ttest: 1.0894075\tbest: 1.0894064 (7184)\ttotal: 37.9s\tremaining: 3m 44s\n",
            "7300:\tlearn: 1.0812423\ttest: 1.0894011\tbest: 1.0894007 (7246)\ttotal: 38.4s\tremaining: 3m 44s\n",
            "7400:\tlearn: 1.0811510\ttest: 1.0893844\tbest: 1.0893780 (7364)\ttotal: 39s\tremaining: 3m 44s\n",
            "7500:\tlearn: 1.0810713\ttest: 1.0893757\tbest: 1.0893737 (7490)\ttotal: 39.6s\tremaining: 3m 44s\n",
            "7600:\tlearn: 1.0809836\ttest: 1.0893595\tbest: 1.0893595 (7600)\ttotal: 40.2s\tremaining: 3m 44s\n",
            "7700:\tlearn: 1.0808959\ttest: 1.0893521\tbest: 1.0893450 (7686)\ttotal: 40.8s\tremaining: 3m 44s\n",
            "7800:\tlearn: 1.0807978\ttest: 1.0893555\tbest: 1.0893450 (7686)\ttotal: 41.4s\tremaining: 3m 43s\n",
            "7900:\tlearn: 1.0807068\ttest: 1.0893593\tbest: 1.0893450 (7686)\ttotal: 42s\tremaining: 3m 43s\n",
            "8000:\tlearn: 1.0806209\ttest: 1.0893376\tbest: 1.0893370 (7988)\ttotal: 42.5s\tremaining: 3m 43s\n",
            "8100:\tlearn: 1.0805366\ttest: 1.0893380\tbest: 1.0893241 (8042)\ttotal: 43.1s\tremaining: 3m 43s\n",
            "8200:\tlearn: 1.0804488\ttest: 1.0893104\tbest: 1.0893104 (8200)\ttotal: 43.7s\tremaining: 3m 42s\n",
            "8300:\tlearn: 1.0803651\ttest: 1.0892878\tbest: 1.0892849 (8280)\ttotal: 44.3s\tremaining: 3m 42s\n",
            "8400:\tlearn: 1.0802790\ttest: 1.0892705\tbest: 1.0892697 (8397)\ttotal: 44.9s\tremaining: 3m 42s\n",
            "8500:\tlearn: 1.0801958\ttest: 1.0892611\tbest: 1.0892530 (8440)\ttotal: 45.4s\tremaining: 3m 41s\n",
            "8600:\tlearn: 1.0801049\ttest: 1.0892599\tbest: 1.0892445 (8559)\ttotal: 46s\tremaining: 3m 41s\n",
            "8700:\tlearn: 1.0800170\ttest: 1.0892522\tbest: 1.0892445 (8559)\ttotal: 46.6s\tremaining: 3m 41s\n",
            "8800:\tlearn: 1.0799252\ttest: 1.0892438\tbest: 1.0892421 (8707)\ttotal: 47.2s\tremaining: 3m 40s\n",
            "8900:\tlearn: 1.0798530\ttest: 1.0892459\tbest: 1.0892398 (8808)\ttotal: 47.8s\tremaining: 3m 40s\n",
            "9000:\tlearn: 1.0797707\ttest: 1.0892462\tbest: 1.0892398 (8808)\ttotal: 48.4s\tremaining: 3m 40s\n",
            "9100:\tlearn: 1.0797048\ttest: 1.0892456\tbest: 1.0892398 (8808)\ttotal: 48.9s\tremaining: 3m 39s\n",
            "9200:\tlearn: 1.0796242\ttest: 1.0892401\tbest: 1.0892398 (8808)\ttotal: 49.5s\tremaining: 3m 39s\n",
            "9300:\tlearn: 1.0795431\ttest: 1.0892399\tbest: 1.0892341 (9217)\ttotal: 50.1s\tremaining: 3m 39s\n",
            "9400:\tlearn: 1.0794667\ttest: 1.0892366\tbest: 1.0892260 (9336)\ttotal: 50.7s\tremaining: 3m 38s\n",
            "9500:\tlearn: 1.0793865\ttest: 1.0892233\tbest: 1.0892212 (9487)\ttotal: 51.2s\tremaining: 3m 38s\n",
            "9600:\tlearn: 1.0793040\ttest: 1.0892283\tbest: 1.0892212 (9487)\ttotal: 51.8s\tremaining: 3m 37s\n",
            "9700:\tlearn: 1.0792273\ttest: 1.0892202\tbest: 1.0892186 (9666)\ttotal: 52.4s\tremaining: 3m 37s\n",
            "9800:\tlearn: 1.0791496\ttest: 1.0892148\tbest: 1.0892143 (9745)\ttotal: 53s\tremaining: 3m 37s\n",
            "9900:\tlearn: 1.0790681\ttest: 1.0891922\tbest: 1.0891922 (9900)\ttotal: 53.6s\tremaining: 3m 36s\n",
            "10000:\tlearn: 1.0789945\ttest: 1.0891790\tbest: 1.0891789 (9996)\ttotal: 54.1s\tremaining: 3m 36s\n",
            "10100:\tlearn: 1.0789201\ttest: 1.0891678\tbest: 1.0891606 (10083)\ttotal: 54.7s\tremaining: 3m 36s\n",
            "10200:\tlearn: 1.0788431\ttest: 1.0891561\tbest: 1.0891516 (10178)\ttotal: 55.2s\tremaining: 3m 35s\n",
            "10300:\tlearn: 1.0787601\ttest: 1.0891566\tbest: 1.0891516 (10178)\ttotal: 55.8s\tremaining: 3m 35s\n",
            "10400:\tlearn: 1.0786865\ttest: 1.0891550\tbest: 1.0891516 (10178)\ttotal: 56.4s\tremaining: 3m 34s\n",
            "10500:\tlearn: 1.0786147\ttest: 1.0891532\tbest: 1.0891516 (10178)\ttotal: 56.9s\tremaining: 3m 34s\n",
            "10600:\tlearn: 1.0785430\ttest: 1.0891583\tbest: 1.0891516 (10178)\ttotal: 57.5s\tremaining: 3m 33s\n",
            "10700:\tlearn: 1.0784656\ttest: 1.0891554\tbest: 1.0891516 (10178)\ttotal: 58s\tremaining: 3m 33s\n",
            "10800:\tlearn: 1.0783888\ttest: 1.0891465\tbest: 1.0891451 (10796)\ttotal: 58.6s\tremaining: 3m 32s\n",
            "10900:\tlearn: 1.0783109\ttest: 1.0891491\tbest: 1.0891392 (10859)\ttotal: 59.2s\tremaining: 3m 32s\n",
            "11000:\tlearn: 1.0782369\ttest: 1.0891532\tbest: 1.0891392 (10859)\ttotal: 59.7s\tremaining: 3m 31s\n",
            "11100:\tlearn: 1.0781725\ttest: 1.0891619\tbest: 1.0891392 (10859)\ttotal: 1m\tremaining: 3m 31s\n",
            "11200:\tlearn: 1.0780931\ttest: 1.0891535\tbest: 1.0891392 (10859)\ttotal: 1m\tremaining: 3m 30s\n",
            "11300:\tlearn: 1.0780194\ttest: 1.0891647\tbest: 1.0891392 (10859)\ttotal: 1m 1s\tremaining: 3m 30s\n",
            "11400:\tlearn: 1.0779535\ttest: 1.0891612\tbest: 1.0891392 (10859)\ttotal: 1m 1s\tremaining: 3m 29s\n",
            "11500:\tlearn: 1.0778793\ttest: 1.0891712\tbest: 1.0891392 (10859)\ttotal: 1m 2s\tremaining: 3m 29s\n",
            "11600:\tlearn: 1.0778104\ttest: 1.0891688\tbest: 1.0891392 (10859)\ttotal: 1m 3s\tremaining: 3m 28s\n",
            "11700:\tlearn: 1.0777432\ttest: 1.0891668\tbest: 1.0891392 (10859)\ttotal: 1m 3s\tremaining: 3m 28s\n",
            "11800:\tlearn: 1.0776648\ttest: 1.0891623\tbest: 1.0891392 (10859)\ttotal: 1m 4s\tremaining: 3m 27s\n",
            "bestTest = 1.08913916\n",
            "bestIteration = 10859\n",
            "Shrink model to first 10860 iterations.\n",
            "fold: 1,log_loss: 1.0890407157792397\n",
            "0:\tlearn: 1.3666726\ttest: 1.3666797\tbest: 1.3666797 (0)\ttotal: 7.6ms\tremaining: 6m 19s\n",
            "100:\tlearn: 1.1115515\ttest: 1.1119132\tbest: 1.1119132 (100)\ttotal: 492ms\tremaining: 4m 3s\n",
            "200:\tlearn: 1.1065564\ttest: 1.1075513\tbest: 1.1075513 (200)\ttotal: 972ms\tremaining: 4m\n",
            "300:\tlearn: 1.1032550\ttest: 1.1047840\tbest: 1.1047840 (300)\ttotal: 1.51s\tremaining: 4m 10s\n",
            "400:\tlearn: 1.1007703\ttest: 1.1027462\tbest: 1.1027462 (400)\ttotal: 2.07s\tremaining: 4m 15s\n",
            "500:\tlearn: 1.0987141\ttest: 1.1011563\tbest: 1.1011563 (500)\ttotal: 2.58s\tremaining: 4m 14s\n",
            "600:\tlearn: 1.0970437\ttest: 1.0999500\tbest: 1.0999500 (600)\ttotal: 3.1s\tremaining: 4m 14s\n",
            "700:\tlearn: 1.0956725\ttest: 1.0989259\tbest: 1.0989259 (700)\ttotal: 3.63s\tremaining: 4m 15s\n",
            "800:\tlearn: 1.0945143\ttest: 1.0981548\tbest: 1.0981548 (800)\ttotal: 4.18s\tremaining: 4m 16s\n",
            "900:\tlearn: 1.0935553\ttest: 1.0975438\tbest: 1.0975438 (900)\ttotal: 4.71s\tremaining: 4m 16s\n",
            "1000:\tlearn: 1.0926925\ttest: 1.0971107\tbest: 1.0971107 (1000)\ttotal: 5.24s\tremaining: 4m 16s\n",
            "1100:\tlearn: 1.0919439\ttest: 1.0966580\tbest: 1.0966580 (1100)\ttotal: 5.77s\tremaining: 4m 16s\n",
            "1200:\tlearn: 1.0913580\ttest: 1.0963494\tbest: 1.0963494 (1200)\ttotal: 6.3s\tremaining: 4m 16s\n",
            "1300:\tlearn: 1.0907484\ttest: 1.0960236\tbest: 1.0960236 (1300)\ttotal: 6.83s\tremaining: 4m 15s\n",
            "1400:\tlearn: 1.0902104\ttest: 1.0957842\tbest: 1.0957842 (1400)\ttotal: 7.37s\tremaining: 4m 15s\n",
            "1500:\tlearn: 1.0896967\ttest: 1.0955462\tbest: 1.0955462 (1500)\ttotal: 7.89s\tremaining: 4m 14s\n",
            "1600:\tlearn: 1.0892683\ttest: 1.0953739\tbest: 1.0953739 (1600)\ttotal: 8.42s\tremaining: 4m 14s\n",
            "1700:\tlearn: 1.0888519\ttest: 1.0951999\tbest: 1.0951999 (1700)\ttotal: 8.96s\tremaining: 4m 14s\n",
            "1800:\tlearn: 1.0884646\ttest: 1.0950454\tbest: 1.0950454 (1800)\ttotal: 9.49s\tremaining: 4m 13s\n",
            "1900:\tlearn: 1.0881107\ttest: 1.0948928\tbest: 1.0948928 (1900)\ttotal: 10s\tremaining: 4m 13s\n",
            "2000:\tlearn: 1.0877937\ttest: 1.0947894\tbest: 1.0947877 (1999)\ttotal: 10.6s\tremaining: 4m 13s\n",
            "2100:\tlearn: 1.0874999\ttest: 1.0947096\tbest: 1.0947096 (2100)\ttotal: 11.1s\tremaining: 4m 13s\n",
            "2200:\tlearn: 1.0872139\ttest: 1.0946114\tbest: 1.0946114 (2200)\ttotal: 11.6s\tremaining: 4m 12s\n",
            "2300:\tlearn: 1.0869461\ttest: 1.0945232\tbest: 1.0945226 (2299)\ttotal: 12.2s\tremaining: 4m 12s\n",
            "2400:\tlearn: 1.0866912\ttest: 1.0944514\tbest: 1.0944514 (2400)\ttotal: 12.7s\tremaining: 4m 11s\n",
            "2500:\tlearn: 1.0864380\ttest: 1.0943880\tbest: 1.0943855 (2499)\ttotal: 13.2s\tremaining: 4m 11s\n",
            "2600:\tlearn: 1.0862235\ttest: 1.0943225\tbest: 1.0943225 (2600)\ttotal: 13.8s\tremaining: 4m 10s\n",
            "2700:\tlearn: 1.0860037\ttest: 1.0942749\tbest: 1.0942722 (2696)\ttotal: 14.3s\tremaining: 4m 10s\n",
            "2800:\tlearn: 1.0857818\ttest: 1.0942271\tbest: 1.0942254 (2786)\ttotal: 14.8s\tremaining: 4m 10s\n",
            "2900:\tlearn: 1.0855808\ttest: 1.0941655\tbest: 1.0941655 (2898)\ttotal: 15.4s\tremaining: 4m 9s\n",
            "3000:\tlearn: 1.0853780\ttest: 1.0941329\tbest: 1.0941310 (2998)\ttotal: 15.9s\tremaining: 4m 9s\n",
            "3100:\tlearn: 1.0851926\ttest: 1.0940998\tbest: 1.0940962 (3095)\ttotal: 16.4s\tremaining: 4m 8s\n",
            "3200:\tlearn: 1.0850039\ttest: 1.0940588\tbest: 1.0940558 (3193)\ttotal: 17s\tremaining: 4m 8s\n",
            "3300:\tlearn: 1.0848150\ttest: 1.0940113\tbest: 1.0940113 (3300)\ttotal: 17.5s\tremaining: 4m 7s\n",
            "3400:\tlearn: 1.0846438\ttest: 1.0940103\tbest: 1.0940052 (3366)\ttotal: 18s\tremaining: 4m 7s\n",
            "3500:\tlearn: 1.0844735\ttest: 1.0939697\tbest: 1.0939693 (3497)\ttotal: 18.6s\tremaining: 4m 6s\n",
            "3600:\tlearn: 1.0843091\ttest: 1.0939244\tbest: 1.0939236 (3599)\ttotal: 19.1s\tremaining: 4m 6s\n",
            "3700:\tlearn: 1.0841499\ttest: 1.0939013\tbest: 1.0939005 (3698)\ttotal: 19.7s\tremaining: 4m 6s\n",
            "3800:\tlearn: 1.0840069\ttest: 1.0938708\tbest: 1.0938708 (3800)\ttotal: 20.2s\tremaining: 4m 5s\n",
            "3900:\tlearn: 1.0838551\ttest: 1.0938262\tbest: 1.0938262 (3900)\ttotal: 20.8s\tremaining: 4m 5s\n",
            "4000:\tlearn: 1.0837104\ttest: 1.0938182\tbest: 1.0938143 (3930)\ttotal: 21.3s\tremaining: 4m 5s\n",
            "4100:\tlearn: 1.0835720\ttest: 1.0937862\tbest: 1.0937842 (4097)\ttotal: 21.9s\tremaining: 4m 4s\n",
            "4200:\tlearn: 1.0834223\ttest: 1.0937697\tbest: 1.0937626 (4184)\ttotal: 22.4s\tremaining: 4m 4s\n",
            "4300:\tlearn: 1.0832943\ttest: 1.0937464\tbest: 1.0937429 (4295)\ttotal: 23s\tremaining: 4m 3s\n",
            "4400:\tlearn: 1.0831614\ttest: 1.0937321\tbest: 1.0937320 (4399)\ttotal: 23.5s\tremaining: 4m 3s\n",
            "4500:\tlearn: 1.0830186\ttest: 1.0937149\tbest: 1.0937149 (4500)\ttotal: 24s\tremaining: 4m 2s\n",
            "4600:\tlearn: 1.0829036\ttest: 1.0937031\tbest: 1.0937006 (4551)\ttotal: 24.6s\tremaining: 4m 2s\n",
            "4700:\tlearn: 1.0827766\ttest: 1.0936718\tbest: 1.0936683 (4690)\ttotal: 25.1s\tremaining: 4m 1s\n",
            "4800:\tlearn: 1.0826520\ttest: 1.0936593\tbest: 1.0936563 (4796)\ttotal: 25.6s\tremaining: 4m 1s\n",
            "4900:\tlearn: 1.0825254\ttest: 1.0936458\tbest: 1.0936458 (4900)\ttotal: 26.2s\tremaining: 4m 1s\n",
            "5000:\tlearn: 1.0824111\ttest: 1.0936482\tbest: 1.0936381 (4914)\ttotal: 26.7s\tremaining: 4m\n",
            "5100:\tlearn: 1.0822942\ttest: 1.0936518\tbest: 1.0936381 (4914)\ttotal: 27.3s\tremaining: 4m\n",
            "5200:\tlearn: 1.0821823\ttest: 1.0936589\tbest: 1.0936381 (4914)\ttotal: 27.8s\tremaining: 3m 59s\n",
            "5300:\tlearn: 1.0820707\ttest: 1.0936523\tbest: 1.0936381 (4914)\ttotal: 28.3s\tremaining: 3m 58s\n",
            "5400:\tlearn: 1.0819510\ttest: 1.0936521\tbest: 1.0936381 (4914)\ttotal: 28.9s\tremaining: 3m 58s\n",
            "5500:\tlearn: 1.0818428\ttest: 1.0936318\tbest: 1.0936318 (5500)\ttotal: 29.4s\tremaining: 3m 57s\n",
            "5600:\tlearn: 1.0817332\ttest: 1.0936495\tbest: 1.0936317 (5501)\ttotal: 29.9s\tremaining: 3m 57s\n",
            "5700:\tlearn: 1.0816241\ttest: 1.0936413\tbest: 1.0936317 (5501)\ttotal: 30.5s\tremaining: 3m 56s\n",
            "5800:\tlearn: 1.0815158\ttest: 1.0936499\tbest: 1.0936317 (5501)\ttotal: 31s\tremaining: 3m 56s\n",
            "5900:\tlearn: 1.0813938\ttest: 1.0936478\tbest: 1.0936317 (5501)\ttotal: 31.6s\tremaining: 3m 55s\n",
            "6000:\tlearn: 1.0812879\ttest: 1.0936562\tbest: 1.0936317 (5501)\ttotal: 32.1s\tremaining: 3m 55s\n",
            "6100:\tlearn: 1.0811745\ttest: 1.0936601\tbest: 1.0936317 (5501)\ttotal: 32.6s\tremaining: 3m 54s\n",
            "6200:\tlearn: 1.0810674\ttest: 1.0936457\tbest: 1.0936317 (5501)\ttotal: 33.2s\tremaining: 3m 54s\n",
            "6300:\tlearn: 1.0809729\ttest: 1.0936313\tbest: 1.0936305 (6293)\ttotal: 33.7s\tremaining: 3m 53s\n",
            "6400:\tlearn: 1.0808680\ttest: 1.0936335\tbest: 1.0936305 (6293)\ttotal: 34.3s\tremaining: 3m 53s\n",
            "6500:\tlearn: 1.0807735\ttest: 1.0936258\tbest: 1.0936258 (6500)\ttotal: 34.8s\tremaining: 3m 52s\n",
            "6600:\tlearn: 1.0806734\ttest: 1.0936232\tbest: 1.0936218 (6594)\ttotal: 35.3s\tremaining: 3m 52s\n",
            "6700:\tlearn: 1.0805585\ttest: 1.0936379\tbest: 1.0936218 (6594)\ttotal: 35.9s\tremaining: 3m 51s\n",
            "6800:\tlearn: 1.0804610\ttest: 1.0936438\tbest: 1.0936218 (6594)\ttotal: 36.4s\tremaining: 3m 51s\n",
            "6900:\tlearn: 1.0803653\ttest: 1.0936464\tbest: 1.0936218 (6594)\ttotal: 36.9s\tremaining: 3m 50s\n",
            "7000:\tlearn: 1.0802605\ttest: 1.0936476\tbest: 1.0936218 (6594)\ttotal: 37.5s\tremaining: 3m 50s\n",
            "7100:\tlearn: 1.0801682\ttest: 1.0936368\tbest: 1.0936218 (6594)\ttotal: 38s\tremaining: 3m 49s\n",
            "7200:\tlearn: 1.0800763\ttest: 1.0936403\tbest: 1.0936218 (6594)\ttotal: 38.5s\tremaining: 3m 48s\n",
            "7300:\tlearn: 1.0799854\ttest: 1.0936297\tbest: 1.0936218 (6594)\ttotal: 39s\tremaining: 3m 48s\n",
            "7400:\tlearn: 1.0798899\ttest: 1.0936155\tbest: 1.0936104 (7390)\ttotal: 39.6s\tremaining: 3m 47s\n",
            "7500:\tlearn: 1.0798063\ttest: 1.0936158\tbest: 1.0936096 (7462)\ttotal: 40.1s\tremaining: 3m 47s\n",
            "7600:\tlearn: 1.0797148\ttest: 1.0936231\tbest: 1.0936096 (7462)\ttotal: 40.6s\tremaining: 3m 46s\n",
            "7700:\tlearn: 1.0796312\ttest: 1.0936215\tbest: 1.0936096 (7462)\ttotal: 41.2s\tremaining: 3m 46s\n",
            "7800:\tlearn: 1.0795430\ttest: 1.0936255\tbest: 1.0936096 (7462)\ttotal: 41.7s\tremaining: 3m 45s\n",
            "7900:\tlearn: 1.0794490\ttest: 1.0936395\tbest: 1.0936096 (7462)\ttotal: 42.3s\tremaining: 3m 45s\n",
            "8000:\tlearn: 1.0793655\ttest: 1.0936547\tbest: 1.0936096 (7462)\ttotal: 42.8s\tremaining: 3m 44s\n",
            "8100:\tlearn: 1.0792762\ttest: 1.0936582\tbest: 1.0936096 (7462)\ttotal: 43.4s\tremaining: 3m 44s\n",
            "8200:\tlearn: 1.0791865\ttest: 1.0936676\tbest: 1.0936096 (7462)\ttotal: 44s\tremaining: 3m 44s\n",
            "8300:\tlearn: 1.0790912\ttest: 1.0936717\tbest: 1.0936096 (7462)\ttotal: 44.5s\tremaining: 3m 43s\n",
            "8400:\tlearn: 1.0790019\ttest: 1.0936620\tbest: 1.0936096 (7462)\ttotal: 45.1s\tremaining: 3m 43s\n",
            "bestTest = 1.09360957\n",
            "bestIteration = 7462\n",
            "Shrink model to first 7463 iterations.\n",
            "0:\tlearn: 1.3666861\ttest: 1.3666635\tbest: 1.3666635 (0)\ttotal: 8.17ms\tremaining: 6m 48s\n",
            "100:\tlearn: 1.1115294\ttest: 1.1117291\tbest: 1.1117291 (100)\ttotal: 477ms\tremaining: 3m 55s\n",
            "200:\tlearn: 1.1064358\ttest: 1.1074333\tbest: 1.1074333 (200)\ttotal: 917ms\tremaining: 3m 47s\n",
            "300:\tlearn: 1.1031117\ttest: 1.1047220\tbest: 1.1047220 (300)\ttotal: 1.37s\tremaining: 3m 45s\n",
            "400:\tlearn: 1.1004662\ttest: 1.1026824\tbest: 1.1026824 (400)\ttotal: 1.84s\tremaining: 3m 47s\n",
            "500:\tlearn: 1.0984471\ttest: 1.1011207\tbest: 1.1011207 (500)\ttotal: 2.37s\tremaining: 3m 53s\n",
            "600:\tlearn: 1.0968580\ttest: 1.0998689\tbest: 1.0998689 (600)\ttotal: 2.92s\tremaining: 4m\n",
            "700:\tlearn: 1.0954838\ttest: 1.0988479\tbest: 1.0988479 (700)\ttotal: 3.49s\tremaining: 4m 5s\n",
            "800:\tlearn: 1.0943391\ttest: 1.0980514\tbest: 1.0980514 (800)\ttotal: 4.05s\tremaining: 4m 8s\n",
            "900:\tlearn: 1.0933801\ttest: 1.0974145\tbest: 1.0974145 (900)\ttotal: 4.6s\tremaining: 4m 10s\n",
            "1000:\tlearn: 1.0925143\ttest: 1.0968359\tbest: 1.0968359 (1000)\ttotal: 5.14s\tremaining: 4m 11s\n",
            "1100:\tlearn: 1.0917596\ttest: 1.0964500\tbest: 1.0964481 (1099)\ttotal: 5.71s\tremaining: 4m 13s\n",
            "1200:\tlearn: 1.0911022\ttest: 1.0960751\tbest: 1.0960745 (1199)\ttotal: 6.27s\tremaining: 4m 14s\n",
            "1300:\tlearn: 1.0905207\ttest: 1.0958057\tbest: 1.0958057 (1300)\ttotal: 6.84s\tremaining: 4m 15s\n",
            "1400:\tlearn: 1.0899946\ttest: 1.0955588\tbest: 1.0955584 (1395)\ttotal: 7.41s\tremaining: 4m 16s\n",
            "1500:\tlearn: 1.0895121\ttest: 1.0953506\tbest: 1.0953506 (1500)\ttotal: 7.96s\tremaining: 4m 17s\n",
            "1600:\tlearn: 1.0890889\ttest: 1.0951180\tbest: 1.0951180 (1600)\ttotal: 8.54s\tremaining: 4m 18s\n",
            "1700:\tlearn: 1.0886913\ttest: 1.0949465\tbest: 1.0949465 (1700)\ttotal: 9.09s\tremaining: 4m 17s\n",
            "1800:\tlearn: 1.0883427\ttest: 1.0948183\tbest: 1.0948168 (1798)\ttotal: 9.65s\tremaining: 4m 18s\n",
            "1900:\tlearn: 1.0879762\ttest: 1.0946730\tbest: 1.0946730 (1900)\ttotal: 10.2s\tremaining: 4m 17s\n",
            "2000:\tlearn: 1.0876463\ttest: 1.0945770\tbest: 1.0945747 (1995)\ttotal: 10.7s\tremaining: 4m 17s\n",
            "2100:\tlearn: 1.0873445\ttest: 1.0944851\tbest: 1.0944851 (2100)\ttotal: 11.2s\tremaining: 4m 16s\n",
            "2200:\tlearn: 1.0870500\ttest: 1.0943708\tbest: 1.0943708 (2200)\ttotal: 11.8s\tremaining: 4m 15s\n",
            "2300:\tlearn: 1.0868009\ttest: 1.0942995\tbest: 1.0942967 (2275)\ttotal: 12.3s\tremaining: 4m 14s\n",
            "2400:\tlearn: 1.0865286\ttest: 1.0942418\tbest: 1.0942418 (2400)\ttotal: 12.8s\tremaining: 4m 13s\n",
            "2500:\tlearn: 1.0862754\ttest: 1.0941757\tbest: 1.0941751 (2499)\ttotal: 13.3s\tremaining: 4m 12s\n",
            "2600:\tlearn: 1.0860415\ttest: 1.0941140\tbest: 1.0941140 (2600)\ttotal: 13.9s\tremaining: 4m 12s\n",
            "2700:\tlearn: 1.0858220\ttest: 1.0940553\tbest: 1.0940481 (2683)\ttotal: 14.4s\tremaining: 4m 11s\n",
            "2800:\tlearn: 1.0856223\ttest: 1.0940252\tbest: 1.0940190 (2784)\ttotal: 14.9s\tremaining: 4m 10s\n",
            "2900:\tlearn: 1.0854187\ttest: 1.0939744\tbest: 1.0939689 (2895)\ttotal: 15.4s\tremaining: 4m 10s\n",
            "3000:\tlearn: 1.0852215\ttest: 1.0939500\tbest: 1.0939495 (2998)\ttotal: 15.9s\tremaining: 4m 9s\n",
            "3100:\tlearn: 1.0850396\ttest: 1.0939007\tbest: 1.0938982 (3099)\ttotal: 16.5s\tremaining: 4m 8s\n",
            "3200:\tlearn: 1.0848675\ttest: 1.0938635\tbest: 1.0938578 (3193)\ttotal: 17s\tremaining: 4m 8s\n",
            "3300:\tlearn: 1.0846792\ttest: 1.0938136\tbest: 1.0938125 (3287)\ttotal: 17.5s\tremaining: 4m 7s\n",
            "3400:\tlearn: 1.0844995\ttest: 1.0937876\tbest: 1.0937811 (3372)\ttotal: 18s\tremaining: 4m 7s\n",
            "3500:\tlearn: 1.0843351\ttest: 1.0937525\tbest: 1.0937517 (3493)\ttotal: 18.5s\tremaining: 4m 6s\n",
            "3600:\tlearn: 1.0841609\ttest: 1.0937302\tbest: 1.0937281 (3598)\ttotal: 19.1s\tremaining: 4m 5s\n",
            "3700:\tlearn: 1.0839938\ttest: 1.0937067\tbest: 1.0937053 (3698)\ttotal: 19.6s\tremaining: 4m 5s\n",
            "3800:\tlearn: 1.0838396\ttest: 1.0936761\tbest: 1.0936761 (3800)\ttotal: 20.1s\tremaining: 4m 4s\n",
            "3900:\tlearn: 1.0836883\ttest: 1.0936568\tbest: 1.0936550 (3864)\ttotal: 20.7s\tremaining: 4m 4s\n",
            "4000:\tlearn: 1.0835384\ttest: 1.0936379\tbest: 1.0936379 (4000)\ttotal: 21.2s\tremaining: 4m 3s\n",
            "4100:\tlearn: 1.0833839\ttest: 1.0936353\tbest: 1.0936313 (4079)\ttotal: 21.7s\tremaining: 4m 3s\n",
            "4200:\tlearn: 1.0832406\ttest: 1.0936100\tbest: 1.0936100 (4200)\ttotal: 22.3s\tremaining: 4m 2s\n",
            "4300:\tlearn: 1.0831048\ttest: 1.0935969\tbest: 1.0935937 (4282)\ttotal: 22.8s\tremaining: 4m 2s\n",
            "4400:\tlearn: 1.0829550\ttest: 1.0935692\tbest: 1.0935673 (4396)\ttotal: 23.3s\tremaining: 4m 1s\n",
            "4500:\tlearn: 1.0828232\ttest: 1.0935595\tbest: 1.0935531 (4483)\ttotal: 23.8s\tremaining: 4m 1s\n",
            "4600:\tlearn: 1.0826937\ttest: 1.0935345\tbest: 1.0935339 (4599)\ttotal: 24.4s\tremaining: 4m\n",
            "4700:\tlearn: 1.0825652\ttest: 1.0935262\tbest: 1.0935229 (4682)\ttotal: 24.9s\tremaining: 3m 59s\n",
            "4800:\tlearn: 1.0824412\ttest: 1.0935110\tbest: 1.0935096 (4729)\ttotal: 25.4s\tremaining: 3m 59s\n",
            "4900:\tlearn: 1.0823135\ttest: 1.0934979\tbest: 1.0934946 (4837)\ttotal: 25.9s\tremaining: 3m 58s\n",
            "5000:\tlearn: 1.0821897\ttest: 1.0934855\tbest: 1.0934811 (4989)\ttotal: 26.5s\tremaining: 3m 58s\n",
            "5100:\tlearn: 1.0820710\ttest: 1.0934741\tbest: 1.0934741 (5100)\ttotal: 27s\tremaining: 3m 57s\n",
            "5200:\tlearn: 1.0819444\ttest: 1.0934687\tbest: 1.0934659 (5196)\ttotal: 27.5s\tremaining: 3m 56s\n",
            "5300:\tlearn: 1.0818306\ttest: 1.0934631\tbest: 1.0934592 (5269)\ttotal: 28s\tremaining: 3m 56s\n",
            "5400:\tlearn: 1.0817221\ttest: 1.0934666\tbest: 1.0934572 (5305)\ttotal: 28.6s\tremaining: 3m 55s\n",
            "5500:\tlearn: 1.0816147\ttest: 1.0934446\tbest: 1.0934446 (5500)\ttotal: 29.1s\tremaining: 3m 55s\n",
            "5600:\tlearn: 1.0815021\ttest: 1.0934369\tbest: 1.0934327 (5551)\ttotal: 29.6s\tremaining: 3m 54s\n",
            "5700:\tlearn: 1.0813870\ttest: 1.0934480\tbest: 1.0934327 (5551)\ttotal: 30.2s\tremaining: 3m 54s\n",
            "5800:\tlearn: 1.0812813\ttest: 1.0934628\tbest: 1.0934327 (5551)\ttotal: 30.7s\tremaining: 3m 53s\n",
            "5900:\tlearn: 1.0811746\ttest: 1.0934451\tbest: 1.0934327 (5551)\ttotal: 31.2s\tremaining: 3m 53s\n",
            "6000:\tlearn: 1.0810677\ttest: 1.0934485\tbest: 1.0934327 (5551)\ttotal: 31.7s\tremaining: 3m 52s\n",
            "6100:\tlearn: 1.0809536\ttest: 1.0934425\tbest: 1.0934327 (5551)\ttotal: 32.3s\tremaining: 3m 52s\n",
            "6200:\tlearn: 1.0808517\ttest: 1.0934399\tbest: 1.0934327 (5551)\ttotal: 32.8s\tremaining: 3m 51s\n",
            "6300:\tlearn: 1.0807491\ttest: 1.0934285\tbest: 1.0934285 (6300)\ttotal: 33.4s\tremaining: 3m 51s\n",
            "6400:\tlearn: 1.0806472\ttest: 1.0934194\tbest: 1.0934146 (6378)\ttotal: 33.9s\tremaining: 3m 50s\n",
            "6500:\tlearn: 1.0805467\ttest: 1.0934218\tbest: 1.0934107 (6420)\ttotal: 34.4s\tremaining: 3m 50s\n",
            "6600:\tlearn: 1.0804490\ttest: 1.0934153\tbest: 1.0934107 (6420)\ttotal: 35s\tremaining: 3m 50s\n",
            "6700:\tlearn: 1.0803466\ttest: 1.0934079\tbest: 1.0934063 (6699)\ttotal: 35.5s\tremaining: 3m 49s\n",
            "6800:\tlearn: 1.0802427\ttest: 1.0933948\tbest: 1.0933937 (6797)\ttotal: 36.1s\tremaining: 3m 49s\n",
            "6900:\tlearn: 1.0801522\ttest: 1.0933914\tbest: 1.0933874 (6892)\ttotal: 36.6s\tremaining: 3m 48s\n",
            "7000:\tlearn: 1.0800562\ttest: 1.0934104\tbest: 1.0933874 (6892)\ttotal: 37.1s\tremaining: 3m 48s\n",
            "7100:\tlearn: 1.0799745\ttest: 1.0934233\tbest: 1.0933874 (6892)\ttotal: 37.7s\tremaining: 3m 47s\n",
            "7200:\tlearn: 1.0798817\ttest: 1.0934201\tbest: 1.0933874 (6892)\ttotal: 38.2s\tremaining: 3m 47s\n",
            "7300:\tlearn: 1.0797877\ttest: 1.0934315\tbest: 1.0933874 (6892)\ttotal: 38.8s\tremaining: 3m 46s\n",
            "7400:\tlearn: 1.0796811\ttest: 1.0934380\tbest: 1.0933874 (6892)\ttotal: 39.3s\tremaining: 3m 46s\n",
            "7500:\tlearn: 1.0795872\ttest: 1.0934344\tbest: 1.0933874 (6892)\ttotal: 39.9s\tremaining: 3m 45s\n",
            "7600:\tlearn: 1.0794907\ttest: 1.0934300\tbest: 1.0933874 (6892)\ttotal: 40.4s\tremaining: 3m 45s\n",
            "7700:\tlearn: 1.0794058\ttest: 1.0934383\tbest: 1.0933874 (6892)\ttotal: 41s\tremaining: 3m 44s\n",
            "7800:\tlearn: 1.0793132\ttest: 1.0934434\tbest: 1.0933874 (6892)\ttotal: 41.5s\tremaining: 3m 44s\n",
            "bestTest = 1.093387402\n",
            "bestIteration = 6892\n",
            "Shrink model to first 6893 iterations.\n",
            "0:\tlearn: 1.3669260\ttest: 1.3668943\tbest: 1.3668943 (0)\ttotal: 5.61ms\tremaining: 4m 40s\n",
            "100:\tlearn: 1.1115302\ttest: 1.1119359\tbest: 1.1119359 (100)\ttotal: 444ms\tremaining: 3m 39s\n",
            "200:\tlearn: 1.1063576\ttest: 1.1075965\tbest: 1.1075965 (200)\ttotal: 878ms\tremaining: 3m 37s\n",
            "300:\tlearn: 1.1030495\ttest: 1.1048321\tbest: 1.1048321 (300)\ttotal: 1.33s\tremaining: 3m 39s\n",
            "400:\tlearn: 1.1004771\ttest: 1.1027334\tbest: 1.1027334 (400)\ttotal: 1.8s\tremaining: 3m 42s\n",
            "500:\tlearn: 1.0984386\ttest: 1.1011777\tbest: 1.1011777 (500)\ttotal: 2.28s\tremaining: 3m 45s\n",
            "600:\tlearn: 1.0967135\ttest: 1.0999354\tbest: 1.0999354 (600)\ttotal: 2.77s\tremaining: 3m 47s\n",
            "700:\tlearn: 1.0953136\ttest: 1.0988917\tbest: 1.0988917 (700)\ttotal: 3.32s\tremaining: 3m 53s\n",
            "800:\tlearn: 1.0941401\ttest: 1.0981536\tbest: 1.0981536 (800)\ttotal: 3.84s\tremaining: 3m 55s\n",
            "900:\tlearn: 1.0931298\ttest: 1.0974814\tbest: 1.0974814 (900)\ttotal: 4.36s\tremaining: 3m 57s\n",
            "1000:\tlearn: 1.0922909\ttest: 1.0970177\tbest: 1.0970177 (1000)\ttotal: 4.89s\tremaining: 3m 59s\n",
            "1100:\tlearn: 1.0915204\ttest: 1.0966147\tbest: 1.0966147 (1100)\ttotal: 5.41s\tremaining: 4m\n",
            "1200:\tlearn: 1.0908904\ttest: 1.0962935\tbest: 1.0962935 (1200)\ttotal: 5.93s\tremaining: 4m 1s\n",
            "1300:\tlearn: 1.0902928\ttest: 1.0959739\tbest: 1.0959739 (1300)\ttotal: 6.46s\tremaining: 4m 1s\n",
            "1400:\tlearn: 1.0897436\ttest: 1.0957175\tbest: 1.0957175 (1400)\ttotal: 6.99s\tremaining: 4m 2s\n",
            "1500:\tlearn: 1.0892780\ttest: 1.0955048\tbest: 1.0955048 (1500)\ttotal: 7.53s\tremaining: 4m 3s\n",
            "1600:\tlearn: 1.0888686\ttest: 1.0953198\tbest: 1.0953198 (1600)\ttotal: 8.07s\tremaining: 4m 4s\n",
            "1700:\tlearn: 1.0884722\ttest: 1.0951467\tbest: 1.0951467 (1700)\ttotal: 8.61s\tremaining: 4m 4s\n",
            "1800:\tlearn: 1.0881085\ttest: 1.0949942\tbest: 1.0949942 (1800)\ttotal: 9.14s\tremaining: 4m 4s\n",
            "1900:\tlearn: 1.0877934\ttest: 1.0948726\tbest: 1.0948726 (1900)\ttotal: 9.67s\tremaining: 4m 4s\n",
            "2000:\tlearn: 1.0874710\ttest: 1.0947500\tbest: 1.0947492 (1999)\ttotal: 10.2s\tremaining: 4m 4s\n",
            "2100:\tlearn: 1.0871782\ttest: 1.0946265\tbest: 1.0946262 (2097)\ttotal: 10.7s\tremaining: 4m 4s\n",
            "2200:\tlearn: 1.0869020\ttest: 1.0945198\tbest: 1.0945188 (2198)\ttotal: 11.2s\tremaining: 4m 3s\n",
            "2300:\tlearn: 1.0866129\ttest: 1.0944354\tbest: 1.0944354 (2300)\ttotal: 11.8s\tremaining: 4m 3s\n",
            "2400:\tlearn: 1.0863506\ttest: 1.0943604\tbest: 1.0943571 (2395)\ttotal: 12.3s\tremaining: 4m 3s\n",
            "2500:\tlearn: 1.0861181\ttest: 1.0942606\tbest: 1.0942549 (2498)\ttotal: 12.8s\tremaining: 4m 3s\n",
            "2600:\tlearn: 1.0858814\ttest: 1.0941760\tbest: 1.0941740 (2597)\ttotal: 13.3s\tremaining: 4m 3s\n",
            "2700:\tlearn: 1.0856608\ttest: 1.0941203\tbest: 1.0941201 (2695)\ttotal: 13.9s\tremaining: 4m 2s\n",
            "2800:\tlearn: 1.0854386\ttest: 1.0940554\tbest: 1.0940549 (2798)\ttotal: 14.4s\tremaining: 4m 2s\n",
            "2900:\tlearn: 1.0852325\ttest: 1.0940042\tbest: 1.0940040 (2897)\ttotal: 14.9s\tremaining: 4m 2s\n",
            "3000:\tlearn: 1.0850473\ttest: 1.0939552\tbest: 1.0939552 (3000)\ttotal: 15.4s\tremaining: 4m 1s\n",
            "3100:\tlearn: 1.0848702\ttest: 1.0939190\tbest: 1.0939161 (3095)\ttotal: 15.9s\tremaining: 4m 1s\n",
            "3200:\tlearn: 1.0846707\ttest: 1.0938799\tbest: 1.0938799 (3200)\ttotal: 16.5s\tremaining: 4m\n",
            "3300:\tlearn: 1.0844978\ttest: 1.0938377\tbest: 1.0938374 (3293)\ttotal: 17s\tremaining: 4m\n",
            "3400:\tlearn: 1.0843185\ttest: 1.0938144\tbest: 1.0938085 (3388)\ttotal: 17.5s\tremaining: 4m\n",
            "3500:\tlearn: 1.0841394\ttest: 1.0937647\tbest: 1.0937640 (3496)\ttotal: 18.1s\tremaining: 3m 59s\n",
            "3600:\tlearn: 1.0839670\ttest: 1.0937287\tbest: 1.0937243 (3584)\ttotal: 18.6s\tremaining: 3m 59s\n",
            "3700:\tlearn: 1.0838086\ttest: 1.0936902\tbest: 1.0936900 (3690)\ttotal: 19.1s\tremaining: 3m 58s\n",
            "3800:\tlearn: 1.0836501\ttest: 1.0936649\tbest: 1.0936631 (3790)\ttotal: 19.6s\tremaining: 3m 58s\n",
            "3900:\tlearn: 1.0834936\ttest: 1.0936356\tbest: 1.0936337 (3899)\ttotal: 20.2s\tremaining: 3m 58s\n",
            "4000:\tlearn: 1.0833463\ttest: 1.0936144\tbest: 1.0936086 (3982)\ttotal: 20.7s\tremaining: 3m 57s\n",
            "4100:\tlearn: 1.0831841\ttest: 1.0936081\tbest: 1.0935972 (4070)\ttotal: 21.2s\tremaining: 3m 57s\n",
            "4200:\tlearn: 1.0830348\ttest: 1.0935824\tbest: 1.0935782 (4182)\ttotal: 21.7s\tremaining: 3m 57s\n",
            "4300:\tlearn: 1.0828899\ttest: 1.0935673\tbest: 1.0935619 (4294)\ttotal: 22.3s\tremaining: 3m 56s\n",
            "4400:\tlearn: 1.0827597\ttest: 1.0935484\tbest: 1.0935427 (4383)\ttotal: 22.8s\tremaining: 3m 56s\n",
            "4500:\tlearn: 1.0826276\ttest: 1.0935247\tbest: 1.0935210 (4482)\ttotal: 23.3s\tremaining: 3m 55s\n",
            "4600:\tlearn: 1.0824953\ttest: 1.0935177\tbest: 1.0935132 (4593)\ttotal: 23.9s\tremaining: 3m 55s\n",
            "4700:\tlearn: 1.0823772\ttest: 1.0935031\tbest: 1.0935008 (4684)\ttotal: 24.4s\tremaining: 3m 54s\n",
            "4800:\tlearn: 1.0822402\ttest: 1.0934907\tbest: 1.0934836 (4753)\ttotal: 24.9s\tremaining: 3m 54s\n",
            "4900:\tlearn: 1.0821238\ttest: 1.0934776\tbest: 1.0934725 (4874)\ttotal: 25.4s\tremaining: 3m 53s\n",
            "5000:\tlearn: 1.0820007\ttest: 1.0934655\tbest: 1.0934619 (4994)\ttotal: 25.9s\tremaining: 3m 53s\n",
            "5100:\tlearn: 1.0818853\ttest: 1.0934486\tbest: 1.0934450 (5083)\ttotal: 26.5s\tremaining: 3m 52s\n",
            "5200:\tlearn: 1.0817636\ttest: 1.0934386\tbest: 1.0934333 (5173)\ttotal: 27s\tremaining: 3m 52s\n",
            "5300:\tlearn: 1.0816537\ttest: 1.0934294\tbest: 1.0934221 (5283)\ttotal: 27.5s\tremaining: 3m 52s\n",
            "5400:\tlearn: 1.0815331\ttest: 1.0934475\tbest: 1.0934221 (5283)\ttotal: 28.1s\tremaining: 3m 51s\n",
            "5500:\tlearn: 1.0814157\ttest: 1.0934476\tbest: 1.0934221 (5283)\ttotal: 28.6s\tremaining: 3m 51s\n",
            "5600:\tlearn: 1.0813000\ttest: 1.0934418\tbest: 1.0934221 (5283)\ttotal: 29.1s\tremaining: 3m 50s\n",
            "5700:\tlearn: 1.0811948\ttest: 1.0934452\tbest: 1.0934221 (5283)\ttotal: 29.6s\tremaining: 3m 50s\n",
            "5800:\tlearn: 1.0810865\ttest: 1.0934326\tbest: 1.0934221 (5283)\ttotal: 30.2s\tremaining: 3m 49s\n",
            "5900:\tlearn: 1.0809694\ttest: 1.0934317\tbest: 1.0934204 (5821)\ttotal: 30.7s\tremaining: 3m 49s\n",
            "6000:\tlearn: 1.0808746\ttest: 1.0934436\tbest: 1.0934204 (5821)\ttotal: 31.2s\tremaining: 3m 48s\n",
            "6100:\tlearn: 1.0807675\ttest: 1.0934424\tbest: 1.0934204 (5821)\ttotal: 31.7s\tremaining: 3m 48s\n",
            "6200:\tlearn: 1.0806574\ttest: 1.0934397\tbest: 1.0934204 (5821)\ttotal: 32.3s\tremaining: 3m 47s\n",
            "6300:\tlearn: 1.0805576\ttest: 1.0934517\tbest: 1.0934204 (5821)\ttotal: 32.8s\tremaining: 3m 47s\n",
            "6400:\tlearn: 1.0804408\ttest: 1.0934374\tbest: 1.0934204 (5821)\ttotal: 33.4s\tremaining: 3m 47s\n",
            "6500:\tlearn: 1.0803402\ttest: 1.0934253\tbest: 1.0934204 (5821)\ttotal: 34s\tremaining: 3m 47s\n",
            "6600:\tlearn: 1.0802393\ttest: 1.0934320\tbest: 1.0934204 (5821)\ttotal: 34.5s\tremaining: 3m 46s\n",
            "6700:\tlearn: 1.0801429\ttest: 1.0934180\tbest: 1.0934158 (6698)\ttotal: 35.1s\tremaining: 3m 46s\n",
            "6800:\tlearn: 1.0800499\ttest: 1.0934199\tbest: 1.0934142 (6764)\ttotal: 35.6s\tremaining: 3m 46s\n",
            "6900:\tlearn: 1.0799440\ttest: 1.0934300\tbest: 1.0934142 (6764)\ttotal: 36.1s\tremaining: 3m 45s\n",
            "7000:\tlearn: 1.0798421\ttest: 1.0934268\tbest: 1.0934142 (6764)\ttotal: 36.7s\tremaining: 3m 45s\n",
            "7100:\tlearn: 1.0797436\ttest: 1.0934302\tbest: 1.0934142 (6764)\ttotal: 37.3s\tremaining: 3m 45s\n",
            "7200:\tlearn: 1.0796499\ttest: 1.0934455\tbest: 1.0934142 (6764)\ttotal: 37.8s\tremaining: 3m 44s\n",
            "7300:\tlearn: 1.0795482\ttest: 1.0934450\tbest: 1.0934142 (6764)\ttotal: 38.3s\tremaining: 3m 44s\n",
            "7400:\tlearn: 1.0794511\ttest: 1.0934683\tbest: 1.0934142 (6764)\ttotal: 38.9s\tremaining: 3m 44s\n",
            "7500:\tlearn: 1.0793604\ttest: 1.0934673\tbest: 1.0934142 (6764)\ttotal: 39.5s\tremaining: 3m 43s\n",
            "7600:\tlearn: 1.0792696\ttest: 1.0934838\tbest: 1.0934142 (6764)\ttotal: 40s\tremaining: 3m 43s\n",
            "7700:\tlearn: 1.0791842\ttest: 1.0934763\tbest: 1.0934142 (6764)\ttotal: 40.6s\tremaining: 3m 42s\n",
            "bestTest = 1.09341416\n",
            "bestIteration = 6764\n",
            "Shrink model to first 6765 iterations.\n",
            "fold: 2,log_loss: 1.093304888016366\n",
            "0:\tlearn: 1.3666909\ttest: 1.3666784\tbest: 1.3666784 (0)\ttotal: 5.86ms\tremaining: 4m 53s\n",
            "100:\tlearn: 1.1115661\ttest: 1.1124316\tbest: 1.1124316 (100)\ttotal: 446ms\tremaining: 3m 40s\n",
            "200:\tlearn: 1.1067134\ttest: 1.1077248\tbest: 1.1077248 (200)\ttotal: 875ms\tremaining: 3m 36s\n",
            "300:\tlearn: 1.1035060\ttest: 1.1046698\tbest: 1.1046698 (300)\ttotal: 1.32s\tremaining: 3m 37s\n",
            "400:\tlearn: 1.1010704\ttest: 1.1024103\tbest: 1.1024103 (400)\ttotal: 1.76s\tremaining: 3m 38s\n",
            "500:\tlearn: 1.0990289\ttest: 1.1005146\tbest: 1.1005146 (500)\ttotal: 2.2s\tremaining: 3m 37s\n",
            "600:\tlearn: 1.0974415\ttest: 1.0990000\tbest: 1.0990000 (600)\ttotal: 2.72s\tremaining: 3m 43s\n",
            "700:\tlearn: 1.0961068\ttest: 1.0977811\tbest: 1.0977811 (700)\ttotal: 3.25s\tremaining: 3m 48s\n",
            "800:\tlearn: 1.0950075\ttest: 1.0968422\tbest: 1.0968422 (800)\ttotal: 3.78s\tremaining: 3m 51s\n",
            "900:\tlearn: 1.0940829\ttest: 1.0959996\tbest: 1.0959996 (900)\ttotal: 4.28s\tremaining: 3m 53s\n",
            "1000:\tlearn: 1.0932789\ttest: 1.0953265\tbest: 1.0953265 (1000)\ttotal: 4.83s\tremaining: 3m 56s\n",
            "1100:\tlearn: 1.0926424\ttest: 1.0947898\tbest: 1.0947898 (1100)\ttotal: 5.36s\tremaining: 3m 58s\n",
            "1200:\tlearn: 1.0920198\ttest: 1.0942897\tbest: 1.0942897 (1200)\ttotal: 5.89s\tremaining: 3m 59s\n",
            "1300:\tlearn: 1.0914952\ttest: 1.0938896\tbest: 1.0938896 (1300)\ttotal: 6.43s\tremaining: 4m\n",
            "1400:\tlearn: 1.0910011\ttest: 1.0935119\tbest: 1.0935119 (1400)\ttotal: 6.94s\tremaining: 4m\n",
            "1500:\tlearn: 1.0905661\ttest: 1.0931733\tbest: 1.0931733 (1500)\ttotal: 7.47s\tremaining: 4m 1s\n",
            "1600:\tlearn: 1.0901720\ttest: 1.0928768\tbest: 1.0928768 (1600)\ttotal: 8s\tremaining: 4m 1s\n",
            "1700:\tlearn: 1.0898164\ttest: 1.0926246\tbest: 1.0926246 (1700)\ttotal: 8.53s\tremaining: 4m 2s\n",
            "1800:\tlearn: 1.0894435\ttest: 1.0923717\tbest: 1.0923717 (1800)\ttotal: 9.06s\tremaining: 4m 2s\n",
            "1900:\tlearn: 1.0891098\ttest: 1.0921091\tbest: 1.0921071 (1898)\ttotal: 9.58s\tremaining: 4m 2s\n",
            "2000:\tlearn: 1.0888282\ttest: 1.0919308\tbest: 1.0919308 (2000)\ttotal: 10.1s\tremaining: 4m 2s\n",
            "2100:\tlearn: 1.0885551\ttest: 1.0917782\tbest: 1.0917782 (2100)\ttotal: 10.6s\tremaining: 4m 2s\n",
            "2200:\tlearn: 1.0883010\ttest: 1.0916170\tbest: 1.0916170 (2200)\ttotal: 11.2s\tremaining: 4m 2s\n",
            "2300:\tlearn: 1.0880541\ttest: 1.0914482\tbest: 1.0914482 (2300)\ttotal: 11.7s\tremaining: 4m 2s\n",
            "2400:\tlearn: 1.0878108\ttest: 1.0913055\tbest: 1.0913035 (2392)\ttotal: 12.2s\tremaining: 4m 2s\n",
            "2500:\tlearn: 1.0875762\ttest: 1.0911816\tbest: 1.0911816 (2500)\ttotal: 12.7s\tremaining: 4m 1s\n",
            "2600:\tlearn: 1.0873731\ttest: 1.0910893\tbest: 1.0910893 (2600)\ttotal: 13.3s\tremaining: 4m 1s\n",
            "2700:\tlearn: 1.0871712\ttest: 1.0909793\tbest: 1.0909793 (2700)\ttotal: 13.8s\tremaining: 4m 1s\n",
            "2800:\tlearn: 1.0869645\ttest: 1.0908440\tbest: 1.0908440 (2800)\ttotal: 14.3s\tremaining: 4m 1s\n",
            "2900:\tlearn: 1.0867833\ttest: 1.0907601\tbest: 1.0907569 (2896)\ttotal: 14.8s\tremaining: 4m\n",
            "3000:\tlearn: 1.0865919\ttest: 1.0906920\tbest: 1.0906920 (3000)\ttotal: 15.3s\tremaining: 4m\n",
            "3100:\tlearn: 1.0863919\ttest: 1.0905823\tbest: 1.0905815 (3099)\ttotal: 15.9s\tremaining: 3m 59s\n",
            "3200:\tlearn: 1.0862233\ttest: 1.0905133\tbest: 1.0905121 (3199)\ttotal: 16.4s\tremaining: 3m 59s\n",
            "3300:\tlearn: 1.0860589\ttest: 1.0904265\tbest: 1.0904261 (3298)\ttotal: 16.9s\tremaining: 3m 59s\n",
            "3400:\tlearn: 1.0859015\ttest: 1.0903706\tbest: 1.0903700 (3399)\ttotal: 17.4s\tremaining: 3m 58s\n",
            "3500:\tlearn: 1.0857473\ttest: 1.0902998\tbest: 1.0902994 (3499)\ttotal: 18s\tremaining: 3m 58s\n",
            "3600:\tlearn: 1.0855963\ttest: 1.0902297\tbest: 1.0902297 (3600)\ttotal: 18.5s\tremaining: 3m 58s\n",
            "3700:\tlearn: 1.0854493\ttest: 1.0901761\tbest: 1.0901761 (3700)\ttotal: 19s\tremaining: 3m 58s\n",
            "3800:\tlearn: 1.0852953\ttest: 1.0901014\tbest: 1.0901014 (3800)\ttotal: 19.6s\tremaining: 3m 57s\n",
            "3900:\tlearn: 1.0851450\ttest: 1.0900362\tbest: 1.0900347 (3896)\ttotal: 20.1s\tremaining: 3m 57s\n",
            "4000:\tlearn: 1.0850038\ttest: 1.0899638\tbest: 1.0899638 (4000)\ttotal: 20.6s\tremaining: 3m 57s\n",
            "4100:\tlearn: 1.0848576\ttest: 1.0899168\tbest: 1.0899168 (4100)\ttotal: 21.2s\tremaining: 3m 57s\n",
            "4200:\tlearn: 1.0847383\ttest: 1.0898877\tbest: 1.0898862 (4194)\ttotal: 21.7s\tremaining: 3m 56s\n",
            "4300:\tlearn: 1.0845987\ttest: 1.0898355\tbest: 1.0898330 (4294)\ttotal: 22.2s\tremaining: 3m 55s\n",
            "4400:\tlearn: 1.0844723\ttest: 1.0897774\tbest: 1.0897774 (4400)\ttotal: 22.7s\tremaining: 3m 55s\n",
            "4500:\tlearn: 1.0843446\ttest: 1.0897452\tbest: 1.0897436 (4496)\ttotal: 23.3s\tremaining: 3m 55s\n",
            "4600:\tlearn: 1.0842164\ttest: 1.0896956\tbest: 1.0896956 (4600)\ttotal: 23.8s\tremaining: 3m 54s\n",
            "4700:\tlearn: 1.0840927\ttest: 1.0896660\tbest: 1.0896615 (4680)\ttotal: 24.3s\tremaining: 3m 54s\n",
            "4800:\tlearn: 1.0839638\ttest: 1.0896252\tbest: 1.0896237 (4784)\ttotal: 24.8s\tremaining: 3m 53s\n",
            "4900:\tlearn: 1.0838421\ttest: 1.0895901\tbest: 1.0895879 (4892)\ttotal: 25.4s\tremaining: 3m 53s\n",
            "5000:\tlearn: 1.0837278\ttest: 1.0895524\tbest: 1.0895524 (5000)\ttotal: 25.9s\tremaining: 3m 53s\n",
            "5100:\tlearn: 1.0836166\ttest: 1.0895130\tbest: 1.0895129 (5095)\ttotal: 26.5s\tremaining: 3m 52s\n",
            "5200:\tlearn: 1.0835057\ttest: 1.0894956\tbest: 1.0894946 (5198)\ttotal: 27s\tremaining: 3m 52s\n",
            "5300:\tlearn: 1.0833959\ttest: 1.0894758\tbest: 1.0894716 (5292)\ttotal: 27.5s\tremaining: 3m 51s\n",
            "5400:\tlearn: 1.0832958\ttest: 1.0894566\tbest: 1.0894566 (5400)\ttotal: 28s\tremaining: 3m 51s\n",
            "5500:\tlearn: 1.0831949\ttest: 1.0894439\tbest: 1.0894426 (5498)\ttotal: 28.5s\tremaining: 3m 50s\n",
            "5600:\tlearn: 1.0830905\ttest: 1.0894024\tbest: 1.0894024 (5600)\ttotal: 29.1s\tremaining: 3m 50s\n",
            "5700:\tlearn: 1.0829889\ttest: 1.0893829\tbest: 1.0893829 (5700)\ttotal: 29.6s\tremaining: 3m 50s\n",
            "5800:\tlearn: 1.0828769\ttest: 1.0893710\tbest: 1.0893686 (5766)\ttotal: 30.1s\tremaining: 3m 49s\n",
            "5900:\tlearn: 1.0827676\ttest: 1.0893512\tbest: 1.0893504 (5897)\ttotal: 30.7s\tremaining: 3m 49s\n",
            "6000:\tlearn: 1.0826709\ttest: 1.0893180\tbest: 1.0893180 (6000)\ttotal: 31.2s\tremaining: 3m 48s\n",
            "6100:\tlearn: 1.0825766\ttest: 1.0893024\tbest: 1.0893016 (6088)\ttotal: 31.8s\tremaining: 3m 48s\n",
            "6200:\tlearn: 1.0824792\ttest: 1.0892770\tbest: 1.0892770 (6200)\ttotal: 32.3s\tremaining: 3m 48s\n",
            "6300:\tlearn: 1.0823904\ttest: 1.0892643\tbest: 1.0892605 (6288)\ttotal: 32.9s\tremaining: 3m 47s\n",
            "6400:\tlearn: 1.0822918\ttest: 1.0892503\tbest: 1.0892495 (6399)\ttotal: 33.4s\tremaining: 3m 47s\n",
            "6500:\tlearn: 1.0822063\ttest: 1.0892303\tbest: 1.0892271 (6491)\ttotal: 34s\tremaining: 3m 47s\n",
            "6600:\tlearn: 1.0821115\ttest: 1.0892222\tbest: 1.0892211 (6515)\ttotal: 34.5s\tremaining: 3m 47s\n",
            "6700:\tlearn: 1.0820139\ttest: 1.0892022\tbest: 1.0892017 (6694)\ttotal: 35.1s\tremaining: 3m 46s\n",
            "6800:\tlearn: 1.0819287\ttest: 1.0891938\tbest: 1.0891882 (6793)\ttotal: 35.6s\tremaining: 3m 46s\n",
            "6900:\tlearn: 1.0818365\ttest: 1.0891763\tbest: 1.0891761 (6898)\ttotal: 36.2s\tremaining: 3m 46s\n",
            "7000:\tlearn: 1.0817423\ttest: 1.0891596\tbest: 1.0891592 (6999)\ttotal: 36.7s\tremaining: 3m 45s\n",
            "7100:\tlearn: 1.0816513\ttest: 1.0891548\tbest: 1.0891497 (7092)\ttotal: 37.3s\tremaining: 3m 45s\n",
            "7200:\tlearn: 1.0815603\ttest: 1.0891275\tbest: 1.0891275 (7200)\ttotal: 37.9s\tremaining: 3m 45s\n",
            "7300:\tlearn: 1.0814700\ttest: 1.0891142\tbest: 1.0891121 (7293)\ttotal: 38.4s\tremaining: 3m 44s\n",
            "7400:\tlearn: 1.0813859\ttest: 1.0891102\tbest: 1.0891094 (7371)\ttotal: 39s\tremaining: 3m 44s\n",
            "7500:\tlearn: 1.0812895\ttest: 1.0891009\tbest: 1.0891009 (7500)\ttotal: 39.5s\tremaining: 3m 43s\n",
            "7600:\tlearn: 1.0812065\ttest: 1.0891040\tbest: 1.0890983 (7528)\ttotal: 40.1s\tremaining: 3m 43s\n",
            "7700:\tlearn: 1.0811223\ttest: 1.0890744\tbest: 1.0890744 (7698)\ttotal: 40.6s\tremaining: 3m 43s\n",
            "7800:\tlearn: 1.0810396\ttest: 1.0890712\tbest: 1.0890712 (7800)\ttotal: 41.2s\tremaining: 3m 42s\n",
            "7900:\tlearn: 1.0809519\ttest: 1.0890798\tbest: 1.0890694 (7820)\ttotal: 41.7s\tremaining: 3m 42s\n",
            "8000:\tlearn: 1.0808688\ttest: 1.0890795\tbest: 1.0890694 (7820)\ttotal: 42.3s\tremaining: 3m 41s\n",
            "8100:\tlearn: 1.0807851\ttest: 1.0890503\tbest: 1.0890487 (8097)\ttotal: 42.8s\tremaining: 3m 41s\n",
            "8200:\tlearn: 1.0806991\ttest: 1.0890731\tbest: 1.0890487 (8097)\ttotal: 43.4s\tremaining: 3m 40s\n",
            "8300:\tlearn: 1.0806149\ttest: 1.0890542\tbest: 1.0890487 (8097)\ttotal: 43.9s\tremaining: 3m 40s\n",
            "8400:\tlearn: 1.0805282\ttest: 1.0890545\tbest: 1.0890424 (8377)\ttotal: 44.5s\tremaining: 3m 40s\n",
            "8500:\tlearn: 1.0804488\ttest: 1.0890437\tbest: 1.0890424 (8377)\ttotal: 45s\tremaining: 3m 39s\n",
            "8600:\tlearn: 1.0803514\ttest: 1.0890169\tbest: 1.0890167 (8599)\ttotal: 45.6s\tremaining: 3m 39s\n",
            "8700:\tlearn: 1.0802688\ttest: 1.0889973\tbest: 1.0889944 (8693)\ttotal: 46.1s\tremaining: 3m 38s\n",
            "8800:\tlearn: 1.0801916\ttest: 1.0889955\tbest: 1.0889920 (8724)\ttotal: 46.7s\tremaining: 3m 38s\n",
            "8900:\tlearn: 1.0801094\ttest: 1.0889941\tbest: 1.0889920 (8724)\ttotal: 47.2s\tremaining: 3m 38s\n",
            "9000:\tlearn: 1.0800197\ttest: 1.0889887\tbest: 1.0889840 (8972)\ttotal: 47.8s\tremaining: 3m 37s\n",
            "9100:\tlearn: 1.0799427\ttest: 1.0889854\tbest: 1.0889804 (9081)\ttotal: 48.4s\tremaining: 3m 37s\n",
            "9200:\tlearn: 1.0798525\ttest: 1.0889878\tbest: 1.0889726 (9152)\ttotal: 48.9s\tremaining: 3m 37s\n",
            "9300:\tlearn: 1.0797770\ttest: 1.0889881\tbest: 1.0889726 (9152)\ttotal: 49.5s\tremaining: 3m 36s\n",
            "9400:\tlearn: 1.0797016\ttest: 1.0889834\tbest: 1.0889726 (9152)\ttotal: 50s\tremaining: 3m 36s\n",
            "9500:\tlearn: 1.0796241\ttest: 1.0889883\tbest: 1.0889726 (9152)\ttotal: 50.6s\tremaining: 3m 35s\n",
            "9600:\tlearn: 1.0795378\ttest: 1.0889884\tbest: 1.0889726 (9152)\ttotal: 51.2s\tremaining: 3m 35s\n",
            "9700:\tlearn: 1.0794726\ttest: 1.0889854\tbest: 1.0889726 (9152)\ttotal: 51.7s\tremaining: 3m 34s\n",
            "9800:\tlearn: 1.0793950\ttest: 1.0889873\tbest: 1.0889726 (9152)\ttotal: 52.3s\tremaining: 3m 34s\n",
            "9900:\tlearn: 1.0793212\ttest: 1.0889652\tbest: 1.0889649 (9899)\ttotal: 52.8s\tremaining: 3m 33s\n",
            "10000:\tlearn: 1.0792458\ttest: 1.0889654\tbest: 1.0889625 (9984)\ttotal: 53.4s\tremaining: 3m 33s\n",
            "10100:\tlearn: 1.0791661\ttest: 1.0889490\tbest: 1.0889468 (10097)\ttotal: 53.9s\tremaining: 3m 32s\n",
            "10200:\tlearn: 1.0790954\ttest: 1.0889326\tbest: 1.0889310 (10185)\ttotal: 54.5s\tremaining: 3m 32s\n",
            "10300:\tlearn: 1.0790245\ttest: 1.0889375\tbest: 1.0889289 (10225)\ttotal: 55s\tremaining: 3m 31s\n",
            "10400:\tlearn: 1.0789524\ttest: 1.0889362\tbest: 1.0889289 (10225)\ttotal: 55.5s\tremaining: 3m 31s\n",
            "10500:\tlearn: 1.0788842\ttest: 1.0889410\tbest: 1.0889289 (10225)\ttotal: 56.1s\tremaining: 3m 30s\n",
            "10600:\tlearn: 1.0788143\ttest: 1.0889579\tbest: 1.0889289 (10225)\ttotal: 56.6s\tremaining: 3m 30s\n",
            "10700:\tlearn: 1.0787376\ttest: 1.0889633\tbest: 1.0889289 (10225)\ttotal: 57.2s\tremaining: 3m 30s\n",
            "10800:\tlearn: 1.0786534\ttest: 1.0889528\tbest: 1.0889289 (10225)\ttotal: 57.8s\tremaining: 3m 29s\n",
            "10900:\tlearn: 1.0785855\ttest: 1.0889630\tbest: 1.0889289 (10225)\ttotal: 58.4s\tremaining: 3m 29s\n",
            "11000:\tlearn: 1.0785118\ttest: 1.0889517\tbest: 1.0889289 (10225)\ttotal: 59s\tremaining: 3m 29s\n",
            "11100:\tlearn: 1.0784378\ttest: 1.0889627\tbest: 1.0889289 (10225)\ttotal: 59.5s\tremaining: 3m 28s\n",
            "11200:\tlearn: 1.0783666\ttest: 1.0889652\tbest: 1.0889289 (10225)\ttotal: 1m\tremaining: 3m 28s\n",
            "bestTest = 1.088928906\n",
            "bestIteration = 10225\n",
            "Shrink model to first 10226 iterations.\n",
            "0:\tlearn: 1.3669119\ttest: 1.3669260\tbest: 1.3669260 (0)\ttotal: 5.52ms\tremaining: 4m 36s\n",
            "100:\tlearn: 1.1116416\ttest: 1.1124867\tbest: 1.1124867 (100)\ttotal: 472ms\tremaining: 3m 53s\n",
            "200:\tlearn: 1.1068799\ttest: 1.1078969\tbest: 1.1078969 (200)\ttotal: 925ms\tremaining: 3m 49s\n",
            "300:\tlearn: 1.1036200\ttest: 1.1047294\tbest: 1.1047294 (300)\ttotal: 1.4s\tremaining: 3m 51s\n",
            "400:\tlearn: 1.1010309\ttest: 1.1023046\tbest: 1.1023046 (400)\ttotal: 1.87s\tremaining: 3m 51s\n",
            "500:\tlearn: 1.0990385\ttest: 1.1004794\tbest: 1.1004794 (500)\ttotal: 2.36s\tremaining: 3m 53s\n",
            "600:\tlearn: 1.0974177\ttest: 1.0989866\tbest: 1.0989866 (600)\ttotal: 2.84s\tremaining: 3m 53s\n",
            "700:\tlearn: 1.0961066\ttest: 1.0977475\tbest: 1.0977475 (700)\ttotal: 3.33s\tremaining: 3m 54s\n",
            "800:\tlearn: 1.0950424\ttest: 1.0967735\tbest: 1.0967735 (800)\ttotal: 3.84s\tremaining: 3m 55s\n",
            "900:\tlearn: 1.0941808\ttest: 1.0960094\tbest: 1.0960094 (900)\ttotal: 4.34s\tremaining: 3m 56s\n",
            "1000:\tlearn: 1.0933500\ttest: 1.0952342\tbest: 1.0952342 (1000)\ttotal: 4.84s\tremaining: 3m 56s\n",
            "1100:\tlearn: 1.0927211\ttest: 1.0947081\tbest: 1.0947081 (1100)\ttotal: 5.34s\tremaining: 3m 57s\n",
            "1200:\tlearn: 1.0920815\ttest: 1.0941938\tbest: 1.0941938 (1200)\ttotal: 5.84s\tremaining: 3m 57s\n",
            "1300:\tlearn: 1.0915772\ttest: 1.0937721\tbest: 1.0937721 (1300)\ttotal: 6.34s\tremaining: 3m 57s\n",
            "1400:\tlearn: 1.0910961\ttest: 1.0933806\tbest: 1.0933806 (1400)\ttotal: 6.85s\tremaining: 3m 57s\n",
            "1500:\tlearn: 1.0906420\ttest: 1.0930348\tbest: 1.0930348 (1500)\ttotal: 7.34s\tremaining: 3m 57s\n",
            "1600:\tlearn: 1.0901923\ttest: 1.0927019\tbest: 1.0927019 (1600)\ttotal: 7.84s\tremaining: 3m 56s\n",
            "1700:\tlearn: 1.0898173\ttest: 1.0923906\tbest: 1.0923906 (1700)\ttotal: 8.32s\tremaining: 3m 56s\n",
            "1800:\tlearn: 1.0894419\ttest: 1.0921585\tbest: 1.0921585 (1800)\ttotal: 8.82s\tremaining: 3m 56s\n",
            "1900:\tlearn: 1.0891055\ttest: 1.0919045\tbest: 1.0919045 (1900)\ttotal: 9.32s\tremaining: 3m 55s\n",
            "2000:\tlearn: 1.0888024\ttest: 1.0917085\tbest: 1.0917085 (2000)\ttotal: 9.8s\tremaining: 3m 55s\n",
            "2100:\tlearn: 1.0885182\ttest: 1.0915201\tbest: 1.0915190 (2099)\ttotal: 10.3s\tremaining: 3m 54s\n",
            "2200:\tlearn: 1.0882502\ttest: 1.0913388\tbest: 1.0913388 (2200)\ttotal: 10.8s\tremaining: 3m 53s\n",
            "2300:\tlearn: 1.0879932\ttest: 1.0911922\tbest: 1.0911922 (2300)\ttotal: 11.3s\tremaining: 3m 53s\n",
            "2400:\tlearn: 1.0877497\ttest: 1.0910179\tbest: 1.0910179 (2400)\ttotal: 11.8s\tremaining: 3m 53s\n",
            "2500:\tlearn: 1.0875201\ttest: 1.0908939\tbest: 1.0908938 (2495)\ttotal: 12.3s\tremaining: 3m 52s\n",
            "2600:\tlearn: 1.0872965\ttest: 1.0907382\tbest: 1.0907379 (2599)\ttotal: 12.7s\tremaining: 3m 52s\n",
            "2700:\tlearn: 1.0870829\ttest: 1.0906169\tbest: 1.0906169 (2700)\ttotal: 13.2s\tremaining: 3m 51s\n",
            "2800:\tlearn: 1.0868795\ttest: 1.0905021\tbest: 1.0905021 (2800)\ttotal: 13.7s\tremaining: 3m 51s\n",
            "2900:\tlearn: 1.0866904\ttest: 1.0904210\tbest: 1.0904200 (2899)\ttotal: 14.2s\tremaining: 3m 50s\n",
            "3000:\tlearn: 1.0865138\ttest: 1.0903294\tbest: 1.0903294 (3000)\ttotal: 14.7s\tremaining: 3m 50s\n",
            "3100:\tlearn: 1.0863350\ttest: 1.0902250\tbest: 1.0902250 (3100)\ttotal: 15.2s\tremaining: 3m 50s\n",
            "3200:\tlearn: 1.0861618\ttest: 1.0901146\tbest: 1.0901134 (3198)\ttotal: 15.7s\tremaining: 3m 49s\n",
            "3300:\tlearn: 1.0860069\ttest: 1.0900510\tbest: 1.0900497 (3299)\ttotal: 16.2s\tremaining: 3m 49s\n",
            "3400:\tlearn: 1.0858354\ttest: 1.0900068\tbest: 1.0900009 (3387)\ttotal: 16.7s\tremaining: 3m 49s\n",
            "3500:\tlearn: 1.0856737\ttest: 1.0899180\tbest: 1.0899180 (3500)\ttotal: 17.2s\tremaining: 3m 49s\n",
            "3600:\tlearn: 1.0855226\ttest: 1.0898626\tbest: 1.0898626 (3600)\ttotal: 17.7s\tremaining: 3m 48s\n",
            "3700:\tlearn: 1.0853729\ttest: 1.0898097\tbest: 1.0898095 (3695)\ttotal: 18.2s\tremaining: 3m 47s\n",
            "3800:\tlearn: 1.0852164\ttest: 1.0897375\tbest: 1.0897375 (3800)\ttotal: 18.7s\tremaining: 3m 47s\n",
            "3900:\tlearn: 1.0850741\ttest: 1.0896651\tbest: 1.0896646 (3897)\ttotal: 19.2s\tremaining: 3m 47s\n",
            "4000:\tlearn: 1.0849321\ttest: 1.0896129\tbest: 1.0896129 (3998)\ttotal: 19.7s\tremaining: 3m 46s\n",
            "4100:\tlearn: 1.0847914\ttest: 1.0895613\tbest: 1.0895613 (4100)\ttotal: 20.2s\tremaining: 3m 46s\n",
            "4200:\tlearn: 1.0846645\ttest: 1.0894975\tbest: 1.0894969 (4199)\ttotal: 20.8s\tremaining: 3m 46s\n",
            "4300:\tlearn: 1.0845310\ttest: 1.0894539\tbest: 1.0894525 (4298)\ttotal: 21.3s\tremaining: 3m 45s\n",
            "4400:\tlearn: 1.0843958\ttest: 1.0894188\tbest: 1.0894181 (4397)\ttotal: 21.8s\tremaining: 3m 45s\n",
            "4500:\tlearn: 1.0842744\ttest: 1.0893729\tbest: 1.0893729 (4500)\ttotal: 22.2s\tremaining: 3m 44s\n",
            "4600:\tlearn: 1.0841435\ttest: 1.0893060\tbest: 1.0893060 (4600)\ttotal: 22.7s\tremaining: 3m 44s\n",
            "4700:\tlearn: 1.0840167\ttest: 1.0892374\tbest: 1.0892368 (4699)\ttotal: 23.2s\tremaining: 3m 43s\n",
            "4800:\tlearn: 1.0838993\ttest: 1.0891957\tbest: 1.0891957 (4800)\ttotal: 23.7s\tremaining: 3m 43s\n",
            "4900:\tlearn: 1.0837901\ttest: 1.0891659\tbest: 1.0891639 (4889)\ttotal: 24.2s\tremaining: 3m 42s\n",
            "5000:\tlearn: 1.0836784\ttest: 1.0891448\tbest: 1.0891438 (4999)\ttotal: 24.7s\tremaining: 3m 42s\n",
            "5100:\tlearn: 1.0835570\ttest: 1.0891098\tbest: 1.0891098 (5100)\ttotal: 25.2s\tremaining: 3m 41s\n",
            "5200:\tlearn: 1.0834359\ttest: 1.0890765\tbest: 1.0890754 (5198)\ttotal: 25.7s\tremaining: 3m 41s\n",
            "5300:\tlearn: 1.0833247\ttest: 1.0890515\tbest: 1.0890515 (5300)\ttotal: 26.2s\tremaining: 3m 40s\n",
            "5400:\tlearn: 1.0831969\ttest: 1.0890341\tbest: 1.0890341 (5400)\ttotal: 26.7s\tremaining: 3m 40s\n",
            "5500:\tlearn: 1.0830864\ttest: 1.0890069\tbest: 1.0890061 (5494)\ttotal: 27.3s\tremaining: 3m 40s\n",
            "5600:\tlearn: 1.0829866\ttest: 1.0889950\tbest: 1.0889950 (5600)\ttotal: 27.8s\tremaining: 3m 40s\n",
            "5700:\tlearn: 1.0828708\ttest: 1.0889612\tbest: 1.0889578 (5697)\ttotal: 28.3s\tremaining: 3m 39s\n",
            "5800:\tlearn: 1.0827703\ttest: 1.0889316\tbest: 1.0889315 (5799)\ttotal: 28.8s\tremaining: 3m 39s\n",
            "5900:\tlearn: 1.0826603\ttest: 1.0889213\tbest: 1.0889190 (5892)\ttotal: 29.4s\tremaining: 3m 39s\n",
            "6000:\tlearn: 1.0825619\ttest: 1.0888988\tbest: 1.0888988 (6000)\ttotal: 29.9s\tremaining: 3m 39s\n",
            "6100:\tlearn: 1.0824514\ttest: 1.0888939\tbest: 1.0888902 (6028)\ttotal: 30.4s\tremaining: 3m 38s\n",
            "6200:\tlearn: 1.0823449\ttest: 1.0888687\tbest: 1.0888687 (6200)\ttotal: 31s\tremaining: 3m 38s\n",
            "6300:\tlearn: 1.0822399\ttest: 1.0888539\tbest: 1.0888507 (6265)\ttotal: 31.5s\tremaining: 3m 38s\n",
            "6400:\tlearn: 1.0821358\ttest: 1.0888293\tbest: 1.0888291 (6381)\ttotal: 32.1s\tremaining: 3m 38s\n",
            "6500:\tlearn: 1.0820360\ttest: 1.0888071\tbest: 1.0888047 (6495)\ttotal: 32.7s\tremaining: 3m 38s\n",
            "6600:\tlearn: 1.0819330\ttest: 1.0887814\tbest: 1.0887778 (6592)\ttotal: 33.3s\tremaining: 3m 38s\n",
            "6700:\tlearn: 1.0818412\ttest: 1.0887823\tbest: 1.0887771 (6623)\ttotal: 33.9s\tremaining: 3m 38s\n",
            "6800:\tlearn: 1.0817516\ttest: 1.0887609\tbest: 1.0887606 (6762)\ttotal: 34.4s\tremaining: 3m 38s\n",
            "6900:\tlearn: 1.0816645\ttest: 1.0887495\tbest: 1.0887490 (6893)\ttotal: 34.9s\tremaining: 3m 37s\n",
            "7000:\tlearn: 1.0815722\ttest: 1.0887410\tbest: 1.0887410 (6996)\ttotal: 35.4s\tremaining: 3m 37s\n",
            "7100:\tlearn: 1.0814769\ttest: 1.0887239\tbest: 1.0887209 (7087)\ttotal: 36s\tremaining: 3m 37s\n",
            "7200:\tlearn: 1.0813858\ttest: 1.0887058\tbest: 1.0887017 (7186)\ttotal: 36.5s\tremaining: 3m 37s\n",
            "7300:\tlearn: 1.0812969\ttest: 1.0887005\tbest: 1.0886932 (7253)\ttotal: 37.1s\tremaining: 3m 36s\n",
            "7400:\tlearn: 1.0812110\ttest: 1.0886893\tbest: 1.0886893 (7400)\ttotal: 37.6s\tremaining: 3m 36s\n",
            "7500:\tlearn: 1.0811247\ttest: 1.0886863\tbest: 1.0886832 (7451)\ttotal: 38.2s\tremaining: 3m 36s\n",
            "7600:\tlearn: 1.0810409\ttest: 1.0886851\tbest: 1.0886832 (7451)\ttotal: 38.7s\tremaining: 3m 35s\n",
            "7700:\tlearn: 1.0809557\ttest: 1.0886763\tbest: 1.0886758 (7687)\ttotal: 39.3s\tremaining: 3m 35s\n",
            "7800:\tlearn: 1.0808680\ttest: 1.0886744\tbest: 1.0886740 (7799)\ttotal: 39.8s\tremaining: 3m 35s\n",
            "7900:\tlearn: 1.0807823\ttest: 1.0886578\tbest: 1.0886566 (7899)\ttotal: 40.4s\tremaining: 3m 35s\n",
            "8000:\tlearn: 1.0807011\ttest: 1.0886444\tbest: 1.0886437 (7998)\ttotal: 40.9s\tremaining: 3m 34s\n",
            "8100:\tlearn: 1.0806212\ttest: 1.0886282\tbest: 1.0886264 (8093)\ttotal: 41.5s\tremaining: 3m 34s\n",
            "8200:\tlearn: 1.0805344\ttest: 1.0886247\tbest: 1.0886233 (8145)\ttotal: 42s\tremaining: 3m 34s\n",
            "8300:\tlearn: 1.0804479\ttest: 1.0886229\tbest: 1.0886213 (8263)\ttotal: 42.6s\tremaining: 3m 33s\n",
            "8400:\tlearn: 1.0803607\ttest: 1.0886156\tbest: 1.0886102 (8361)\ttotal: 43.1s\tremaining: 3m 33s\n",
            "8500:\tlearn: 1.0802862\ttest: 1.0886176\tbest: 1.0886102 (8361)\ttotal: 43.7s\tremaining: 3m 33s\n",
            "8600:\tlearn: 1.0802111\ttest: 1.0886132\tbest: 1.0886102 (8361)\ttotal: 44.2s\tremaining: 3m 32s\n",
            "8700:\tlearn: 1.0801278\ttest: 1.0885858\tbest: 1.0885853 (8699)\ttotal: 44.8s\tremaining: 3m 32s\n",
            "8800:\tlearn: 1.0800516\ttest: 1.0885819\tbest: 1.0885793 (8742)\ttotal: 45.4s\tremaining: 3m 32s\n",
            "8900:\tlearn: 1.0799729\ttest: 1.0885705\tbest: 1.0885704 (8890)\ttotal: 45.9s\tremaining: 3m 31s\n",
            "9000:\tlearn: 1.0798932\ttest: 1.0885858\tbest: 1.0885698 (8905)\ttotal: 46.4s\tremaining: 3m 31s\n",
            "9100:\tlearn: 1.0798026\ttest: 1.0886059\tbest: 1.0885698 (8905)\ttotal: 47s\tremaining: 3m 31s\n",
            "9200:\tlearn: 1.0797231\ttest: 1.0885964\tbest: 1.0885698 (8905)\ttotal: 47.5s\tremaining: 3m 30s\n",
            "9300:\tlearn: 1.0796438\ttest: 1.0885891\tbest: 1.0885698 (8905)\ttotal: 48.1s\tremaining: 3m 30s\n",
            "9400:\tlearn: 1.0795708\ttest: 1.0885819\tbest: 1.0885698 (8905)\ttotal: 48.6s\tremaining: 3m 30s\n",
            "9500:\tlearn: 1.0794875\ttest: 1.0885758\tbest: 1.0885698 (8905)\ttotal: 49.2s\tremaining: 3m 29s\n",
            "9600:\tlearn: 1.0794102\ttest: 1.0885863\tbest: 1.0885698 (8905)\ttotal: 49.7s\tremaining: 3m 29s\n",
            "9700:\tlearn: 1.0793414\ttest: 1.0885637\tbest: 1.0885613 (9695)\ttotal: 50.3s\tremaining: 3m 28s\n",
            "9800:\tlearn: 1.0792663\ttest: 1.0885544\tbest: 1.0885494 (9770)\ttotal: 50.8s\tremaining: 3m 28s\n",
            "9900:\tlearn: 1.0791891\ttest: 1.0885310\tbest: 1.0885308 (9899)\ttotal: 51.4s\tremaining: 3m 28s\n",
            "10000:\tlearn: 1.0791202\ttest: 1.0885236\tbest: 1.0885209 (9935)\ttotal: 51.9s\tremaining: 3m 27s\n",
            "10100:\tlearn: 1.0790446\ttest: 1.0885100\tbest: 1.0885063 (10046)\ttotal: 52.5s\tremaining: 3m 27s\n",
            "10200:\tlearn: 1.0789731\ttest: 1.0885066\tbest: 1.0885019 (10192)\ttotal: 53.1s\tremaining: 3m 27s\n",
            "10300:\tlearn: 1.0788948\ttest: 1.0884987\tbest: 1.0884976 (10292)\ttotal: 53.7s\tremaining: 3m 26s\n",
            "10400:\tlearn: 1.0788162\ttest: 1.0884941\tbest: 1.0884870 (10352)\ttotal: 54.2s\tremaining: 3m 26s\n",
            "10500:\tlearn: 1.0787454\ttest: 1.0884952\tbest: 1.0884870 (10352)\ttotal: 54.8s\tremaining: 3m 25s\n",
            "10600:\tlearn: 1.0786691\ttest: 1.0884909\tbest: 1.0884870 (10352)\ttotal: 55.3s\tremaining: 3m 25s\n",
            "10700:\tlearn: 1.0785910\ttest: 1.0885053\tbest: 1.0884870 (10352)\ttotal: 55.9s\tremaining: 3m 25s\n",
            "10800:\tlearn: 1.0785176\ttest: 1.0884917\tbest: 1.0884870 (10352)\ttotal: 56.4s\tremaining: 3m 24s\n",
            "10900:\tlearn: 1.0784425\ttest: 1.0884849\tbest: 1.0884828 (10877)\ttotal: 57s\tremaining: 3m 24s\n",
            "11000:\tlearn: 1.0783739\ttest: 1.0884822\tbest: 1.0884808 (10998)\ttotal: 57.5s\tremaining: 3m 23s\n",
            "11100:\tlearn: 1.0783019\ttest: 1.0884820\tbest: 1.0884789 (11059)\ttotal: 58.1s\tremaining: 3m 23s\n",
            "11200:\tlearn: 1.0782275\ttest: 1.0884709\tbest: 1.0884676 (11194)\ttotal: 58.6s\tremaining: 3m 23s\n",
            "11300:\tlearn: 1.0781618\ttest: 1.0884631\tbest: 1.0884621 (11290)\ttotal: 59.2s\tremaining: 3m 22s\n",
            "11400:\tlearn: 1.0780947\ttest: 1.0884767\tbest: 1.0884604 (11317)\ttotal: 59.8s\tremaining: 3m 22s\n",
            "11500:\tlearn: 1.0780159\ttest: 1.0884709\tbest: 1.0884604 (11317)\ttotal: 1m\tremaining: 3m 21s\n",
            "11600:\tlearn: 1.0779413\ttest: 1.0884725\tbest: 1.0884604 (11317)\ttotal: 1m\tremaining: 3m 21s\n",
            "11700:\tlearn: 1.0778659\ttest: 1.0884604\tbest: 1.0884587 (11682)\ttotal: 1m 1s\tremaining: 3m 21s\n",
            "11800:\tlearn: 1.0777957\ttest: 1.0884678\tbest: 1.0884554 (11734)\ttotal: 1m 1s\tremaining: 3m 20s\n",
            "11900:\tlearn: 1.0777296\ttest: 1.0884487\tbest: 1.0884471 (11897)\ttotal: 1m 2s\tremaining: 3m 20s\n",
            "12000:\tlearn: 1.0776696\ttest: 1.0884543\tbest: 1.0884471 (11897)\ttotal: 1m 3s\tremaining: 3m 19s\n",
            "12100:\tlearn: 1.0776006\ttest: 1.0884499\tbest: 1.0884471 (11897)\ttotal: 1m 3s\tremaining: 3m 19s\n",
            "12200:\tlearn: 1.0775369\ttest: 1.0884388\tbest: 1.0884386 (12199)\ttotal: 1m 4s\tremaining: 3m 18s\n",
            "12300:\tlearn: 1.0774751\ttest: 1.0884437\tbest: 1.0884349 (12235)\ttotal: 1m 4s\tremaining: 3m 18s\n",
            "12400:\tlearn: 1.0774105\ttest: 1.0884453\tbest: 1.0884349 (12235)\ttotal: 1m 5s\tremaining: 3m 17s\n",
            "12500:\tlearn: 1.0773432\ttest: 1.0884382\tbest: 1.0884349 (12235)\ttotal: 1m 5s\tremaining: 3m 17s\n",
            "12600:\tlearn: 1.0772796\ttest: 1.0884448\tbest: 1.0884349 (12235)\ttotal: 1m 6s\tremaining: 3m 17s\n",
            "12700:\tlearn: 1.0772156\ttest: 1.0884465\tbest: 1.0884349 (12235)\ttotal: 1m 6s\tremaining: 3m 16s\n",
            "12800:\tlearn: 1.0771499\ttest: 1.0884450\tbest: 1.0884349 (12235)\ttotal: 1m 7s\tremaining: 3m 16s\n",
            "12900:\tlearn: 1.0770829\ttest: 1.0884523\tbest: 1.0884349 (12235)\ttotal: 1m 8s\tremaining: 3m 15s\n",
            "13000:\tlearn: 1.0770186\ttest: 1.0884497\tbest: 1.0884349 (12235)\ttotal: 1m 8s\tremaining: 3m 15s\n",
            "13100:\tlearn: 1.0769583\ttest: 1.0884468\tbest: 1.0884349 (12235)\ttotal: 1m 9s\tremaining: 3m 14s\n",
            "13200:\tlearn: 1.0768887\ttest: 1.0884549\tbest: 1.0884349 (12235)\ttotal: 1m 9s\tremaining: 3m 14s\n",
            "bestTest = 1.088434863\n",
            "bestIteration = 12235\n",
            "Shrink model to first 12236 iterations.\n",
            "0:\tlearn: 1.3668907\ttest: 1.3669049\tbest: 1.3669049 (0)\ttotal: 6.07ms\tremaining: 5m 3s\n",
            "100:\tlearn: 1.1116010\ttest: 1.1125449\tbest: 1.1125449 (100)\ttotal: 491ms\tremaining: 4m 2s\n",
            "200:\tlearn: 1.1069120\ttest: 1.1079498\tbest: 1.1079498 (200)\ttotal: 981ms\tremaining: 4m 3s\n",
            "300:\tlearn: 1.1037569\ttest: 1.1049255\tbest: 1.1049255 (300)\ttotal: 1.45s\tremaining: 3m 59s\n",
            "400:\tlearn: 1.1012617\ttest: 1.1025482\tbest: 1.1025482 (400)\ttotal: 1.94s\tremaining: 3m 59s\n",
            "500:\tlearn: 1.0992668\ttest: 1.1007112\tbest: 1.1007112 (500)\ttotal: 2.44s\tremaining: 4m 1s\n",
            "600:\tlearn: 1.0976691\ttest: 1.0991922\tbest: 1.0991922 (600)\ttotal: 2.93s\tremaining: 4m 1s\n",
            "700:\tlearn: 1.0962867\ttest: 1.0979259\tbest: 1.0979259 (700)\ttotal: 3.44s\tremaining: 4m 1s\n",
            "800:\tlearn: 1.0952500\ttest: 1.0969787\tbest: 1.0969787 (800)\ttotal: 3.97s\tremaining: 4m 3s\n",
            "900:\tlearn: 1.0943618\ttest: 1.0961876\tbest: 1.0961876 (900)\ttotal: 4.52s\tremaining: 4m 6s\n",
            "1000:\tlearn: 1.0935410\ttest: 1.0954688\tbest: 1.0954688 (1000)\ttotal: 5.06s\tremaining: 4m 7s\n",
            "1100:\tlearn: 1.0928660\ttest: 1.0949106\tbest: 1.0949106 (1100)\ttotal: 5.6s\tremaining: 4m 8s\n",
            "1200:\tlearn: 1.0922359\ttest: 1.0944027\tbest: 1.0944027 (1200)\ttotal: 6.16s\tremaining: 4m 10s\n",
            "1300:\tlearn: 1.0917110\ttest: 1.0939366\tbest: 1.0939363 (1299)\ttotal: 6.71s\tremaining: 4m 11s\n",
            "1400:\tlearn: 1.0912262\ttest: 1.0935679\tbest: 1.0935679 (1400)\ttotal: 7.26s\tremaining: 4m 11s\n",
            "1500:\tlearn: 1.0907741\ttest: 1.0932235\tbest: 1.0932235 (1500)\ttotal: 7.82s\tremaining: 4m 12s\n",
            "1600:\tlearn: 1.0903729\ttest: 1.0929028\tbest: 1.0929028 (1600)\ttotal: 8.37s\tremaining: 4m 12s\n",
            "1700:\tlearn: 1.0900236\ttest: 1.0926327\tbest: 1.0926327 (1700)\ttotal: 8.91s\tremaining: 4m 13s\n",
            "1800:\tlearn: 1.0896766\ttest: 1.0924021\tbest: 1.0924017 (1799)\ttotal: 9.45s\tremaining: 4m 12s\n",
            "1900:\tlearn: 1.0893526\ttest: 1.0921664\tbest: 1.0921664 (1900)\ttotal: 9.98s\tremaining: 4m 12s\n",
            "2000:\tlearn: 1.0890549\ttest: 1.0919390\tbest: 1.0919390 (2000)\ttotal: 10.5s\tremaining: 4m 12s\n",
            "2100:\tlearn: 1.0887681\ttest: 1.0917432\tbest: 1.0917432 (2100)\ttotal: 11.1s\tremaining: 4m 12s\n",
            "2200:\tlearn: 1.0884948\ttest: 1.0915371\tbest: 1.0915371 (2200)\ttotal: 11.6s\tremaining: 4m 11s\n",
            "2300:\tlearn: 1.0882624\ttest: 1.0914227\tbest: 1.0914227 (2300)\ttotal: 12.1s\tremaining: 4m 10s\n",
            "2400:\tlearn: 1.0880319\ttest: 1.0912553\tbest: 1.0912553 (2400)\ttotal: 12.6s\tremaining: 4m 9s\n",
            "2500:\tlearn: 1.0878167\ttest: 1.0911283\tbest: 1.0911283 (2500)\ttotal: 13.1s\tremaining: 4m 8s\n",
            "2600:\tlearn: 1.0875953\ttest: 1.0910098\tbest: 1.0910098 (2600)\ttotal: 13.6s\tremaining: 4m 7s\n",
            "2700:\tlearn: 1.0873962\ttest: 1.0908963\tbest: 1.0908963 (2700)\ttotal: 14.1s\tremaining: 4m 6s\n",
            "2800:\tlearn: 1.0872045\ttest: 1.0907893\tbest: 1.0907890 (2799)\ttotal: 14.6s\tremaining: 4m 5s\n",
            "2900:\tlearn: 1.0870249\ttest: 1.0906769\tbest: 1.0906761 (2899)\ttotal: 15.1s\tremaining: 4m 4s\n",
            "3000:\tlearn: 1.0868537\ttest: 1.0905866\tbest: 1.0905866 (3000)\ttotal: 15.6s\tremaining: 4m 3s\n",
            "3100:\tlearn: 1.0866672\ttest: 1.0904921\tbest: 1.0904921 (3100)\ttotal: 16.1s\tremaining: 4m 3s\n",
            "3200:\tlearn: 1.0864904\ttest: 1.0904007\tbest: 1.0904007 (3200)\ttotal: 16.6s\tremaining: 4m 2s\n",
            "3300:\tlearn: 1.0863263\ttest: 1.0903273\tbest: 1.0903268 (3298)\ttotal: 17.1s\tremaining: 4m 1s\n",
            "3400:\tlearn: 1.0861671\ttest: 1.0902612\tbest: 1.0902612 (3400)\ttotal: 17.6s\tremaining: 4m\n",
            "3500:\tlearn: 1.0860058\ttest: 1.0901667\tbest: 1.0901667 (3500)\ttotal: 18.1s\tremaining: 4m\n",
            "3600:\tlearn: 1.0858564\ttest: 1.0901063\tbest: 1.0901063 (3600)\ttotal: 18.6s\tremaining: 3m 59s\n",
            "3700:\tlearn: 1.0857132\ttest: 1.0900500\tbest: 1.0900495 (3698)\ttotal: 19.1s\tremaining: 3m 58s\n",
            "3800:\tlearn: 1.0855680\ttest: 1.0900069\tbest: 1.0900069 (3800)\ttotal: 19.6s\tremaining: 3m 58s\n",
            "3900:\tlearn: 1.0854356\ttest: 1.0899558\tbest: 1.0899543 (3899)\ttotal: 20.1s\tremaining: 3m 57s\n",
            "4000:\tlearn: 1.0853033\ttest: 1.0899086\tbest: 1.0899078 (3991)\ttotal: 20.6s\tremaining: 3m 56s\n",
            "4100:\tlearn: 1.0851687\ttest: 1.0898431\tbest: 1.0898431 (4100)\ttotal: 21.1s\tremaining: 3m 56s\n",
            "4200:\tlearn: 1.0850365\ttest: 1.0898036\tbest: 1.0898036 (4200)\ttotal: 21.6s\tremaining: 3m 55s\n",
            "4300:\tlearn: 1.0849100\ttest: 1.0897482\tbest: 1.0897482 (4300)\ttotal: 22.2s\tremaining: 3m 55s\n",
            "4400:\tlearn: 1.0847795\ttest: 1.0897033\tbest: 1.0897029 (4398)\ttotal: 22.7s\tremaining: 3m 55s\n",
            "4500:\tlearn: 1.0846612\ttest: 1.0896512\tbest: 1.0896496 (4496)\ttotal: 23.2s\tremaining: 3m 54s\n",
            "4600:\tlearn: 1.0845406\ttest: 1.0896287\tbest: 1.0896287 (4600)\ttotal: 23.8s\tremaining: 3m 54s\n",
            "4700:\tlearn: 1.0844170\ttest: 1.0895784\tbest: 1.0895771 (4698)\ttotal: 24.3s\tremaining: 3m 54s\n",
            "4800:\tlearn: 1.0842982\ttest: 1.0895273\tbest: 1.0895273 (4800)\ttotal: 24.9s\tremaining: 3m 54s\n",
            "4900:\tlearn: 1.0841911\ttest: 1.0894912\tbest: 1.0894896 (4881)\ttotal: 25.4s\tremaining: 3m 53s\n",
            "5000:\tlearn: 1.0840844\ttest: 1.0894555\tbest: 1.0894534 (4994)\ttotal: 26s\tremaining: 3m 53s\n",
            "5100:\tlearn: 1.0839746\ttest: 1.0894209\tbest: 1.0894209 (5100)\ttotal: 26.5s\tremaining: 3m 53s\n",
            "5200:\tlearn: 1.0838740\ttest: 1.0893739\tbest: 1.0893739 (5200)\ttotal: 27.1s\tremaining: 3m 53s\n",
            "5300:\tlearn: 1.0837733\ttest: 1.0893229\tbest: 1.0893229 (5300)\ttotal: 27.6s\tremaining: 3m 52s\n",
            "5400:\tlearn: 1.0836634\ttest: 1.0893036\tbest: 1.0893036 (5400)\ttotal: 28.2s\tremaining: 3m 52s\n",
            "5500:\tlearn: 1.0835556\ttest: 1.0892620\tbest: 1.0892620 (5500)\ttotal: 28.7s\tremaining: 3m 52s\n",
            "5600:\tlearn: 1.0834494\ttest: 1.0892182\tbest: 1.0892172 (5592)\ttotal: 29.3s\tremaining: 3m 51s\n",
            "5700:\tlearn: 1.0833489\ttest: 1.0891953\tbest: 1.0891913 (5697)\ttotal: 29.8s\tremaining: 3m 51s\n",
            "5800:\tlearn: 1.0832497\ttest: 1.0891661\tbest: 1.0891647 (5790)\ttotal: 30.3s\tremaining: 3m 51s\n",
            "5900:\tlearn: 1.0831442\ttest: 1.0891630\tbest: 1.0891531 (5851)\ttotal: 30.9s\tremaining: 3m 50s\n",
            "6000:\tlearn: 1.0830362\ttest: 1.0891326\tbest: 1.0891318 (5999)\ttotal: 31.4s\tremaining: 3m 49s\n",
            "6100:\tlearn: 1.0829335\ttest: 1.0891021\tbest: 1.0891015 (6098)\ttotal: 31.8s\tremaining: 3m 49s\n",
            "6200:\tlearn: 1.0828412\ttest: 1.0890643\tbest: 1.0890636 (6192)\ttotal: 32.3s\tremaining: 3m 48s\n",
            "6300:\tlearn: 1.0827442\ttest: 1.0890403\tbest: 1.0890403 (6300)\ttotal: 32.8s\tremaining: 3m 47s\n",
            "6400:\tlearn: 1.0826530\ttest: 1.0890280\tbest: 1.0890227 (6388)\ttotal: 33.3s\tremaining: 3m 46s\n",
            "6500:\tlearn: 1.0825632\ttest: 1.0890043\tbest: 1.0890042 (6499)\ttotal: 33.8s\tremaining: 3m 46s\n",
            "6600:\tlearn: 1.0824704\ttest: 1.0889984\tbest: 1.0889979 (6592)\ttotal: 34.3s\tremaining: 3m 45s\n",
            "6700:\tlearn: 1.0823877\ttest: 1.0889794\tbest: 1.0889786 (6672)\ttotal: 34.8s\tremaining: 3m 45s\n",
            "6800:\tlearn: 1.0822869\ttest: 1.0889611\tbest: 1.0889600 (6782)\ttotal: 35.3s\tremaining: 3m 44s\n",
            "6900:\tlearn: 1.0821852\ttest: 1.0889403\tbest: 1.0889386 (6888)\ttotal: 35.8s\tremaining: 3m 43s\n",
            "7000:\tlearn: 1.0821054\ttest: 1.0889199\tbest: 1.0889185 (6993)\ttotal: 36.3s\tremaining: 3m 42s\n",
            "7100:\tlearn: 1.0820210\ttest: 1.0889045\tbest: 1.0889044 (7099)\ttotal: 36.8s\tremaining: 3m 42s\n",
            "7200:\tlearn: 1.0819272\ttest: 1.0888771\tbest: 1.0888756 (7197)\ttotal: 37.3s\tremaining: 3m 41s\n",
            "7300:\tlearn: 1.0818397\ttest: 1.0888704\tbest: 1.0888704 (7300)\ttotal: 37.8s\tremaining: 3m 41s\n",
            "7400:\tlearn: 1.0817488\ttest: 1.0888544\tbest: 1.0888531 (7394)\ttotal: 38.3s\tremaining: 3m 40s\n",
            "7500:\tlearn: 1.0816579\ttest: 1.0888394\tbest: 1.0888389 (7483)\ttotal: 38.8s\tremaining: 3m 39s\n",
            "7600:\tlearn: 1.0815672\ttest: 1.0888364\tbest: 1.0888331 (7560)\ttotal: 39.3s\tremaining: 3m 39s\n",
            "7700:\tlearn: 1.0814858\ttest: 1.0888291\tbest: 1.0888242 (7675)\ttotal: 39.8s\tremaining: 3m 38s\n",
            "7800:\tlearn: 1.0814062\ttest: 1.0887983\tbest: 1.0887942 (7786)\ttotal: 40.3s\tremaining: 3m 37s\n",
            "7900:\tlearn: 1.0813161\ttest: 1.0887871\tbest: 1.0887871 (7900)\ttotal: 40.7s\tremaining: 3m 37s\n",
            "8000:\tlearn: 1.0812351\ttest: 1.0887843\tbest: 1.0887843 (8000)\ttotal: 41.2s\tremaining: 3m 36s\n",
            "8100:\tlearn: 1.0811520\ttest: 1.0887602\tbest: 1.0887602 (8099)\ttotal: 41.7s\tremaining: 3m 35s\n",
            "8200:\tlearn: 1.0810686\ttest: 1.0887338\tbest: 1.0887338 (8197)\ttotal: 42.2s\tremaining: 3m 35s\n",
            "8300:\tlearn: 1.0809953\ttest: 1.0887224\tbest: 1.0887205 (8275)\ttotal: 42.8s\tremaining: 3m 34s\n",
            "8400:\tlearn: 1.0809223\ttest: 1.0886968\tbest: 1.0886963 (8399)\ttotal: 43.3s\tremaining: 3m 34s\n",
            "8500:\tlearn: 1.0808448\ttest: 1.0886997\tbest: 1.0886963 (8399)\ttotal: 43.8s\tremaining: 3m 33s\n",
            "8600:\tlearn: 1.0807615\ttest: 1.0886941\tbest: 1.0886926 (8535)\ttotal: 44.3s\tremaining: 3m 33s\n",
            "8700:\tlearn: 1.0806797\ttest: 1.0886834\tbest: 1.0886783 (8676)\ttotal: 44.8s\tremaining: 3m 32s\n",
            "8800:\tlearn: 1.0805928\ttest: 1.0886714\tbest: 1.0886708 (8795)\ttotal: 45.3s\tremaining: 3m 31s\n",
            "8900:\tlearn: 1.0805232\ttest: 1.0886668\tbest: 1.0886656 (8854)\ttotal: 45.8s\tremaining: 3m 31s\n",
            "9000:\tlearn: 1.0804472\ttest: 1.0886649\tbest: 1.0886636 (8924)\ttotal: 46.3s\tremaining: 3m 30s\n",
            "9100:\tlearn: 1.0803677\ttest: 1.0886511\tbest: 1.0886422 (9082)\ttotal: 46.9s\tremaining: 3m 30s\n",
            "9200:\tlearn: 1.0802917\ttest: 1.0886436\tbest: 1.0886418 (9180)\ttotal: 47.5s\tremaining: 3m 30s\n",
            "9300:\tlearn: 1.0802149\ttest: 1.0886377\tbest: 1.0886356 (9295)\ttotal: 48.1s\tremaining: 3m 30s\n",
            "9400:\tlearn: 1.0801293\ttest: 1.0886177\tbest: 1.0886164 (9396)\ttotal: 48.6s\tremaining: 3m 30s\n",
            "9500:\tlearn: 1.0800514\ttest: 1.0886055\tbest: 1.0886010 (9491)\ttotal: 49.2s\tremaining: 3m 29s\n",
            "9600:\tlearn: 1.0799746\ttest: 1.0885966\tbest: 1.0885948 (9589)\ttotal: 49.8s\tremaining: 3m 29s\n",
            "9700:\tlearn: 1.0798971\ttest: 1.0885843\tbest: 1.0885799 (9683)\ttotal: 50.4s\tremaining: 3m 29s\n",
            "9800:\tlearn: 1.0798179\ttest: 1.0885884\tbest: 1.0885799 (9683)\ttotal: 51s\tremaining: 3m 29s\n",
            "9900:\tlearn: 1.0797458\ttest: 1.0885801\tbest: 1.0885773 (9880)\ttotal: 51.6s\tremaining: 3m 28s\n",
            "10000:\tlearn: 1.0796724\ttest: 1.0885780\tbest: 1.0885722 (9964)\ttotal: 52.2s\tremaining: 3m 28s\n",
            "10100:\tlearn: 1.0795901\ttest: 1.0885648\tbest: 1.0885620 (10090)\ttotal: 52.8s\tremaining: 3m 28s\n",
            "10200:\tlearn: 1.0795214\ttest: 1.0885585\tbest: 1.0885573 (10195)\ttotal: 53.4s\tremaining: 3m 28s\n",
            "10300:\tlearn: 1.0794515\ttest: 1.0885423\tbest: 1.0885414 (10298)\ttotal: 53.9s\tremaining: 3m 27s\n",
            "10400:\tlearn: 1.0793816\ttest: 1.0885275\tbest: 1.0885262 (10393)\ttotal: 54.5s\tremaining: 3m 27s\n",
            "10500:\tlearn: 1.0793135\ttest: 1.0885322\tbest: 1.0885262 (10393)\ttotal: 55.1s\tremaining: 3m 27s\n",
            "10600:\tlearn: 1.0792382\ttest: 1.0885350\tbest: 1.0885262 (10393)\ttotal: 55.7s\tremaining: 3m 26s\n",
            "10700:\tlearn: 1.0791664\ttest: 1.0885275\tbest: 1.0885259 (10698)\ttotal: 56.3s\tremaining: 3m 26s\n",
            "10800:\tlearn: 1.0790898\ttest: 1.0885383\tbest: 1.0885254 (10704)\ttotal: 56.9s\tremaining: 3m 26s\n",
            "10900:\tlearn: 1.0790143\ttest: 1.0885208\tbest: 1.0885195 (10896)\ttotal: 57.4s\tremaining: 3m 26s\n",
            "11000:\tlearn: 1.0789487\ttest: 1.0885201\tbest: 1.0885157 (10923)\ttotal: 58s\tremaining: 3m 25s\n",
            "11100:\tlearn: 1.0788801\ttest: 1.0885186\tbest: 1.0885122 (11043)\ttotal: 58.6s\tremaining: 3m 25s\n",
            "11200:\tlearn: 1.0788078\ttest: 1.0885096\tbest: 1.0885088 (11199)\ttotal: 59.2s\tremaining: 3m 25s\n",
            "11300:\tlearn: 1.0787363\ttest: 1.0884947\tbest: 1.0884943 (11292)\ttotal: 59.8s\tremaining: 3m 24s\n",
            "11400:\tlearn: 1.0786686\ttest: 1.0885001\tbest: 1.0884907 (11331)\ttotal: 1m\tremaining: 3m 24s\n",
            "11500:\tlearn: 1.0785975\ttest: 1.0884944\tbest: 1.0884907 (11331)\ttotal: 1m\tremaining: 3m 24s\n",
            "11600:\tlearn: 1.0785305\ttest: 1.0884937\tbest: 1.0884886 (11557)\ttotal: 1m 1s\tremaining: 3m 23s\n",
            "11700:\tlearn: 1.0784656\ttest: 1.0884916\tbest: 1.0884886 (11557)\ttotal: 1m 2s\tremaining: 3m 23s\n",
            "11800:\tlearn: 1.0783982\ttest: 1.0885011\tbest: 1.0884886 (11557)\ttotal: 1m 2s\tremaining: 3m 22s\n",
            "11900:\tlearn: 1.0783298\ttest: 1.0885002\tbest: 1.0884886 (11557)\ttotal: 1m 3s\tremaining: 3m 22s\n",
            "12000:\tlearn: 1.0782592\ttest: 1.0884951\tbest: 1.0884886 (11557)\ttotal: 1m 3s\tremaining: 3m 22s\n",
            "12100:\tlearn: 1.0781874\ttest: 1.0884933\tbest: 1.0884876 (12091)\ttotal: 1m 4s\tremaining: 3m 21s\n",
            "12200:\tlearn: 1.0781202\ttest: 1.0884904\tbest: 1.0884876 (12091)\ttotal: 1m 5s\tremaining: 3m 21s\n",
            "12300:\tlearn: 1.0780534\ttest: 1.0884919\tbest: 1.0884853 (12263)\ttotal: 1m 5s\tremaining: 3m 21s\n",
            "12400:\tlearn: 1.0779795\ttest: 1.0884930\tbest: 1.0884853 (12263)\ttotal: 1m 6s\tremaining: 3m 20s\n",
            "12500:\tlearn: 1.0779060\ttest: 1.0884997\tbest: 1.0884853 (12263)\ttotal: 1m 6s\tremaining: 3m 20s\n",
            "12600:\tlearn: 1.0778408\ttest: 1.0884995\tbest: 1.0884853 (12263)\ttotal: 1m 7s\tremaining: 3m 20s\n",
            "12700:\tlearn: 1.0777776\ttest: 1.0885055\tbest: 1.0884853 (12263)\ttotal: 1m 8s\tremaining: 3m 19s\n",
            "12800:\tlearn: 1.0777099\ttest: 1.0885064\tbest: 1.0884853 (12263)\ttotal: 1m 8s\tremaining: 3m 19s\n",
            "12900:\tlearn: 1.0776436\ttest: 1.0885081\tbest: 1.0884853 (12263)\ttotal: 1m 9s\tremaining: 3m 18s\n",
            "13000:\tlearn: 1.0775788\ttest: 1.0885041\tbest: 1.0884853 (12263)\ttotal: 1m 9s\tremaining: 3m 18s\n",
            "13100:\tlearn: 1.0775147\ttest: 1.0885094\tbest: 1.0884853 (12263)\ttotal: 1m 10s\tremaining: 3m 18s\n",
            "13200:\tlearn: 1.0774495\ttest: 1.0885014\tbest: 1.0884853 (12263)\ttotal: 1m 10s\tremaining: 3m 17s\n",
            "bestTest = 1.088485254\n",
            "bestIteration = 12263\n",
            "Shrink model to first 12264 iterations.\n",
            "fold: 3,log_loss: 1.088402283475375\n",
            "0:\tlearn: 1.3668889\ttest: 1.3669454\tbest: 1.3669454 (0)\ttotal: 6.06ms\tremaining: 5m 3s\n",
            "100:\tlearn: 1.1120079\ttest: 1.1122539\tbest: 1.1122539 (100)\ttotal: 467ms\tremaining: 3m 50s\n",
            "200:\tlearn: 1.1071636\ttest: 1.1075679\tbest: 1.1075679 (200)\ttotal: 938ms\tremaining: 3m 52s\n",
            "300:\tlearn: 1.1039025\ttest: 1.1046012\tbest: 1.1046012 (300)\ttotal: 1.41s\tremaining: 3m 52s\n",
            "400:\tlearn: 1.1014119\ttest: 1.1022540\tbest: 1.1022540 (400)\ttotal: 1.91s\tremaining: 3m 55s\n",
            "500:\tlearn: 1.0994099\ttest: 1.1005387\tbest: 1.1005387 (500)\ttotal: 2.36s\tremaining: 3m 53s\n",
            "600:\tlearn: 1.0976795\ttest: 1.0989619\tbest: 1.0989619 (600)\ttotal: 2.88s\tremaining: 3m 56s\n",
            "700:\tlearn: 1.0963593\ttest: 1.0978209\tbest: 1.0978209 (700)\ttotal: 3.39s\tremaining: 3m 58s\n",
            "800:\tlearn: 1.0951981\ttest: 1.0968349\tbest: 1.0968349 (800)\ttotal: 3.9s\tremaining: 3m 59s\n",
            "900:\tlearn: 1.0943050\ttest: 1.0960896\tbest: 1.0960896 (900)\ttotal: 4.43s\tremaining: 4m 1s\n",
            "1000:\tlearn: 1.0934668\ttest: 1.0953873\tbest: 1.0953873 (1000)\ttotal: 4.97s\tremaining: 4m 3s\n",
            "1100:\tlearn: 1.0927777\ttest: 1.0948011\tbest: 1.0948011 (1100)\ttotal: 5.5s\tremaining: 4m 4s\n",
            "1200:\tlearn: 1.0921728\ttest: 1.0943754\tbest: 1.0943754 (1200)\ttotal: 6.04s\tremaining: 4m 5s\n",
            "1300:\tlearn: 1.0916250\ttest: 1.0939634\tbest: 1.0939634 (1300)\ttotal: 6.57s\tremaining: 4m 5s\n",
            "1400:\tlearn: 1.0911101\ttest: 1.0935928\tbest: 1.0935928 (1400)\ttotal: 7.11s\tremaining: 4m 6s\n",
            "1500:\tlearn: 1.0906794\ttest: 1.0932943\tbest: 1.0932943 (1500)\ttotal: 7.63s\tremaining: 4m 6s\n",
            "1600:\tlearn: 1.0902546\ttest: 1.0929971\tbest: 1.0929971 (1600)\ttotal: 8.16s\tremaining: 4m 6s\n",
            "1700:\tlearn: 1.0898985\ttest: 1.0927352\tbest: 1.0927352 (1700)\ttotal: 8.69s\tremaining: 4m 6s\n",
            "1800:\tlearn: 1.0895316\ttest: 1.0925052\tbest: 1.0925052 (1800)\ttotal: 9.21s\tremaining: 4m 6s\n",
            "1900:\tlearn: 1.0891921\ttest: 1.0923255\tbest: 1.0923255 (1900)\ttotal: 9.74s\tremaining: 4m 6s\n",
            "2000:\tlearn: 1.0888861\ttest: 1.0921656\tbest: 1.0921656 (2000)\ttotal: 10.3s\tremaining: 4m 6s\n",
            "2100:\tlearn: 1.0885862\ttest: 1.0920188\tbest: 1.0920188 (2100)\ttotal: 10.8s\tremaining: 4m 5s\n",
            "2200:\tlearn: 1.0883219\ttest: 1.0918416\tbest: 1.0918416 (2200)\ttotal: 11.3s\tremaining: 4m 5s\n",
            "2300:\tlearn: 1.0880440\ttest: 1.0916481\tbest: 1.0916481 (2300)\ttotal: 11.8s\tremaining: 4m 4s\n",
            "2400:\tlearn: 1.0877987\ttest: 1.0915196\tbest: 1.0915188 (2392)\ttotal: 12.4s\tremaining: 4m 4s\n",
            "2500:\tlearn: 1.0875649\ttest: 1.0914153\tbest: 1.0914153 (2500)\ttotal: 12.9s\tremaining: 4m 4s\n",
            "2600:\tlearn: 1.0873266\ttest: 1.0913252\tbest: 1.0913252 (2600)\ttotal: 13.4s\tremaining: 4m 4s\n",
            "2700:\tlearn: 1.0871024\ttest: 1.0911979\tbest: 1.0911978 (2698)\ttotal: 14s\tremaining: 4m 4s\n",
            "2800:\tlearn: 1.0869027\ttest: 1.0911150\tbest: 1.0911150 (2800)\ttotal: 14.5s\tremaining: 4m 5s\n",
            "2900:\tlearn: 1.0867054\ttest: 1.0910565\tbest: 1.0910565 (2900)\ttotal: 15.1s\tremaining: 4m 5s\n",
            "3000:\tlearn: 1.0865143\ttest: 1.0909693\tbest: 1.0909693 (3000)\ttotal: 15.7s\tremaining: 4m 5s\n",
            "3100:\tlearn: 1.0863225\ttest: 1.0908771\tbest: 1.0908771 (3100)\ttotal: 16.2s\tremaining: 4m 4s\n",
            "3200:\tlearn: 1.0861497\ttest: 1.0908060\tbest: 1.0908058 (3197)\ttotal: 16.8s\tremaining: 4m 4s\n",
            "3300:\tlearn: 1.0859741\ttest: 1.0907558\tbest: 1.0907547 (3297)\ttotal: 17.3s\tremaining: 4m 4s\n",
            "3400:\tlearn: 1.0858170\ttest: 1.0906878\tbest: 1.0906865 (3399)\ttotal: 17.8s\tremaining: 4m 4s\n",
            "3500:\tlearn: 1.0856637\ttest: 1.0906322\tbest: 1.0906312 (3496)\ttotal: 18.4s\tremaining: 4m 4s\n",
            "3600:\tlearn: 1.0855040\ttest: 1.0905908\tbest: 1.0905908 (3600)\ttotal: 19s\tremaining: 4m 4s\n",
            "3700:\tlearn: 1.0853483\ttest: 1.0905206\tbest: 1.0905206 (3698)\ttotal: 19.5s\tremaining: 4m 3s\n",
            "3800:\tlearn: 1.0851940\ttest: 1.0904656\tbest: 1.0904656 (3800)\ttotal: 20s\tremaining: 4m 3s\n",
            "3900:\tlearn: 1.0850463\ttest: 1.0904226\tbest: 1.0904173 (3884)\ttotal: 20.6s\tremaining: 4m 3s\n",
            "4000:\tlearn: 1.0849063\ttest: 1.0903618\tbest: 1.0903614 (3998)\ttotal: 21.1s\tremaining: 4m 2s\n",
            "4100:\tlearn: 1.0847674\ttest: 1.0903475\tbest: 1.0903475 (4100)\ttotal: 21.7s\tremaining: 4m 2s\n",
            "4200:\tlearn: 1.0846303\ttest: 1.0903158\tbest: 1.0903105 (4182)\ttotal: 22.3s\tremaining: 4m 2s\n",
            "4300:\tlearn: 1.0844947\ttest: 1.0902743\tbest: 1.0902736 (4290)\ttotal: 22.8s\tremaining: 4m 2s\n",
            "4400:\tlearn: 1.0843496\ttest: 1.0902405\tbest: 1.0902405 (4400)\ttotal: 23.4s\tremaining: 4m 2s\n",
            "4500:\tlearn: 1.0842317\ttest: 1.0902124\tbest: 1.0902117 (4499)\ttotal: 23.9s\tremaining: 4m 1s\n",
            "4600:\tlearn: 1.0841036\ttest: 1.0901783\tbest: 1.0901783 (4600)\ttotal: 24.5s\tremaining: 4m 1s\n",
            "4700:\tlearn: 1.0839721\ttest: 1.0901236\tbest: 1.0901236 (4700)\ttotal: 25.1s\tremaining: 4m 1s\n",
            "4800:\tlearn: 1.0838486\ttest: 1.0900919\tbest: 1.0900900 (4798)\ttotal: 25.6s\tremaining: 4m 1s\n",
            "4900:\tlearn: 1.0837306\ttest: 1.0900599\tbest: 1.0900587 (4899)\ttotal: 26.2s\tremaining: 4m 1s\n",
            "5000:\tlearn: 1.0836155\ttest: 1.0900234\tbest: 1.0900232 (4999)\ttotal: 26.8s\tremaining: 4m 1s\n",
            "5100:\tlearn: 1.0834988\ttest: 1.0900052\tbest: 1.0900040 (5099)\ttotal: 27.4s\tremaining: 4m 1s\n",
            "5200:\tlearn: 1.0833804\ttest: 1.0899715\tbest: 1.0899704 (5195)\ttotal: 28s\tremaining: 4m\n",
            "5300:\tlearn: 1.0832645\ttest: 1.0899532\tbest: 1.0899532 (5298)\ttotal: 28.5s\tremaining: 4m\n",
            "5400:\tlearn: 1.0831563\ttest: 1.0899228\tbest: 1.0899228 (5400)\ttotal: 29.1s\tremaining: 4m\n",
            "5500:\tlearn: 1.0830494\ttest: 1.0898951\tbest: 1.0898941 (5490)\ttotal: 29.7s\tremaining: 4m\n",
            "5600:\tlearn: 1.0829389\ttest: 1.0898823\tbest: 1.0898797 (5597)\ttotal: 30.3s\tremaining: 3m 59s\n",
            "5700:\tlearn: 1.0828256\ttest: 1.0898771\tbest: 1.0898762 (5659)\ttotal: 30.9s\tremaining: 3m 59s\n",
            "5800:\tlearn: 1.0827167\ttest: 1.0898654\tbest: 1.0898604 (5793)\ttotal: 31.4s\tremaining: 3m 59s\n",
            "5900:\tlearn: 1.0826109\ttest: 1.0898443\tbest: 1.0898441 (5899)\ttotal: 32s\tremaining: 3m 59s\n",
            "6000:\tlearn: 1.0825046\ttest: 1.0898275\tbest: 1.0898271 (5998)\ttotal: 32.6s\tremaining: 3m 59s\n",
            "6100:\tlearn: 1.0823977\ttest: 1.0898040\tbest: 1.0898037 (6087)\ttotal: 33.2s\tremaining: 3m 58s\n",
            "6200:\tlearn: 1.0822930\ttest: 1.0897892\tbest: 1.0897883 (6197)\ttotal: 33.8s\tremaining: 3m 58s\n",
            "6300:\tlearn: 1.0821972\ttest: 1.0897712\tbest: 1.0897701 (6297)\ttotal: 34.4s\tremaining: 3m 58s\n",
            "6400:\tlearn: 1.0820937\ttest: 1.0897494\tbest: 1.0897494 (6400)\ttotal: 35s\tremaining: 3m 58s\n",
            "6500:\tlearn: 1.0820055\ttest: 1.0897313\tbest: 1.0897294 (6497)\ttotal: 35.5s\tremaining: 3m 57s\n",
            "6600:\tlearn: 1.0819107\ttest: 1.0897329\tbest: 1.0897281 (6507)\ttotal: 36.1s\tremaining: 3m 57s\n",
            "6700:\tlearn: 1.0818121\ttest: 1.0897156\tbest: 1.0897156 (6700)\ttotal: 36.7s\tremaining: 3m 57s\n",
            "6800:\tlearn: 1.0817122\ttest: 1.0897124\tbest: 1.0897074 (6751)\ttotal: 37.3s\tremaining: 3m 56s\n",
            "6900:\tlearn: 1.0816114\ttest: 1.0897053\tbest: 1.0897021 (6895)\ttotal: 37.9s\tremaining: 3m 56s\n",
            "7000:\tlearn: 1.0815109\ttest: 1.0897062\tbest: 1.0896990 (6964)\ttotal: 38.5s\tremaining: 3m 56s\n",
            "7100:\tlearn: 1.0814175\ttest: 1.0896951\tbest: 1.0896909 (7080)\ttotal: 39.1s\tremaining: 3m 56s\n",
            "7200:\tlearn: 1.0813248\ttest: 1.0896992\tbest: 1.0896878 (7113)\ttotal: 39.7s\tremaining: 3m 55s\n",
            "7300:\tlearn: 1.0812327\ttest: 1.0897016\tbest: 1.0896878 (7113)\ttotal: 40.3s\tremaining: 3m 55s\n",
            "7400:\tlearn: 1.0811415\ttest: 1.0897000\tbest: 1.0896878 (7113)\ttotal: 40.9s\tremaining: 3m 55s\n",
            "7500:\tlearn: 1.0810484\ttest: 1.0896748\tbest: 1.0896740 (7498)\ttotal: 41.5s\tremaining: 3m 54s\n",
            "7600:\tlearn: 1.0809593\ttest: 1.0896821\tbest: 1.0896712 (7512)\ttotal: 42.1s\tremaining: 3m 54s\n",
            "7700:\tlearn: 1.0808640\ttest: 1.0896682\tbest: 1.0896673 (7696)\ttotal: 42.6s\tremaining: 3m 54s\n",
            "7800:\tlearn: 1.0807805\ttest: 1.0896557\tbest: 1.0896548 (7784)\ttotal: 43.2s\tremaining: 3m 53s\n",
            "7900:\tlearn: 1.0806904\ttest: 1.0896556\tbest: 1.0896462 (7828)\ttotal: 43.8s\tremaining: 3m 53s\n",
            "8000:\tlearn: 1.0806048\ttest: 1.0896518\tbest: 1.0896462 (7828)\ttotal: 44.4s\tremaining: 3m 53s\n",
            "8100:\tlearn: 1.0805242\ttest: 1.0896492\tbest: 1.0896462 (7828)\ttotal: 45s\tremaining: 3m 52s\n",
            "8200:\tlearn: 1.0804406\ttest: 1.0896441\tbest: 1.0896391 (8157)\ttotal: 45.6s\tremaining: 3m 52s\n",
            "8300:\tlearn: 1.0803553\ttest: 1.0896470\tbest: 1.0896391 (8157)\ttotal: 46.1s\tremaining: 3m 51s\n",
            "8400:\tlearn: 1.0802757\ttest: 1.0896428\tbest: 1.0896358 (8368)\ttotal: 46.7s\tremaining: 3m 51s\n",
            "8500:\tlearn: 1.0801896\ttest: 1.0896223\tbest: 1.0896223 (8499)\ttotal: 47.2s\tremaining: 3m 50s\n",
            "8600:\tlearn: 1.0801101\ttest: 1.0896186\tbest: 1.0896130 (8535)\ttotal: 47.8s\tremaining: 3m 50s\n",
            "8700:\tlearn: 1.0800227\ttest: 1.0896128\tbest: 1.0896099 (8636)\ttotal: 48.4s\tremaining: 3m 49s\n",
            "8800:\tlearn: 1.0799390\ttest: 1.0896138\tbest: 1.0896099 (8636)\ttotal: 49s\tremaining: 3m 49s\n",
            "8900:\tlearn: 1.0798525\ttest: 1.0896100\tbest: 1.0896067 (8879)\ttotal: 49.6s\tremaining: 3m 48s\n",
            "9000:\tlearn: 1.0797730\ttest: 1.0896022\tbest: 1.0895996 (8981)\ttotal: 50.2s\tremaining: 3m 48s\n",
            "9100:\tlearn: 1.0796987\ttest: 1.0896025\tbest: 1.0895964 (9026)\ttotal: 50.7s\tremaining: 3m 47s\n",
            "9200:\tlearn: 1.0796343\ttest: 1.0895924\tbest: 1.0895924 (9200)\ttotal: 51.3s\tremaining: 3m 47s\n",
            "9300:\tlearn: 1.0795565\ttest: 1.0895854\tbest: 1.0895852 (9298)\ttotal: 51.9s\tremaining: 3m 47s\n",
            "9400:\tlearn: 1.0794781\ttest: 1.0895708\tbest: 1.0895702 (9399)\ttotal: 52.5s\tremaining: 3m 46s\n",
            "9500:\tlearn: 1.0793972\ttest: 1.0895685\tbest: 1.0895637 (9424)\ttotal: 53.1s\tremaining: 3m 46s\n",
            "9600:\tlearn: 1.0793266\ttest: 1.0895677\tbest: 1.0895637 (9424)\ttotal: 53.7s\tremaining: 3m 45s\n",
            "9700:\tlearn: 1.0792443\ttest: 1.0895614\tbest: 1.0895580 (9639)\ttotal: 54.3s\tremaining: 3m 45s\n",
            "9800:\tlearn: 1.0791703\ttest: 1.0895480\tbest: 1.0895465 (9791)\ttotal: 54.8s\tremaining: 3m 44s\n",
            "9900:\tlearn: 1.0790902\ttest: 1.0895406\tbest: 1.0895362 (9890)\ttotal: 55.4s\tremaining: 3m 44s\n",
            "10000:\tlearn: 1.0790207\ttest: 1.0895442\tbest: 1.0895362 (9890)\ttotal: 56s\tremaining: 3m 44s\n",
            "10100:\tlearn: 1.0789500\ttest: 1.0895476\tbest: 1.0895362 (9890)\ttotal: 56.6s\tremaining: 3m 43s\n",
            "10200:\tlearn: 1.0788766\ttest: 1.0895465\tbest: 1.0895362 (9890)\ttotal: 57.2s\tremaining: 3m 43s\n",
            "10300:\tlearn: 1.0788102\ttest: 1.0895466\tbest: 1.0895362 (9890)\ttotal: 57.8s\tremaining: 3m 42s\n",
            "10400:\tlearn: 1.0787404\ttest: 1.0895590\tbest: 1.0895362 (9890)\ttotal: 58.4s\tremaining: 3m 42s\n",
            "10500:\tlearn: 1.0786699\ttest: 1.0895544\tbest: 1.0895362 (9890)\ttotal: 59s\tremaining: 3m 41s\n",
            "10600:\tlearn: 1.0785952\ttest: 1.0895574\tbest: 1.0895362 (9890)\ttotal: 59.6s\tremaining: 3m 41s\n",
            "10700:\tlearn: 1.0785261\ttest: 1.0895559\tbest: 1.0895362 (9890)\ttotal: 1m\tremaining: 3m 40s\n",
            "10800:\tlearn: 1.0784551\ttest: 1.0895624\tbest: 1.0895362 (9890)\ttotal: 1m\tremaining: 3m 40s\n",
            "bestTest = 1.08953623\n",
            "bestIteration = 9890\n",
            "Shrink model to first 9891 iterations.\n",
            "0:\tlearn: 1.3666836\ttest: 1.3666808\tbest: 1.3666808 (0)\ttotal: 5.72ms\tremaining: 4m 46s\n",
            "100:\tlearn: 1.1116944\ttest: 1.1119340\tbest: 1.1119340 (100)\ttotal: 487ms\tremaining: 4m\n",
            "200:\tlearn: 1.1068969\ttest: 1.1073361\tbest: 1.1073361 (200)\ttotal: 962ms\tremaining: 3m 58s\n",
            "300:\tlearn: 1.1036559\ttest: 1.1042936\tbest: 1.1042936 (300)\ttotal: 1.46s\tremaining: 4m\n",
            "400:\tlearn: 1.1012674\ttest: 1.1021521\tbest: 1.1021521 (400)\ttotal: 1.94s\tremaining: 4m\n",
            "500:\tlearn: 1.0992155\ttest: 1.1003088\tbest: 1.1003088 (500)\ttotal: 2.42s\tremaining: 3m 58s\n",
            "600:\tlearn: 1.0975617\ttest: 1.0988579\tbest: 1.0988579 (600)\ttotal: 2.89s\tremaining: 3m 57s\n",
            "700:\tlearn: 1.0962472\ttest: 1.0977067\tbest: 1.0977067 (700)\ttotal: 3.39s\tremaining: 3m 58s\n",
            "800:\tlearn: 1.0950989\ttest: 1.0967247\tbest: 1.0967247 (800)\ttotal: 3.93s\tremaining: 4m 1s\n",
            "900:\tlearn: 1.0941362\ttest: 1.0959601\tbest: 1.0959601 (900)\ttotal: 4.43s\tremaining: 4m 1s\n",
            "1000:\tlearn: 1.0933084\ttest: 1.0953002\tbest: 1.0953002 (1000)\ttotal: 4.94s\tremaining: 4m 1s\n",
            "1100:\tlearn: 1.0926115\ttest: 1.0947406\tbest: 1.0947406 (1100)\ttotal: 5.46s\tremaining: 4m 2s\n",
            "1200:\tlearn: 1.0919862\ttest: 1.0943042\tbest: 1.0943042 (1200)\ttotal: 5.99s\tremaining: 4m 3s\n",
            "1300:\tlearn: 1.0914090\ttest: 1.0939226\tbest: 1.0939226 (1300)\ttotal: 6.53s\tremaining: 4m 4s\n",
            "1400:\tlearn: 1.0908889\ttest: 1.0935679\tbest: 1.0935679 (1400)\ttotal: 7.08s\tremaining: 4m 5s\n",
            "1500:\tlearn: 1.0904494\ttest: 1.0932376\tbest: 1.0932376 (1500)\ttotal: 7.61s\tremaining: 4m 5s\n",
            "1600:\tlearn: 1.0900247\ttest: 1.0929494\tbest: 1.0929494 (1600)\ttotal: 8.15s\tremaining: 4m 6s\n",
            "1700:\tlearn: 1.0896514\ttest: 1.0926923\tbest: 1.0926923 (1700)\ttotal: 8.7s\tremaining: 4m 6s\n",
            "1800:\tlearn: 1.0893226\ttest: 1.0924742\tbest: 1.0924742 (1800)\ttotal: 9.23s\tremaining: 4m 6s\n",
            "1900:\tlearn: 1.0889883\ttest: 1.0922589\tbest: 1.0922589 (1900)\ttotal: 9.78s\tremaining: 4m 7s\n",
            "2000:\tlearn: 1.0887075\ttest: 1.0920820\tbest: 1.0920820 (2000)\ttotal: 10.3s\tremaining: 4m 7s\n",
            "2100:\tlearn: 1.0884003\ttest: 1.0918960\tbest: 1.0918960 (2100)\ttotal: 10.9s\tremaining: 4m 7s\n",
            "2200:\tlearn: 1.0881116\ttest: 1.0917381\tbest: 1.0917369 (2197)\ttotal: 11.4s\tremaining: 4m 7s\n",
            "2300:\tlearn: 1.0878636\ttest: 1.0915822\tbest: 1.0915822 (2300)\ttotal: 12s\tremaining: 4m 7s\n",
            "2400:\tlearn: 1.0876123\ttest: 1.0914578\tbest: 1.0914578 (2400)\ttotal: 12.5s\tremaining: 4m 7s\n",
            "2500:\tlearn: 1.0873662\ttest: 1.0913324\tbest: 1.0913324 (2500)\ttotal: 13s\tremaining: 4m 7s\n",
            "2600:\tlearn: 1.0871498\ttest: 1.0912127\tbest: 1.0912114 (2599)\ttotal: 13.6s\tremaining: 4m 6s\n",
            "2700:\tlearn: 1.0869543\ttest: 1.0911475\tbest: 1.0911475 (2700)\ttotal: 14.1s\tremaining: 4m 6s\n",
            "2800:\tlearn: 1.0867526\ttest: 1.0910678\tbest: 1.0910678 (2800)\ttotal: 14.6s\tremaining: 4m 6s\n",
            "2900:\tlearn: 1.0865382\ttest: 1.0909868\tbest: 1.0909856 (2899)\ttotal: 15.2s\tremaining: 4m 6s\n",
            "3000:\tlearn: 1.0863403\ttest: 1.0909175\tbest: 1.0909175 (3000)\ttotal: 15.7s\tremaining: 4m 5s\n",
            "3100:\tlearn: 1.0861657\ttest: 1.0908385\tbest: 1.0908372 (3098)\ttotal: 16.2s\tremaining: 4m 5s\n",
            "3200:\tlearn: 1.0859811\ttest: 1.0907758\tbest: 1.0907758 (3200)\ttotal: 16.8s\tremaining: 4m 5s\n",
            "3300:\tlearn: 1.0858069\ttest: 1.0907113\tbest: 1.0907113 (3300)\ttotal: 17.3s\tremaining: 4m 5s\n",
            "3400:\tlearn: 1.0856368\ttest: 1.0906332\tbest: 1.0906330 (3384)\ttotal: 17.9s\tremaining: 4m 5s\n",
            "3500:\tlearn: 1.0854753\ttest: 1.0905701\tbest: 1.0905693 (3499)\ttotal: 18.4s\tremaining: 4m 4s\n",
            "3600:\tlearn: 1.0853225\ttest: 1.0905120\tbest: 1.0905120 (3600)\ttotal: 19s\tremaining: 4m 4s\n",
            "3700:\tlearn: 1.0851714\ttest: 1.0904545\tbest: 1.0904545 (3699)\ttotal: 19.5s\tremaining: 4m 3s\n",
            "3800:\tlearn: 1.0850292\ttest: 1.0904181\tbest: 1.0904127 (3798)\ttotal: 20s\tremaining: 4m 3s\n",
            "3900:\tlearn: 1.0848881\ttest: 1.0903716\tbest: 1.0903716 (3900)\ttotal: 20.5s\tremaining: 4m 2s\n",
            "4000:\tlearn: 1.0847467\ttest: 1.0903240\tbest: 1.0903240 (4000)\ttotal: 21s\tremaining: 4m 1s\n",
            "4100:\tlearn: 1.0846027\ttest: 1.0902721\tbest: 1.0902721 (4100)\ttotal: 21.5s\tremaining: 4m\n",
            "4200:\tlearn: 1.0844627\ttest: 1.0902423\tbest: 1.0902415 (4196)\ttotal: 22s\tremaining: 4m\n",
            "4300:\tlearn: 1.0843227\ttest: 1.0901845\tbest: 1.0901845 (4300)\ttotal: 22.6s\tremaining: 4m\n",
            "4400:\tlearn: 1.0841964\ttest: 1.0901364\tbest: 1.0901346 (4396)\ttotal: 23.1s\tremaining: 3m 59s\n",
            "4500:\tlearn: 1.0840668\ttest: 1.0900945\tbest: 1.0900945 (4500)\ttotal: 23.7s\tremaining: 3m 59s\n",
            "4600:\tlearn: 1.0839316\ttest: 1.0900699\tbest: 1.0900699 (4600)\ttotal: 24.1s\tremaining: 3m 58s\n",
            "4700:\tlearn: 1.0838091\ttest: 1.0900481\tbest: 1.0900476 (4699)\ttotal: 24.6s\tremaining: 3m 57s\n",
            "4800:\tlearn: 1.0836762\ttest: 1.0900255\tbest: 1.0900215 (4778)\ttotal: 25.1s\tremaining: 3m 56s\n",
            "4900:\tlearn: 1.0835532\ttest: 1.0899772\tbest: 1.0899751 (4894)\ttotal: 25.7s\tremaining: 3m 56s\n",
            "5000:\tlearn: 1.0834528\ttest: 1.0899521\tbest: 1.0899521 (5000)\ttotal: 26.2s\tremaining: 3m 55s\n",
            "5100:\tlearn: 1.0833443\ttest: 1.0899290\tbest: 1.0899288 (5098)\ttotal: 26.7s\tremaining: 3m 54s\n",
            "5200:\tlearn: 1.0832265\ttest: 1.0898943\tbest: 1.0898931 (5197)\ttotal: 27.2s\tremaining: 3m 54s\n",
            "5300:\tlearn: 1.0831257\ttest: 1.0898657\tbest: 1.0898657 (5300)\ttotal: 27.8s\tremaining: 3m 54s\n",
            "5400:\tlearn: 1.0830155\ttest: 1.0898429\tbest: 1.0898420 (5399)\ttotal: 28.3s\tremaining: 3m 53s\n",
            "5500:\tlearn: 1.0829116\ttest: 1.0898304\tbest: 1.0898298 (5484)\ttotal: 28.8s\tremaining: 3m 53s\n",
            "5600:\tlearn: 1.0828121\ttest: 1.0898258\tbest: 1.0898258 (5600)\ttotal: 29.4s\tremaining: 3m 52s\n",
            "5700:\tlearn: 1.0827088\ttest: 1.0898133\tbest: 1.0898120 (5699)\ttotal: 29.9s\tremaining: 3m 52s\n",
            "5800:\tlearn: 1.0826177\ttest: 1.0897903\tbest: 1.0897903 (5800)\ttotal: 30.5s\tremaining: 3m 52s\n",
            "5900:\tlearn: 1.0825162\ttest: 1.0897806\tbest: 1.0897775 (5892)\ttotal: 31s\tremaining: 3m 51s\n",
            "6000:\tlearn: 1.0824203\ttest: 1.0897574\tbest: 1.0897562 (5999)\ttotal: 31.5s\tremaining: 3m 51s\n",
            "6100:\tlearn: 1.0823274\ttest: 1.0897370\tbest: 1.0897355 (6089)\ttotal: 32.1s\tremaining: 3m 50s\n",
            "6200:\tlearn: 1.0822248\ttest: 1.0897103\tbest: 1.0897103 (6200)\ttotal: 32.6s\tremaining: 3m 50s\n",
            "6300:\tlearn: 1.0821149\ttest: 1.0896869\tbest: 1.0896860 (6298)\ttotal: 33.2s\tremaining: 3m 49s\n",
            "6400:\tlearn: 1.0820229\ttest: 1.0896808\tbest: 1.0896794 (6396)\ttotal: 33.7s\tremaining: 3m 49s\n",
            "6500:\tlearn: 1.0819272\ttest: 1.0896587\tbest: 1.0896587 (6500)\ttotal: 34.2s\tremaining: 3m 49s\n",
            "6600:\tlearn: 1.0818348\ttest: 1.0896445\tbest: 1.0896371 (6561)\ttotal: 34.8s\tremaining: 3m 48s\n",
            "6700:\tlearn: 1.0817421\ttest: 1.0896154\tbest: 1.0896154 (6699)\ttotal: 35.3s\tremaining: 3m 48s\n",
            "6800:\tlearn: 1.0816462\ttest: 1.0895954\tbest: 1.0895954 (6800)\ttotal: 35.9s\tremaining: 3m 47s\n",
            "6900:\tlearn: 1.0815553\ttest: 1.0895808\tbest: 1.0895769 (6837)\ttotal: 36.4s\tremaining: 3m 47s\n",
            "7000:\tlearn: 1.0814728\ttest: 1.0895650\tbest: 1.0895642 (6986)\ttotal: 36.9s\tremaining: 3m 46s\n",
            "7100:\tlearn: 1.0813884\ttest: 1.0895713\tbest: 1.0895594 (7049)\ttotal: 37.5s\tremaining: 3m 46s\n",
            "7200:\tlearn: 1.0812950\ttest: 1.0895565\tbest: 1.0895558 (7198)\ttotal: 38s\tremaining: 3m 45s\n",
            "7300:\tlearn: 1.0812139\ttest: 1.0895440\tbest: 1.0895432 (7299)\ttotal: 38.5s\tremaining: 3m 45s\n",
            "7400:\tlearn: 1.0811303\ttest: 1.0895319\tbest: 1.0895311 (7380)\ttotal: 39.1s\tremaining: 3m 44s\n",
            "7500:\tlearn: 1.0810465\ttest: 1.0895146\tbest: 1.0895146 (7500)\ttotal: 39.6s\tremaining: 3m 44s\n",
            "7600:\tlearn: 1.0809519\ttest: 1.0895021\tbest: 1.0895013 (7596)\ttotal: 40.1s\tremaining: 3m 43s\n",
            "7700:\tlearn: 1.0808636\ttest: 1.0894933\tbest: 1.0894910 (7686)\ttotal: 40.7s\tremaining: 3m 43s\n",
            "7800:\tlearn: 1.0807748\ttest: 1.0894834\tbest: 1.0894814 (7796)\ttotal: 41.2s\tremaining: 3m 42s\n",
            "7900:\tlearn: 1.0806955\ttest: 1.0894774\tbest: 1.0894774 (7898)\ttotal: 41.7s\tremaining: 3m 42s\n",
            "8000:\tlearn: 1.0806080\ttest: 1.0894696\tbest: 1.0894696 (8000)\ttotal: 42.3s\tremaining: 3m 41s\n",
            "8100:\tlearn: 1.0805264\ttest: 1.0894628\tbest: 1.0894619 (8041)\ttotal: 42.8s\tremaining: 3m 41s\n",
            "8200:\tlearn: 1.0804428\ttest: 1.0894594\tbest: 1.0894565 (8189)\ttotal: 43.4s\tremaining: 3m 41s\n",
            "8300:\tlearn: 1.0803519\ttest: 1.0894496\tbest: 1.0894437 (8286)\ttotal: 43.9s\tremaining: 3m 40s\n",
            "8400:\tlearn: 1.0802854\ttest: 1.0894360\tbest: 1.0894360 (8383)\ttotal: 44.5s\tremaining: 3m 40s\n",
            "8500:\tlearn: 1.0802017\ttest: 1.0894209\tbest: 1.0894192 (8498)\ttotal: 45s\tremaining: 3m 39s\n",
            "8600:\tlearn: 1.0801187\ttest: 1.0894208\tbest: 1.0894152 (8513)\ttotal: 45.5s\tremaining: 3m 39s\n",
            "8700:\tlearn: 1.0800333\ttest: 1.0894220\tbest: 1.0894131 (8662)\ttotal: 46.1s\tremaining: 3m 38s\n",
            "8800:\tlearn: 1.0799497\ttest: 1.0894077\tbest: 1.0894076 (8797)\ttotal: 46.6s\tremaining: 3m 38s\n",
            "8900:\tlearn: 1.0798633\ttest: 1.0893933\tbest: 1.0893933 (8900)\ttotal: 47.2s\tremaining: 3m 37s\n",
            "9000:\tlearn: 1.0797913\ttest: 1.0893786\tbest: 1.0893786 (9000)\ttotal: 47.7s\tremaining: 3m 37s\n",
            "9100:\tlearn: 1.0797050\ttest: 1.0893792\tbest: 1.0893744 (9020)\ttotal: 48.3s\tremaining: 3m 36s\n",
            "9200:\tlearn: 1.0796261\ttest: 1.0893709\tbest: 1.0893673 (9134)\ttotal: 48.7s\tremaining: 3m 36s\n",
            "9300:\tlearn: 1.0795463\ttest: 1.0893687\tbest: 1.0893646 (9288)\ttotal: 49.2s\tremaining: 3m 35s\n",
            "9400:\tlearn: 1.0794695\ttest: 1.0893723\tbest: 1.0893617 (9330)\ttotal: 49.7s\tremaining: 3m 34s\n",
            "9500:\tlearn: 1.0793952\ttest: 1.0893729\tbest: 1.0893617 (9330)\ttotal: 50.2s\tremaining: 3m 34s\n",
            "9600:\tlearn: 1.0793122\ttest: 1.0893771\tbest: 1.0893617 (9330)\ttotal: 50.7s\tremaining: 3m 33s\n",
            "9700:\tlearn: 1.0792367\ttest: 1.0893863\tbest: 1.0893617 (9330)\ttotal: 51.2s\tremaining: 3m 32s\n",
            "9800:\tlearn: 1.0791564\ttest: 1.0893797\tbest: 1.0893617 (9330)\ttotal: 51.7s\tremaining: 3m 32s\n",
            "9900:\tlearn: 1.0790843\ttest: 1.0893789\tbest: 1.0893617 (9330)\ttotal: 52.2s\tremaining: 3m 31s\n",
            "10000:\tlearn: 1.0790040\ttest: 1.0893682\tbest: 1.0893617 (9330)\ttotal: 52.7s\tremaining: 3m 30s\n",
            "10100:\tlearn: 1.0789285\ttest: 1.0893619\tbest: 1.0893615 (10096)\ttotal: 53.2s\tremaining: 3m 30s\n",
            "10200:\tlearn: 1.0788500\ttest: 1.0893506\tbest: 1.0893489 (10197)\ttotal: 53.7s\tremaining: 3m 29s\n",
            "10300:\tlearn: 1.0787825\ttest: 1.0893473\tbest: 1.0893397 (10264)\ttotal: 54.2s\tremaining: 3m 28s\n",
            "10400:\tlearn: 1.0787094\ttest: 1.0893429\tbest: 1.0893397 (10264)\ttotal: 54.7s\tremaining: 3m 28s\n",
            "10500:\tlearn: 1.0786396\ttest: 1.0893358\tbest: 1.0893346 (10474)\ttotal: 55.2s\tremaining: 3m 27s\n",
            "10600:\tlearn: 1.0785585\ttest: 1.0893410\tbest: 1.0893341 (10508)\ttotal: 55.6s\tremaining: 3m 26s\n",
            "10700:\tlearn: 1.0784875\ttest: 1.0893326\tbest: 1.0893294 (10640)\ttotal: 56.1s\tremaining: 3m 26s\n",
            "10800:\tlearn: 1.0784125\ttest: 1.0893335\tbest: 1.0893294 (10640)\ttotal: 56.7s\tremaining: 3m 25s\n",
            "10900:\tlearn: 1.0783314\ttest: 1.0893251\tbest: 1.0893213 (10887)\ttotal: 57.2s\tremaining: 3m 25s\n",
            "11000:\tlearn: 1.0782569\ttest: 1.0893248\tbest: 1.0893190 (10932)\ttotal: 57.8s\tremaining: 3m 24s\n",
            "11100:\tlearn: 1.0781820\ttest: 1.0893298\tbest: 1.0893190 (10932)\ttotal: 58.3s\tremaining: 3m 24s\n",
            "11200:\tlearn: 1.0781148\ttest: 1.0893233\tbest: 1.0893190 (10932)\ttotal: 58.8s\tremaining: 3m 23s\n",
            "11300:\tlearn: 1.0780500\ttest: 1.0893209\tbest: 1.0893190 (10932)\ttotal: 59.4s\tremaining: 3m 23s\n",
            "11400:\tlearn: 1.0779796\ttest: 1.0893097\tbest: 1.0893070 (11389)\ttotal: 59.9s\tremaining: 3m 22s\n",
            "11500:\tlearn: 1.0779100\ttest: 1.0893123\tbest: 1.0893070 (11389)\ttotal: 1m\tremaining: 3m 22s\n",
            "11600:\tlearn: 1.0778382\ttest: 1.0893212\tbest: 1.0893070 (11389)\ttotal: 1m\tremaining: 3m 21s\n",
            "11700:\tlearn: 1.0777688\ttest: 1.0893222\tbest: 1.0893070 (11389)\ttotal: 1m 1s\tremaining: 3m 21s\n",
            "11800:\tlearn: 1.0776917\ttest: 1.0893183\tbest: 1.0893070 (11389)\ttotal: 1m 2s\tremaining: 3m 20s\n",
            "11900:\tlearn: 1.0776203\ttest: 1.0893275\tbest: 1.0893070 (11389)\ttotal: 1m 2s\tremaining: 3m 20s\n",
            "12000:\tlearn: 1.0775507\ttest: 1.0893279\tbest: 1.0893070 (11389)\ttotal: 1m 3s\tremaining: 3m 19s\n",
            "12100:\tlearn: 1.0774802\ttest: 1.0893286\tbest: 1.0893070 (11389)\ttotal: 1m 3s\tremaining: 3m 19s\n",
            "12200:\tlearn: 1.0774108\ttest: 1.0893272\tbest: 1.0893070 (11389)\ttotal: 1m 4s\tremaining: 3m 18s\n",
            "12300:\tlearn: 1.0773454\ttest: 1.0893150\tbest: 1.0893070 (11389)\ttotal: 1m 4s\tremaining: 3m 18s\n",
            "bestTest = 1.089307031\n",
            "bestIteration = 11389\n",
            "Shrink model to first 11390 iterations.\n",
            "0:\tlearn: 1.3669023\ttest: 1.3669279\tbest: 1.3669279 (0)\ttotal: 7.01ms\tremaining: 5m 50s\n",
            "100:\tlearn: 1.1116432\ttest: 1.1119558\tbest: 1.1119558 (100)\ttotal: 516ms\tremaining: 4m 14s\n",
            "200:\tlearn: 1.1068325\ttest: 1.1074142\tbest: 1.1074142 (200)\ttotal: 1.02s\tremaining: 4m 12s\n",
            "300:\tlearn: 1.1036599\ttest: 1.1045890\tbest: 1.1045890 (300)\ttotal: 1.52s\tremaining: 4m 11s\n",
            "400:\tlearn: 1.1012431\ttest: 1.1023027\tbest: 1.1023027 (400)\ttotal: 2.06s\tremaining: 4m 14s\n",
            "500:\tlearn: 1.0993083\ttest: 1.1005646\tbest: 1.1005646 (500)\ttotal: 2.61s\tremaining: 4m 17s\n",
            "600:\tlearn: 1.0977629\ttest: 1.0991184\tbest: 1.0991184 (600)\ttotal: 3.16s\tremaining: 4m 19s\n",
            "700:\tlearn: 1.0964235\ttest: 1.0979141\tbest: 1.0979141 (700)\ttotal: 3.71s\tremaining: 4m 20s\n",
            "800:\tlearn: 1.0953138\ttest: 1.0969657\tbest: 1.0969657 (800)\ttotal: 4.25s\tremaining: 4m 21s\n",
            "900:\tlearn: 1.0943256\ttest: 1.0961047\tbest: 1.0961047 (900)\ttotal: 4.81s\tremaining: 4m 21s\n",
            "1000:\tlearn: 1.0935163\ttest: 1.0954789\tbest: 1.0954789 (1000)\ttotal: 5.36s\tremaining: 4m 22s\n",
            "1100:\tlearn: 1.0927757\ttest: 1.0948641\tbest: 1.0948641 (1100)\ttotal: 5.9s\tremaining: 4m 22s\n",
            "1200:\tlearn: 1.0921312\ttest: 1.0943774\tbest: 1.0943774 (1200)\ttotal: 6.47s\tremaining: 4m 22s\n",
            "1300:\tlearn: 1.0915803\ttest: 1.0939659\tbest: 1.0939659 (1300)\ttotal: 7.01s\tremaining: 4m 22s\n",
            "1400:\tlearn: 1.0910924\ttest: 1.0936354\tbest: 1.0936354 (1400)\ttotal: 7.56s\tremaining: 4m 22s\n",
            "1500:\tlearn: 1.0906485\ttest: 1.0933069\tbest: 1.0933069 (1500)\ttotal: 8.1s\tremaining: 4m 21s\n",
            "1600:\tlearn: 1.0902363\ttest: 1.0930482\tbest: 1.0930482 (1600)\ttotal: 8.64s\tremaining: 4m 21s\n",
            "1700:\tlearn: 1.0898634\ttest: 1.0928487\tbest: 1.0928487 (1700)\ttotal: 9.18s\tremaining: 4m 20s\n",
            "1800:\tlearn: 1.0895232\ttest: 1.0926252\tbest: 1.0926252 (1800)\ttotal: 9.72s\tremaining: 4m 20s\n",
            "1900:\tlearn: 1.0891749\ttest: 1.0924055\tbest: 1.0924055 (1900)\ttotal: 10.3s\tremaining: 4m 19s\n",
            "2000:\tlearn: 1.0888847\ttest: 1.0922491\tbest: 1.0922491 (2000)\ttotal: 10.8s\tremaining: 4m 18s\n",
            "2100:\tlearn: 1.0885862\ttest: 1.0920928\tbest: 1.0920919 (2099)\ttotal: 11.3s\tremaining: 4m 18s\n",
            "2200:\tlearn: 1.0883072\ttest: 1.0919394\tbest: 1.0919361 (2198)\ttotal: 11.9s\tremaining: 4m 18s\n",
            "2300:\tlearn: 1.0880420\ttest: 1.0918300\tbest: 1.0918300 (2300)\ttotal: 12.5s\tremaining: 4m 18s\n",
            "2400:\tlearn: 1.0877978\ttest: 1.0916868\tbest: 1.0916868 (2400)\ttotal: 13s\tremaining: 4m 17s\n",
            "2500:\tlearn: 1.0875630\ttest: 1.0915592\tbest: 1.0915591 (2498)\ttotal: 13.5s\tremaining: 4m 17s\n",
            "2600:\tlearn: 1.0873396\ttest: 1.0914612\tbest: 1.0914604 (2598)\ttotal: 14.1s\tremaining: 4m 16s\n",
            "2700:\tlearn: 1.0871362\ttest: 1.0913574\tbest: 1.0913574 (2700)\ttotal: 14.6s\tremaining: 4m 16s\n",
            "2800:\tlearn: 1.0869379\ttest: 1.0912561\tbest: 1.0912542 (2798)\ttotal: 15.2s\tremaining: 4m 15s\n",
            "2900:\tlearn: 1.0867377\ttest: 1.0911813\tbest: 1.0911805 (2899)\ttotal: 15.7s\tremaining: 4m 15s\n",
            "3000:\tlearn: 1.0865412\ttest: 1.0910821\tbest: 1.0910819 (2999)\ttotal: 16.3s\tremaining: 4m 14s\n",
            "3100:\tlearn: 1.0863708\ttest: 1.0910152\tbest: 1.0910152 (3100)\ttotal: 16.8s\tremaining: 4m 14s\n",
            "3200:\tlearn: 1.0861806\ttest: 1.0909316\tbest: 1.0909302 (3193)\ttotal: 17.4s\tremaining: 4m 14s\n",
            "3300:\tlearn: 1.0860113\ttest: 1.0908832\tbest: 1.0908832 (3300)\ttotal: 17.9s\tremaining: 4m 13s\n",
            "3400:\tlearn: 1.0858560\ttest: 1.0908230\tbest: 1.0908230 (3400)\ttotal: 18.4s\tremaining: 4m 11s\n",
            "3500:\tlearn: 1.0856933\ttest: 1.0907806\tbest: 1.0907806 (3497)\ttotal: 18.9s\tremaining: 4m 10s\n",
            "3600:\tlearn: 1.0855433\ttest: 1.0907263\tbest: 1.0907263 (3600)\ttotal: 19.4s\tremaining: 4m 9s\n",
            "3700:\tlearn: 1.0853779\ttest: 1.0906725\tbest: 1.0906702 (3695)\ttotal: 19.9s\tremaining: 4m 8s\n",
            "3800:\tlearn: 1.0852294\ttest: 1.0906143\tbest: 1.0906105 (3796)\ttotal: 20.4s\tremaining: 4m 8s\n",
            "3900:\tlearn: 1.0850762\ttest: 1.0905779\tbest: 1.0905772 (3899)\ttotal: 20.9s\tremaining: 4m 7s\n",
            "4000:\tlearn: 1.0849352\ttest: 1.0905394\tbest: 1.0905376 (3996)\ttotal: 21.4s\tremaining: 4m 5s\n",
            "4100:\tlearn: 1.0847864\ttest: 1.0904928\tbest: 1.0904925 (4099)\ttotal: 21.9s\tremaining: 4m 5s\n",
            "4200:\tlearn: 1.0846396\ttest: 1.0904502\tbest: 1.0904491 (4197)\ttotal: 22.4s\tremaining: 4m 4s\n",
            "4300:\tlearn: 1.0844933\ttest: 1.0903860\tbest: 1.0903855 (4298)\ttotal: 22.9s\tremaining: 4m 3s\n",
            "4400:\tlearn: 1.0843646\ttest: 1.0903540\tbest: 1.0903525 (4396)\ttotal: 23.4s\tremaining: 4m 2s\n",
            "4500:\tlearn: 1.0842354\ttest: 1.0903214\tbest: 1.0903214 (4500)\ttotal: 23.9s\tremaining: 4m 1s\n",
            "4600:\tlearn: 1.0841036\ttest: 1.0902932\tbest: 1.0902906 (4588)\ttotal: 24.4s\tremaining: 4m\n",
            "4700:\tlearn: 1.0839881\ttest: 1.0902771\tbest: 1.0902734 (4696)\ttotal: 24.9s\tremaining: 4m\n",
            "4800:\tlearn: 1.0838715\ttest: 1.0902487\tbest: 1.0902487 (4799)\ttotal: 25.5s\tremaining: 3m 59s\n",
            "4900:\tlearn: 1.0837483\ttest: 1.0902083\tbest: 1.0902068 (4899)\ttotal: 26s\tremaining: 3m 59s\n",
            "5000:\tlearn: 1.0836320\ttest: 1.0901755\tbest: 1.0901745 (4992)\ttotal: 26.5s\tremaining: 3m 58s\n",
            "5100:\tlearn: 1.0835111\ttest: 1.0901466\tbest: 1.0901440 (5093)\ttotal: 27.1s\tremaining: 3m 58s\n",
            "5200:\tlearn: 1.0834002\ttest: 1.0901316\tbest: 1.0901280 (5189)\ttotal: 27.6s\tremaining: 3m 57s\n",
            "5300:\tlearn: 1.0832917\ttest: 1.0901083\tbest: 1.0901032 (5292)\ttotal: 28.2s\tremaining: 3m 57s\n",
            "5400:\tlearn: 1.0831795\ttest: 1.0900836\tbest: 1.0900820 (5390)\ttotal: 28.7s\tremaining: 3m 57s\n",
            "5500:\tlearn: 1.0830569\ttest: 1.0900590\tbest: 1.0900545 (5489)\ttotal: 29.2s\tremaining: 3m 56s\n",
            "5600:\tlearn: 1.0829340\ttest: 1.0900419\tbest: 1.0900384 (5597)\ttotal: 29.8s\tremaining: 3m 56s\n",
            "5700:\tlearn: 1.0828212\ttest: 1.0900063\tbest: 1.0900008 (5687)\ttotal: 30.3s\tremaining: 3m 55s\n",
            "5800:\tlearn: 1.0827110\ttest: 1.0899920\tbest: 1.0899908 (5799)\ttotal: 30.9s\tremaining: 3m 55s\n",
            "5900:\tlearn: 1.0826109\ttest: 1.0899574\tbest: 1.0899574 (5900)\ttotal: 31.4s\tremaining: 3m 54s\n",
            "6000:\tlearn: 1.0824953\ttest: 1.0899405\tbest: 1.0899405 (6000)\ttotal: 32s\tremaining: 3m 54s\n",
            "6100:\tlearn: 1.0823963\ttest: 1.0899276\tbest: 1.0899273 (6091)\ttotal: 32.5s\tremaining: 3m 53s\n",
            "6200:\tlearn: 1.0823020\ttest: 1.0899172\tbest: 1.0899172 (6200)\ttotal: 33s\tremaining: 3m 53s\n",
            "6300:\tlearn: 1.0821945\ttest: 1.0898903\tbest: 1.0898839 (6293)\ttotal: 33.6s\tremaining: 3m 52s\n",
            "6400:\tlearn: 1.0821011\ttest: 1.0898847\tbest: 1.0898820 (6389)\ttotal: 34.1s\tremaining: 3m 52s\n",
            "6500:\tlearn: 1.0820048\ttest: 1.0898709\tbest: 1.0898700 (6492)\ttotal: 34.6s\tremaining: 3m 51s\n",
            "6600:\tlearn: 1.0819054\ttest: 1.0898470\tbest: 1.0898466 (6599)\ttotal: 35.2s\tremaining: 3m 51s\n",
            "6700:\tlearn: 1.0818029\ttest: 1.0898298\tbest: 1.0898298 (6700)\ttotal: 35.7s\tremaining: 3m 50s\n",
            "6800:\tlearn: 1.0817054\ttest: 1.0898213\tbest: 1.0898138 (6774)\ttotal: 36.3s\tremaining: 3m 50s\n",
            "6900:\tlearn: 1.0816090\ttest: 1.0898122\tbest: 1.0898059 (6884)\ttotal: 36.8s\tremaining: 3m 49s\n",
            "7000:\tlearn: 1.0815096\ttest: 1.0897979\tbest: 1.0897973 (6969)\ttotal: 37.4s\tremaining: 3m 49s\n",
            "7100:\tlearn: 1.0814161\ttest: 1.0897959\tbest: 1.0897855 (7037)\ttotal: 37.9s\tremaining: 3m 49s\n",
            "7200:\tlearn: 1.0813315\ttest: 1.0897843\tbest: 1.0897833 (7194)\ttotal: 38.4s\tremaining: 3m 48s\n",
            "7300:\tlearn: 1.0812435\ttest: 1.0897925\tbest: 1.0897767 (7253)\ttotal: 39s\tremaining: 3m 48s\n",
            "7400:\tlearn: 1.0811460\ttest: 1.0897854\tbest: 1.0897767 (7253)\ttotal: 39.5s\tremaining: 3m 47s\n",
            "7500:\tlearn: 1.0810514\ttest: 1.0897762\tbest: 1.0897762 (7500)\ttotal: 40.1s\tremaining: 3m 47s\n",
            "7600:\tlearn: 1.0809662\ttest: 1.0897547\tbest: 1.0897547 (7600)\ttotal: 40.6s\tremaining: 3m 46s\n",
            "7700:\tlearn: 1.0808731\ttest: 1.0897230\tbest: 1.0897193 (7693)\ttotal: 41.2s\tremaining: 3m 46s\n",
            "7800:\tlearn: 1.0807930\ttest: 1.0897183\tbest: 1.0897114 (7756)\ttotal: 41.7s\tremaining: 3m 45s\n",
            "7900:\tlearn: 1.0807041\ttest: 1.0897338\tbest: 1.0897114 (7756)\ttotal: 42.3s\tremaining: 3m 45s\n",
            "8000:\tlearn: 1.0806196\ttest: 1.0897301\tbest: 1.0897114 (7756)\ttotal: 42.8s\tremaining: 3m 44s\n",
            "8100:\tlearn: 1.0805386\ttest: 1.0897276\tbest: 1.0897114 (7756)\ttotal: 43.3s\tremaining: 3m 44s\n",
            "8200:\tlearn: 1.0804464\ttest: 1.0897111\tbest: 1.0897063 (8187)\ttotal: 43.9s\tremaining: 3m 43s\n",
            "8300:\tlearn: 1.0803712\ttest: 1.0896930\tbest: 1.0896930 (8300)\ttotal: 44.4s\tremaining: 3m 43s\n",
            "8400:\tlearn: 1.0803017\ttest: 1.0896911\tbest: 1.0896863 (8365)\ttotal: 45s\tremaining: 3m 42s\n",
            "8500:\tlearn: 1.0802169\ttest: 1.0896861\tbest: 1.0896838 (8457)\ttotal: 45.5s\tremaining: 3m 42s\n",
            "8600:\tlearn: 1.0801323\ttest: 1.0896806\tbest: 1.0896800 (8596)\ttotal: 46.1s\tremaining: 3m 41s\n",
            "8700:\tlearn: 1.0800486\ttest: 1.0896697\tbest: 1.0896631 (8663)\ttotal: 46.6s\tremaining: 3m 41s\n",
            "8800:\tlearn: 1.0799732\ttest: 1.0896732\tbest: 1.0896631 (8663)\ttotal: 47.1s\tremaining: 3m 40s\n",
            "8900:\tlearn: 1.0798891\ttest: 1.0896789\tbest: 1.0896631 (8663)\ttotal: 47.7s\tremaining: 3m 40s\n",
            "9000:\tlearn: 1.0798092\ttest: 1.0896693\tbest: 1.0896631 (8663)\ttotal: 48.2s\tremaining: 3m 39s\n",
            "9100:\tlearn: 1.0797320\ttest: 1.0896650\tbest: 1.0896617 (9060)\ttotal: 48.8s\tremaining: 3m 39s\n",
            "9200:\tlearn: 1.0796575\ttest: 1.0896609\tbest: 1.0896576 (9192)\ttotal: 49.3s\tremaining: 3m 38s\n",
            "9300:\tlearn: 1.0795808\ttest: 1.0896571\tbest: 1.0896558 (9226)\ttotal: 49.9s\tremaining: 3m 38s\n",
            "9400:\tlearn: 1.0795067\ttest: 1.0896446\tbest: 1.0896404 (9376)\ttotal: 50.4s\tremaining: 3m 37s\n",
            "9500:\tlearn: 1.0794323\ttest: 1.0896488\tbest: 1.0896404 (9376)\ttotal: 51s\tremaining: 3m 37s\n",
            "9600:\tlearn: 1.0793506\ttest: 1.0896498\tbest: 1.0896404 (9376)\ttotal: 51.5s\tremaining: 3m 36s\n",
            "9700:\tlearn: 1.0792745\ttest: 1.0896362\tbest: 1.0896332 (9643)\ttotal: 52.1s\tremaining: 3m 36s\n",
            "9800:\tlearn: 1.0792052\ttest: 1.0896340\tbest: 1.0896332 (9643)\ttotal: 52.6s\tremaining: 3m 35s\n",
            "9900:\tlearn: 1.0791295\ttest: 1.0896351\tbest: 1.0896318 (9843)\ttotal: 53.2s\tremaining: 3m 35s\n",
            "10000:\tlearn: 1.0790499\ttest: 1.0896353\tbest: 1.0896267 (9991)\ttotal: 53.7s\tremaining: 3m 34s\n",
            "10100:\tlearn: 1.0789694\ttest: 1.0896461\tbest: 1.0896267 (9991)\ttotal: 54.3s\tremaining: 3m 34s\n",
            "10200:\tlearn: 1.0788994\ttest: 1.0896389\tbest: 1.0896267 (9991)\ttotal: 54.8s\tremaining: 3m 33s\n",
            "10300:\tlearn: 1.0788229\ttest: 1.0896306\tbest: 1.0896267 (9991)\ttotal: 55.4s\tremaining: 3m 33s\n",
            "10400:\tlearn: 1.0787496\ttest: 1.0896209\tbest: 1.0896186 (10397)\ttotal: 55.9s\tremaining: 3m 32s\n",
            "10500:\tlearn: 1.0786773\ttest: 1.0896315\tbest: 1.0896186 (10397)\ttotal: 56.5s\tremaining: 3m 32s\n",
            "10600:\tlearn: 1.0786019\ttest: 1.0896363\tbest: 1.0896186 (10397)\ttotal: 57s\tremaining: 3m 31s\n",
            "10700:\tlearn: 1.0785288\ttest: 1.0896443\tbest: 1.0896186 (10397)\ttotal: 57.5s\tremaining: 3m 31s\n",
            "10800:\tlearn: 1.0784497\ttest: 1.0896520\tbest: 1.0896186 (10397)\ttotal: 58.1s\tremaining: 3m 30s\n",
            "10900:\tlearn: 1.0783761\ttest: 1.0896468\tbest: 1.0896186 (10397)\ttotal: 58.6s\tremaining: 3m 30s\n",
            "11000:\tlearn: 1.0782950\ttest: 1.0896381\tbest: 1.0896186 (10397)\ttotal: 59.2s\tremaining: 3m 29s\n",
            "11100:\tlearn: 1.0782270\ttest: 1.0896379\tbest: 1.0896186 (10397)\ttotal: 59.7s\tremaining: 3m 29s\n",
            "11200:\tlearn: 1.0781497\ttest: 1.0896359\tbest: 1.0896186 (10397)\ttotal: 1m\tremaining: 3m 28s\n",
            "11300:\tlearn: 1.0780775\ttest: 1.0896340\tbest: 1.0896186 (10397)\ttotal: 1m\tremaining: 3m 28s\n",
            "bestTest = 1.089618555\n",
            "bestIteration = 10397\n",
            "Shrink model to first 10398 iterations.\n",
            "fold: 4,log_loss: 1.0892663067784591\n",
            "0:\tlearn: 1.3669115\ttest: 1.3668498\tbest: 1.3668498 (0)\ttotal: 5.79ms\tremaining: 4m 49s\n",
            "100:\tlearn: 1.1118182\ttest: 1.1122177\tbest: 1.1122177 (100)\ttotal: 453ms\tremaining: 3m 43s\n",
            "200:\tlearn: 1.1070438\ttest: 1.1076868\tbest: 1.1076868 (200)\ttotal: 928ms\tremaining: 3m 49s\n",
            "300:\tlearn: 1.1040246\ttest: 1.1047714\tbest: 1.1047714 (300)\ttotal: 1.41s\tremaining: 3m 52s\n",
            "400:\tlearn: 1.1016173\ttest: 1.1026315\tbest: 1.1026315 (400)\ttotal: 1.94s\tremaining: 3m 59s\n",
            "500:\tlearn: 1.0997297\ttest: 1.1009512\tbest: 1.1009512 (500)\ttotal: 2.42s\tremaining: 3m 59s\n",
            "600:\tlearn: 1.0981225\ttest: 1.0995271\tbest: 1.0995271 (600)\ttotal: 2.91s\tremaining: 3m 59s\n",
            "700:\tlearn: 1.0968376\ttest: 1.0984158\tbest: 1.0984158 (700)\ttotal: 3.4s\tremaining: 3m 58s\n",
            "800:\tlearn: 1.0957019\ttest: 1.0974888\tbest: 1.0974888 (800)\ttotal: 3.88s\tremaining: 3m 58s\n",
            "900:\tlearn: 1.0947255\ttest: 1.0967378\tbest: 1.0967378 (900)\ttotal: 4.41s\tremaining: 4m\n",
            "1000:\tlearn: 1.0939025\ttest: 1.0961108\tbest: 1.0961108 (1000)\ttotal: 4.99s\tremaining: 4m 4s\n",
            "1100:\tlearn: 1.0931095\ttest: 1.0955844\tbest: 1.0955844 (1100)\ttotal: 5.56s\tremaining: 4m 7s\n",
            "1200:\tlearn: 1.0925229\ttest: 1.0951672\tbest: 1.0951672 (1200)\ttotal: 6.11s\tremaining: 4m 8s\n",
            "1300:\tlearn: 1.0919088\ttest: 1.0947651\tbest: 1.0947651 (1300)\ttotal: 6.68s\tremaining: 4m 9s\n",
            "1400:\tlearn: 1.0913821\ttest: 1.0943640\tbest: 1.0943640 (1400)\ttotal: 7.25s\tremaining: 4m 11s\n",
            "1500:\tlearn: 1.0909139\ttest: 1.0940932\tbest: 1.0940932 (1499)\ttotal: 7.79s\tremaining: 4m 11s\n",
            "1600:\tlearn: 1.0904863\ttest: 1.0938857\tbest: 1.0938857 (1600)\ttotal: 8.34s\tremaining: 4m 12s\n",
            "1700:\tlearn: 1.0900972\ttest: 1.0936627\tbest: 1.0936627 (1700)\ttotal: 8.91s\tremaining: 4m 12s\n",
            "1800:\tlearn: 1.0897098\ttest: 1.0934753\tbest: 1.0934753 (1800)\ttotal: 9.46s\tremaining: 4m 13s\n",
            "1900:\tlearn: 1.0893427\ttest: 1.0932948\tbest: 1.0932948 (1900)\ttotal: 10s\tremaining: 4m 13s\n",
            "2000:\tlearn: 1.0890354\ttest: 1.0931404\tbest: 1.0931404 (2000)\ttotal: 10.6s\tremaining: 4m 13s\n",
            "2100:\tlearn: 1.0887145\ttest: 1.0930046\tbest: 1.0930043 (2098)\ttotal: 11.1s\tremaining: 4m 14s\n",
            "2200:\tlearn: 1.0884258\ttest: 1.0929073\tbest: 1.0929073 (2200)\ttotal: 11.7s\tremaining: 4m 14s\n",
            "2300:\tlearn: 1.0881618\ttest: 1.0927804\tbest: 1.0927804 (2300)\ttotal: 12.3s\tremaining: 4m 14s\n",
            "2400:\tlearn: 1.0878954\ttest: 1.0926863\tbest: 1.0926863 (2400)\ttotal: 12.9s\tremaining: 4m 15s\n",
            "2500:\tlearn: 1.0876555\ttest: 1.0925585\tbest: 1.0925585 (2500)\ttotal: 13.4s\tremaining: 4m 14s\n",
            "2600:\tlearn: 1.0874196\ttest: 1.0925063\tbest: 1.0925063 (2600)\ttotal: 14s\tremaining: 4m 14s\n",
            "2700:\tlearn: 1.0871998\ttest: 1.0924156\tbest: 1.0924156 (2700)\ttotal: 14.5s\tremaining: 4m 14s\n",
            "2800:\tlearn: 1.0869727\ttest: 1.0923228\tbest: 1.0923228 (2800)\ttotal: 15.1s\tremaining: 4m 14s\n",
            "2900:\tlearn: 1.0867631\ttest: 1.0922709\tbest: 1.0922709 (2900)\ttotal: 15.7s\tremaining: 4m 14s\n",
            "3000:\tlearn: 1.0865515\ttest: 1.0922002\tbest: 1.0922002 (3000)\ttotal: 16.2s\tremaining: 4m 14s\n",
            "3100:\tlearn: 1.0863509\ttest: 1.0921193\tbest: 1.0921193 (3100)\ttotal: 16.8s\tremaining: 4m 14s\n",
            "3200:\tlearn: 1.0861669\ttest: 1.0920377\tbest: 1.0920370 (3199)\ttotal: 17.4s\tremaining: 4m 14s\n",
            "3300:\tlearn: 1.0859964\ttest: 1.0919689\tbest: 1.0919664 (3296)\ttotal: 18s\tremaining: 4m 14s\n",
            "3400:\tlearn: 1.0858140\ttest: 1.0918969\tbest: 1.0918955 (3398)\ttotal: 18.5s\tremaining: 4m 13s\n",
            "3500:\tlearn: 1.0856301\ttest: 1.0918669\tbest: 1.0918661 (3467)\ttotal: 19.1s\tremaining: 4m 13s\n",
            "3600:\tlearn: 1.0854720\ttest: 1.0918297\tbest: 1.0918256 (3589)\ttotal: 19.6s\tremaining: 4m 13s\n",
            "3700:\tlearn: 1.0852998\ttest: 1.0917955\tbest: 1.0917928 (3690)\ttotal: 20.2s\tremaining: 4m 12s\n",
            "3800:\tlearn: 1.0851256\ttest: 1.0917647\tbest: 1.0917646 (3799)\ttotal: 20.8s\tremaining: 4m 12s\n",
            "3900:\tlearn: 1.0849593\ttest: 1.0917171\tbest: 1.0917157 (3898)\ttotal: 21.3s\tremaining: 4m 12s\n",
            "4000:\tlearn: 1.0848186\ttest: 1.0916641\tbest: 1.0916636 (3997)\ttotal: 21.9s\tremaining: 4m 11s\n",
            "4100:\tlearn: 1.0846864\ttest: 1.0916571\tbest: 1.0916562 (4099)\ttotal: 22.4s\tremaining: 4m 10s\n",
            "4200:\tlearn: 1.0845477\ttest: 1.0916351\tbest: 1.0916328 (4196)\ttotal: 23s\tremaining: 4m 10s\n",
            "4300:\tlearn: 1.0844113\ttest: 1.0916218\tbest: 1.0916207 (4295)\ttotal: 23.6s\tremaining: 4m 10s\n",
            "4400:\tlearn: 1.0842737\ttest: 1.0915585\tbest: 1.0915570 (4399)\ttotal: 24.1s\tremaining: 4m 9s\n",
            "4500:\tlearn: 1.0841572\ttest: 1.0915365\tbest: 1.0915242 (4466)\ttotal: 24.7s\tremaining: 4m 9s\n",
            "4600:\tlearn: 1.0840435\ttest: 1.0915271\tbest: 1.0915242 (4466)\ttotal: 25.3s\tremaining: 4m 9s\n",
            "4700:\tlearn: 1.0839146\ttest: 1.0915082\tbest: 1.0915031 (4691)\ttotal: 25.9s\tremaining: 4m 9s\n",
            "4800:\tlearn: 1.0837946\ttest: 1.0914875\tbest: 1.0914869 (4795)\ttotal: 26.4s\tremaining: 4m 8s\n",
            "4900:\tlearn: 1.0836778\ttest: 1.0914603\tbest: 1.0914593 (4892)\ttotal: 27s\tremaining: 4m 8s\n",
            "5000:\tlearn: 1.0835597\ttest: 1.0914479\tbest: 1.0914475 (4974)\ttotal: 27.6s\tremaining: 4m 8s\n",
            "5100:\tlearn: 1.0834348\ttest: 1.0914270\tbest: 1.0914182 (5039)\ttotal: 28.2s\tremaining: 4m 7s\n",
            "5200:\tlearn: 1.0833170\ttest: 1.0914149\tbest: 1.0914149 (5200)\ttotal: 28.7s\tremaining: 4m 7s\n",
            "5300:\tlearn: 1.0831994\ttest: 1.0913961\tbest: 1.0913961 (5300)\ttotal: 29.3s\tremaining: 4m 7s\n",
            "5400:\tlearn: 1.0830800\ttest: 1.0913831\tbest: 1.0913761 (5369)\ttotal: 29.9s\tremaining: 4m 6s\n",
            "5500:\tlearn: 1.0829843\ttest: 1.0913716\tbest: 1.0913651 (5478)\ttotal: 30.5s\tremaining: 4m 6s\n",
            "5600:\tlearn: 1.0828606\ttest: 1.0913586\tbest: 1.0913537 (5549)\ttotal: 31.1s\tremaining: 4m 6s\n",
            "5700:\tlearn: 1.0827602\ttest: 1.0913449\tbest: 1.0913443 (5696)\ttotal: 31.6s\tremaining: 4m 5s\n",
            "5800:\tlearn: 1.0826571\ttest: 1.0913226\tbest: 1.0913226 (5800)\ttotal: 32.2s\tremaining: 4m 5s\n",
            "5900:\tlearn: 1.0825536\ttest: 1.0913126\tbest: 1.0913066 (5870)\ttotal: 32.8s\tremaining: 4m 4s\n",
            "6000:\tlearn: 1.0824513\ttest: 1.0913155\tbest: 1.0913060 (5954)\ttotal: 33.3s\tremaining: 4m 4s\n",
            "6100:\tlearn: 1.0823460\ttest: 1.0913019\tbest: 1.0913015 (6079)\ttotal: 33.9s\tremaining: 4m 3s\n",
            "6200:\tlearn: 1.0822409\ttest: 1.0912919\tbest: 1.0912855 (6171)\ttotal: 34.5s\tremaining: 4m 3s\n",
            "6300:\tlearn: 1.0821346\ttest: 1.0912608\tbest: 1.0912608 (6300)\ttotal: 35.1s\tremaining: 4m 3s\n",
            "6400:\tlearn: 1.0820356\ttest: 1.0912487\tbest: 1.0912444 (6334)\ttotal: 35.7s\tremaining: 4m 2s\n",
            "6500:\tlearn: 1.0819510\ttest: 1.0912444\tbest: 1.0912438 (6498)\ttotal: 36.2s\tremaining: 4m 2s\n",
            "6600:\tlearn: 1.0818521\ttest: 1.0912286\tbest: 1.0912264 (6585)\ttotal: 36.8s\tremaining: 4m 1s\n",
            "6700:\tlearn: 1.0817600\ttest: 1.0912143\tbest: 1.0912123 (6685)\ttotal: 37.3s\tremaining: 4m 1s\n",
            "6800:\tlearn: 1.0816580\ttest: 1.0912004\tbest: 1.0912004 (6800)\ttotal: 37.9s\tremaining: 4m\n",
            "6900:\tlearn: 1.0815593\ttest: 1.0911828\tbest: 1.0911746 (6871)\ttotal: 38.5s\tremaining: 4m\n",
            "7000:\tlearn: 1.0814697\ttest: 1.0911717\tbest: 1.0911688 (6955)\ttotal: 39s\tremaining: 3m 59s\n",
            "7100:\tlearn: 1.0813771\ttest: 1.0911562\tbest: 1.0911556 (7094)\ttotal: 39.5s\tremaining: 3m 58s\n",
            "7200:\tlearn: 1.0812758\ttest: 1.0911584\tbest: 1.0911543 (7113)\ttotal: 40s\tremaining: 3m 57s\n",
            "7300:\tlearn: 1.0811866\ttest: 1.0911617\tbest: 1.0911543 (7113)\ttotal: 40.5s\tremaining: 3m 57s\n",
            "7400:\tlearn: 1.0810947\ttest: 1.0911547\tbest: 1.0911482 (7332)\ttotal: 41.1s\tremaining: 3m 56s\n",
            "7500:\tlearn: 1.0809980\ttest: 1.0911592\tbest: 1.0911482 (7332)\ttotal: 41.6s\tremaining: 3m 55s\n",
            "7600:\tlearn: 1.0809110\ttest: 1.0911566\tbest: 1.0911482 (7332)\ttotal: 42.1s\tremaining: 3m 54s\n",
            "7700:\tlearn: 1.0808235\ttest: 1.0911488\tbest: 1.0911379 (7662)\ttotal: 42.7s\tremaining: 3m 54s\n",
            "7800:\tlearn: 1.0807455\ttest: 1.0911456\tbest: 1.0911379 (7662)\ttotal: 43.2s\tremaining: 3m 53s\n",
            "7900:\tlearn: 1.0806572\ttest: 1.0911397\tbest: 1.0911379 (7662)\ttotal: 43.7s\tremaining: 3m 53s\n",
            "8000:\tlearn: 1.0805677\ttest: 1.0911429\tbest: 1.0911379 (7662)\ttotal: 44.3s\tremaining: 3m 52s\n",
            "8100:\tlearn: 1.0804865\ttest: 1.0911458\tbest: 1.0911379 (7662)\ttotal: 44.8s\tremaining: 3m 51s\n",
            "8200:\tlearn: 1.0804060\ttest: 1.0911513\tbest: 1.0911379 (7662)\ttotal: 45.4s\tremaining: 3m 51s\n",
            "8300:\tlearn: 1.0803222\ttest: 1.0911299\tbest: 1.0911295 (8299)\ttotal: 45.9s\tremaining: 3m 50s\n",
            "8400:\tlearn: 1.0802436\ttest: 1.0911388\tbest: 1.0911244 (8346)\ttotal: 46.5s\tremaining: 3m 50s\n",
            "8500:\tlearn: 1.0801536\ttest: 1.0911262\tbest: 1.0911207 (8467)\ttotal: 47s\tremaining: 3m 49s\n",
            "8600:\tlearn: 1.0800749\ttest: 1.0911257\tbest: 1.0911207 (8467)\ttotal: 47.6s\tremaining: 3m 49s\n",
            "8700:\tlearn: 1.0799941\ttest: 1.0911212\tbest: 1.0911201 (8694)\ttotal: 48.1s\tremaining: 3m 48s\n",
            "8800:\tlearn: 1.0799198\ttest: 1.0911300\tbest: 1.0911201 (8694)\ttotal: 48.7s\tremaining: 3m 47s\n",
            "8900:\tlearn: 1.0798328\ttest: 1.0911211\tbest: 1.0911169 (8877)\ttotal: 49.2s\tremaining: 3m 47s\n",
            "9000:\tlearn: 1.0797446\ttest: 1.0911237\tbest: 1.0911169 (8877)\ttotal: 49.8s\tremaining: 3m 46s\n",
            "9100:\tlearn: 1.0796454\ttest: 1.0911109\tbest: 1.0911079 (9096)\ttotal: 50.4s\tremaining: 3m 46s\n",
            "9200:\tlearn: 1.0795695\ttest: 1.0911018\tbest: 1.0910985 (9184)\ttotal: 50.9s\tremaining: 3m 45s\n",
            "9300:\tlearn: 1.0794882\ttest: 1.0911038\tbest: 1.0910985 (9184)\ttotal: 51.4s\tremaining: 3m 45s\n",
            "9400:\tlearn: 1.0794208\ttest: 1.0910906\tbest: 1.0910896 (9396)\ttotal: 52s\tremaining: 3m 44s\n",
            "9500:\tlearn: 1.0793349\ttest: 1.0910886\tbest: 1.0910839 (9490)\ttotal: 52.5s\tremaining: 3m 43s\n",
            "9600:\tlearn: 1.0792523\ttest: 1.0910626\tbest: 1.0910601 (9597)\ttotal: 53.1s\tremaining: 3m 43s\n",
            "9700:\tlearn: 1.0791753\ttest: 1.0910660\tbest: 1.0910601 (9597)\ttotal: 53.6s\tremaining: 3m 42s\n",
            "9800:\tlearn: 1.0791043\ttest: 1.0910587\tbest: 1.0910587 (9800)\ttotal: 54.1s\tremaining: 3m 42s\n",
            "9900:\tlearn: 1.0790317\ttest: 1.0910522\tbest: 1.0910517 (9899)\ttotal: 54.7s\tremaining: 3m 41s\n",
            "10000:\tlearn: 1.0789527\ttest: 1.0910488\tbest: 1.0910434 (9985)\ttotal: 55.2s\tremaining: 3m 40s\n",
            "10100:\tlearn: 1.0788758\ttest: 1.0910384\tbest: 1.0910384 (10100)\ttotal: 55.8s\tremaining: 3m 40s\n",
            "10200:\tlearn: 1.0787981\ttest: 1.0910187\tbest: 1.0910165 (10199)\ttotal: 56.3s\tremaining: 3m 39s\n",
            "10300:\tlearn: 1.0787200\ttest: 1.0910203\tbest: 1.0910165 (10199)\ttotal: 56.9s\tremaining: 3m 39s\n",
            "10400:\tlearn: 1.0786425\ttest: 1.0910187\tbest: 1.0910134 (10327)\ttotal: 57.4s\tremaining: 3m 38s\n",
            "10500:\tlearn: 1.0785693\ttest: 1.0910136\tbest: 1.0910126 (10495)\ttotal: 58s\tremaining: 3m 38s\n",
            "10600:\tlearn: 1.0784946\ttest: 1.0910264\tbest: 1.0910126 (10495)\ttotal: 58.5s\tremaining: 3m 37s\n",
            "10700:\tlearn: 1.0784188\ttest: 1.0910326\tbest: 1.0910126 (10495)\ttotal: 59.1s\tremaining: 3m 36s\n",
            "10800:\tlearn: 1.0783471\ttest: 1.0910286\tbest: 1.0910126 (10495)\ttotal: 59.6s\tremaining: 3m 36s\n",
            "10900:\tlearn: 1.0782767\ttest: 1.0910222\tbest: 1.0910126 (10495)\ttotal: 1m\tremaining: 3m 35s\n",
            "11000:\tlearn: 1.0782079\ttest: 1.0910255\tbest: 1.0910126 (10495)\ttotal: 1m\tremaining: 3m 35s\n",
            "11100:\tlearn: 1.0781387\ttest: 1.0910219\tbest: 1.0910126 (10495)\ttotal: 1m 1s\tremaining: 3m 34s\n",
            "11200:\tlearn: 1.0780617\ttest: 1.0910168\tbest: 1.0910126 (10495)\ttotal: 1m 1s\tremaining: 3m 34s\n",
            "11300:\tlearn: 1.0779941\ttest: 1.0910111\tbest: 1.0910083 (11284)\ttotal: 1m 2s\tremaining: 3m 33s\n",
            "11400:\tlearn: 1.0779240\ttest: 1.0910158\tbest: 1.0910083 (11284)\ttotal: 1m 2s\tremaining: 3m 32s\n",
            "11500:\tlearn: 1.0778467\ttest: 1.0910123\tbest: 1.0910046 (11442)\ttotal: 1m 3s\tremaining: 3m 32s\n",
            "11600:\tlearn: 1.0777786\ttest: 1.0910149\tbest: 1.0910046 (11442)\ttotal: 1m 3s\tremaining: 3m 31s\n",
            "11700:\tlearn: 1.0777130\ttest: 1.0910170\tbest: 1.0910046 (11442)\ttotal: 1m 4s\tremaining: 3m 31s\n",
            "11800:\tlearn: 1.0776524\ttest: 1.0910219\tbest: 1.0910046 (11442)\ttotal: 1m 5s\tremaining: 3m 30s\n",
            "11900:\tlearn: 1.0775836\ttest: 1.0910115\tbest: 1.0910046 (11442)\ttotal: 1m 5s\tremaining: 3m 29s\n",
            "12000:\tlearn: 1.0775174\ttest: 1.0910141\tbest: 1.0910021 (11945)\ttotal: 1m 6s\tremaining: 3m 29s\n",
            "12100:\tlearn: 1.0774453\ttest: 1.0910235\tbest: 1.0910021 (11945)\ttotal: 1m 6s\tremaining: 3m 28s\n",
            "12200:\tlearn: 1.0773775\ttest: 1.0910319\tbest: 1.0910021 (11945)\ttotal: 1m 7s\tremaining: 3m 27s\n",
            "12300:\tlearn: 1.0773079\ttest: 1.0910294\tbest: 1.0910021 (11945)\ttotal: 1m 7s\tremaining: 3m 27s\n",
            "12400:\tlearn: 1.0772336\ttest: 1.0910375\tbest: 1.0910021 (11945)\ttotal: 1m 8s\tremaining: 3m 26s\n",
            "12500:\tlearn: 1.0771671\ttest: 1.0910302\tbest: 1.0910021 (11945)\ttotal: 1m 8s\tremaining: 3m 26s\n",
            "12600:\tlearn: 1.0770981\ttest: 1.0910262\tbest: 1.0910021 (11945)\ttotal: 1m 9s\tremaining: 3m 25s\n",
            "12700:\tlearn: 1.0770339\ttest: 1.0910245\tbest: 1.0910021 (11945)\ttotal: 1m 9s\tremaining: 3m 25s\n",
            "12800:\tlearn: 1.0769775\ttest: 1.0910155\tbest: 1.0910021 (11945)\ttotal: 1m 10s\tremaining: 3m 24s\n",
            "12900:\tlearn: 1.0769101\ttest: 1.0910299\tbest: 1.0910021 (11945)\ttotal: 1m 10s\tremaining: 3m 23s\n",
            "bestTest = 1.091002148\n",
            "bestIteration = 11945\n",
            "Shrink model to first 11946 iterations.\n",
            "0:\tlearn: 1.3669112\ttest: 1.3668498\tbest: 1.3668498 (0)\ttotal: 6.08ms\tremaining: 5m 4s\n",
            "100:\tlearn: 1.1118408\ttest: 1.1121315\tbest: 1.1121315 (100)\ttotal: 479ms\tremaining: 3m 56s\n",
            "200:\tlearn: 1.1069515\ttest: 1.1076071\tbest: 1.1076071 (200)\ttotal: 931ms\tremaining: 3m 50s\n",
            "300:\tlearn: 1.1036771\ttest: 1.1047265\tbest: 1.1047265 (300)\ttotal: 1.44s\tremaining: 3m 58s\n",
            "400:\tlearn: 1.1012559\ttest: 1.1025454\tbest: 1.1025454 (400)\ttotal: 1.92s\tremaining: 3m 57s\n",
            "500:\tlearn: 1.0993080\ttest: 1.1007947\tbest: 1.1007947 (500)\ttotal: 2.43s\tremaining: 3m 59s\n",
            "600:\tlearn: 1.0976996\ttest: 1.0995088\tbest: 1.0995088 (600)\ttotal: 2.93s\tremaining: 4m\n",
            "700:\tlearn: 1.0963981\ttest: 1.0983776\tbest: 1.0983776 (700)\ttotal: 3.43s\tremaining: 4m 1s\n",
            "800:\tlearn: 1.0952771\ttest: 1.0975414\tbest: 1.0975414 (800)\ttotal: 3.92s\tremaining: 4m\n",
            "900:\tlearn: 1.0942751\ttest: 1.0967717\tbest: 1.0967717 (900)\ttotal: 4.42s\tremaining: 4m 1s\n",
            "1000:\tlearn: 1.0934181\ttest: 1.0962166\tbest: 1.0962166 (1000)\ttotal: 4.93s\tremaining: 4m 1s\n",
            "1100:\tlearn: 1.0927107\ttest: 1.0956800\tbest: 1.0956800 (1100)\ttotal: 5.46s\tremaining: 4m 2s\n",
            "1200:\tlearn: 1.0920721\ttest: 1.0952319\tbest: 1.0952319 (1200)\ttotal: 5.97s\tremaining: 4m 2s\n",
            "1300:\tlearn: 1.0914938\ttest: 1.0948981\tbest: 1.0948981 (1300)\ttotal: 6.48s\tremaining: 4m 2s\n",
            "1400:\tlearn: 1.0909528\ttest: 1.0945559\tbest: 1.0945559 (1400)\ttotal: 7s\tremaining: 4m 3s\n",
            "1500:\tlearn: 1.0904508\ttest: 1.0942282\tbest: 1.0942282 (1500)\ttotal: 7.55s\tremaining: 4m 4s\n",
            "1600:\tlearn: 1.0900188\ttest: 1.0939625\tbest: 1.0939625 (1600)\ttotal: 8.09s\tremaining: 4m 4s\n",
            "1700:\tlearn: 1.0895954\ttest: 1.0937491\tbest: 1.0937491 (1700)\ttotal: 8.63s\tremaining: 4m 4s\n",
            "1800:\tlearn: 1.0892432\ttest: 1.0935803\tbest: 1.0935803 (1800)\ttotal: 9.14s\tremaining: 4m 4s\n",
            "1900:\tlearn: 1.0888860\ttest: 1.0933731\tbest: 1.0933716 (1899)\ttotal: 9.69s\tremaining: 4m 5s\n",
            "2000:\tlearn: 1.0885627\ttest: 1.0932232\tbest: 1.0932211 (1999)\ttotal: 10.2s\tremaining: 4m 5s\n",
            "2100:\tlearn: 1.0882493\ttest: 1.0930548\tbest: 1.0930548 (2100)\ttotal: 10.8s\tremaining: 4m 5s\n",
            "2200:\tlearn: 1.0879662\ttest: 1.0929196\tbest: 1.0929196 (2200)\ttotal: 11.3s\tremaining: 4m 4s\n",
            "2300:\tlearn: 1.0876947\ttest: 1.0928247\tbest: 1.0928247 (2300)\ttotal: 11.8s\tremaining: 4m 4s\n",
            "2400:\tlearn: 1.0874321\ttest: 1.0927184\tbest: 1.0927175 (2399)\ttotal: 12.3s\tremaining: 4m 4s\n",
            "2500:\tlearn: 1.0872080\ttest: 1.0926335\tbest: 1.0926335 (2500)\ttotal: 12.9s\tremaining: 4m 4s\n",
            "2600:\tlearn: 1.0869619\ttest: 1.0925463\tbest: 1.0925463 (2600)\ttotal: 13.4s\tremaining: 4m 4s\n",
            "2700:\tlearn: 1.0867265\ttest: 1.0924564\tbest: 1.0924564 (2700)\ttotal: 13.9s\tremaining: 4m 3s\n",
            "2800:\tlearn: 1.0864968\ttest: 1.0923486\tbest: 1.0923482 (2799)\ttotal: 14.5s\tremaining: 4m 3s\n",
            "2900:\tlearn: 1.0862978\ttest: 1.0922699\tbest: 1.0922699 (2900)\ttotal: 15s\tremaining: 4m 3s\n",
            "3000:\tlearn: 1.0860708\ttest: 1.0921935\tbest: 1.0921929 (2999)\ttotal: 15.5s\tremaining: 4m 3s\n",
            "3100:\tlearn: 1.0858843\ttest: 1.0921321\tbest: 1.0921321 (3099)\ttotal: 16.1s\tremaining: 4m 2s\n",
            "3200:\tlearn: 1.0856874\ttest: 1.0920644\tbest: 1.0920644 (3200)\ttotal: 16.6s\tremaining: 4m 2s\n",
            "3300:\tlearn: 1.0855182\ttest: 1.0920256\tbest: 1.0920256 (3300)\ttotal: 17.1s\tremaining: 4m 2s\n",
            "3400:\tlearn: 1.0853530\ttest: 1.0919521\tbest: 1.0919521 (3399)\ttotal: 17.7s\tremaining: 4m 2s\n",
            "3500:\tlearn: 1.0851688\ttest: 1.0919033\tbest: 1.0918949 (3491)\ttotal: 18.2s\tremaining: 4m 2s\n",
            "3600:\tlearn: 1.0850036\ttest: 1.0918584\tbest: 1.0918574 (3599)\ttotal: 18.8s\tremaining: 4m 1s\n",
            "3700:\tlearn: 1.0848433\ttest: 1.0918072\tbest: 1.0918051 (3698)\ttotal: 19.3s\tremaining: 4m 1s\n",
            "3800:\tlearn: 1.0846822\ttest: 1.0917851\tbest: 1.0917845 (3787)\ttotal: 19.8s\tremaining: 4m 1s\n",
            "3900:\tlearn: 1.0845324\ttest: 1.0917687\tbest: 1.0917618 (3877)\ttotal: 20.4s\tremaining: 4m\n",
            "4000:\tlearn: 1.0843919\ttest: 1.0917410\tbest: 1.0917410 (4000)\ttotal: 20.9s\tremaining: 4m\n",
            "4100:\tlearn: 1.0842397\ttest: 1.0917191\tbest: 1.0917167 (4080)\ttotal: 21.5s\tremaining: 4m\n",
            "4200:\tlearn: 1.0840853\ttest: 1.0916812\tbest: 1.0916812 (4200)\ttotal: 22s\tremaining: 3m 59s\n",
            "4300:\tlearn: 1.0839573\ttest: 1.0916645\tbest: 1.0916639 (4299)\ttotal: 22.5s\tremaining: 3m 59s\n",
            "4400:\tlearn: 1.0838313\ttest: 1.0916442\tbest: 1.0916424 (4389)\ttotal: 23.1s\tremaining: 3m 59s\n",
            "4500:\tlearn: 1.0837055\ttest: 1.0916364\tbest: 1.0916290 (4481)\ttotal: 23.6s\tremaining: 3m 58s\n",
            "4600:\tlearn: 1.0835767\ttest: 1.0916366\tbest: 1.0916290 (4481)\ttotal: 24.2s\tremaining: 3m 58s\n",
            "4700:\tlearn: 1.0834590\ttest: 1.0916283\tbest: 1.0916189 (4693)\ttotal: 24.7s\tremaining: 3m 58s\n",
            "4800:\tlearn: 1.0833378\ttest: 1.0916149\tbest: 1.0916086 (4739)\ttotal: 25.3s\tremaining: 3m 57s\n",
            "4900:\tlearn: 1.0832111\ttest: 1.0916159\tbest: 1.0916036 (4880)\ttotal: 25.8s\tremaining: 3m 57s\n",
            "5000:\tlearn: 1.0830832\ttest: 1.0915683\tbest: 1.0915683 (5000)\ttotal: 26.4s\tremaining: 3m 57s\n",
            "5100:\tlearn: 1.0829731\ttest: 1.0915680\tbest: 1.0915562 (5072)\ttotal: 26.9s\tremaining: 3m 56s\n",
            "5200:\tlearn: 1.0828515\ttest: 1.0915518\tbest: 1.0915504 (5199)\ttotal: 27.4s\tremaining: 3m 56s\n",
            "5300:\tlearn: 1.0827397\ttest: 1.0915238\tbest: 1.0915179 (5282)\ttotal: 28s\tremaining: 3m 55s\n",
            "5400:\tlearn: 1.0826195\ttest: 1.0915067\tbest: 1.0915061 (5398)\ttotal: 28.5s\tremaining: 3m 55s\n",
            "5500:\tlearn: 1.0825011\ttest: 1.0915100\tbest: 1.0915001 (5443)\ttotal: 29s\tremaining: 3m 54s\n",
            "5600:\tlearn: 1.0823941\ttest: 1.0914977\tbest: 1.0914915 (5593)\ttotal: 29.6s\tremaining: 3m 54s\n",
            "5700:\tlearn: 1.0822915\ttest: 1.0914762\tbest: 1.0914741 (5690)\ttotal: 30.1s\tremaining: 3m 53s\n",
            "5800:\tlearn: 1.0821751\ttest: 1.0914664\tbest: 1.0914664 (5800)\ttotal: 30.6s\tremaining: 3m 53s\n",
            "5900:\tlearn: 1.0820707\ttest: 1.0914580\tbest: 1.0914528 (5885)\ttotal: 31.2s\tremaining: 3m 52s\n",
            "6000:\tlearn: 1.0819519\ttest: 1.0914462\tbest: 1.0914438 (5988)\ttotal: 31.7s\tremaining: 3m 52s\n",
            "6100:\tlearn: 1.0818562\ttest: 1.0914499\tbest: 1.0914431 (6088)\ttotal: 32.3s\tremaining: 3m 52s\n",
            "6200:\tlearn: 1.0817495\ttest: 1.0914399\tbest: 1.0914394 (6113)\ttotal: 32.8s\tremaining: 3m 51s\n",
            "6300:\tlearn: 1.0816420\ttest: 1.0914385\tbest: 1.0914313 (6262)\ttotal: 33.3s\tremaining: 3m 51s\n",
            "6400:\tlearn: 1.0815472\ttest: 1.0914206\tbest: 1.0914177 (6370)\ttotal: 33.9s\tremaining: 3m 50s\n",
            "6500:\tlearn: 1.0814417\ttest: 1.0914107\tbest: 1.0914081 (6492)\ttotal: 34.4s\tremaining: 3m 50s\n",
            "6600:\tlearn: 1.0813475\ttest: 1.0914027\tbest: 1.0914027 (6600)\ttotal: 34.9s\tremaining: 3m 49s\n",
            "6700:\tlearn: 1.0812522\ttest: 1.0914175\tbest: 1.0914018 (6602)\ttotal: 35.5s\tremaining: 3m 49s\n",
            "6800:\tlearn: 1.0811533\ttest: 1.0914221\tbest: 1.0914018 (6602)\ttotal: 36s\tremaining: 3m 48s\n",
            "6900:\tlearn: 1.0810491\ttest: 1.0914179\tbest: 1.0914018 (6602)\ttotal: 36.5s\tremaining: 3m 48s\n",
            "7000:\tlearn: 1.0809653\ttest: 1.0913900\tbest: 1.0913900 (6987)\ttotal: 37.1s\tremaining: 3m 47s\n",
            "7100:\tlearn: 1.0808717\ttest: 1.0913873\tbest: 1.0913796 (7071)\ttotal: 37.6s\tremaining: 3m 47s\n",
            "7200:\tlearn: 1.0807773\ttest: 1.0913850\tbest: 1.0913796 (7071)\ttotal: 38.1s\tremaining: 3m 46s\n",
            "7300:\tlearn: 1.0806805\ttest: 1.0913861\tbest: 1.0913738 (7232)\ttotal: 38.7s\tremaining: 3m 46s\n",
            "7400:\tlearn: 1.0805834\ttest: 1.0913782\tbest: 1.0913738 (7232)\ttotal: 39.2s\tremaining: 3m 45s\n",
            "7500:\tlearn: 1.0804947\ttest: 1.0913681\tbest: 1.0913607 (7487)\ttotal: 39.7s\tremaining: 3m 45s\n",
            "7600:\tlearn: 1.0804122\ttest: 1.0913683\tbest: 1.0913551 (7554)\ttotal: 40.2s\tremaining: 3m 44s\n",
            "7700:\tlearn: 1.0803274\ttest: 1.0913606\tbest: 1.0913551 (7554)\ttotal: 40.8s\tremaining: 3m 43s\n",
            "7800:\tlearn: 1.0802389\ttest: 1.0913677\tbest: 1.0913551 (7554)\ttotal: 41.3s\tremaining: 3m 43s\n",
            "7900:\tlearn: 1.0801437\ttest: 1.0913679\tbest: 1.0913551 (7554)\ttotal: 41.8s\tremaining: 3m 42s\n",
            "8000:\tlearn: 1.0800533\ttest: 1.0913615\tbest: 1.0913551 (7554)\ttotal: 42.4s\tremaining: 3m 42s\n",
            "8100:\tlearn: 1.0799732\ttest: 1.0913664\tbest: 1.0913551 (7554)\ttotal: 42.9s\tremaining: 3m 41s\n",
            "8200:\tlearn: 1.0798858\ttest: 1.0913762\tbest: 1.0913551 (7554)\ttotal: 43.4s\tremaining: 3m 41s\n",
            "8300:\tlearn: 1.0797995\ttest: 1.0913787\tbest: 1.0913551 (7554)\ttotal: 44s\tremaining: 3m 40s\n",
            "8400:\tlearn: 1.0797131\ttest: 1.0913711\tbest: 1.0913551 (7554)\ttotal: 44.5s\tremaining: 3m 40s\n",
            "8500:\tlearn: 1.0796284\ttest: 1.0913635\tbest: 1.0913551 (7554)\ttotal: 45.1s\tremaining: 3m 40s\n",
            "bestTest = 1.091355078\n",
            "bestIteration = 7554\n",
            "Shrink model to first 7555 iterations.\n",
            "0:\tlearn: 1.3669121\ttest: 1.3668538\tbest: 1.3668538 (0)\ttotal: 5.82ms\tremaining: 4m 51s\n",
            "100:\tlearn: 1.1116191\ttest: 1.1121194\tbest: 1.1121194 (100)\ttotal: 456ms\tremaining: 3m 45s\n",
            "200:\tlearn: 1.1066721\ttest: 1.1075023\tbest: 1.1075023 (200)\ttotal: 922ms\tremaining: 3m 48s\n",
            "300:\tlearn: 1.1035048\ttest: 1.1044891\tbest: 1.1044891 (300)\ttotal: 1.41s\tremaining: 3m 52s\n",
            "400:\tlearn: 1.1009261\ttest: 1.1022851\tbest: 1.1022851 (400)\ttotal: 1.96s\tremaining: 4m 2s\n",
            "500:\tlearn: 1.0989405\ttest: 1.1005684\tbest: 1.1005684 (500)\ttotal: 2.48s\tremaining: 4m 4s\n",
            "600:\tlearn: 1.0973114\ttest: 1.0991251\tbest: 1.0991251 (600)\ttotal: 2.99s\tremaining: 4m 5s\n",
            "700:\tlearn: 1.0959548\ttest: 1.0979068\tbest: 1.0979068 (700)\ttotal: 3.5s\tremaining: 4m 6s\n",
            "800:\tlearn: 1.0948668\ttest: 1.0970308\tbest: 1.0970308 (800)\ttotal: 4.01s\tremaining: 4m 6s\n",
            "900:\tlearn: 1.0938484\ttest: 1.0962954\tbest: 1.0962954 (900)\ttotal: 4.5s\tremaining: 4m 5s\n",
            "1000:\tlearn: 1.0930712\ttest: 1.0957126\tbest: 1.0957126 (1000)\ttotal: 4.98s\tremaining: 4m 3s\n",
            "1100:\tlearn: 1.0923846\ttest: 1.0951845\tbest: 1.0951845 (1100)\ttotal: 5.49s\tremaining: 4m 4s\n",
            "1200:\tlearn: 1.0917413\ttest: 1.0947697\tbest: 1.0947694 (1199)\ttotal: 5.98s\tremaining: 4m 3s\n",
            "1300:\tlearn: 1.0911430\ttest: 1.0944097\tbest: 1.0944097 (1300)\ttotal: 6.49s\tremaining: 4m 2s\n",
            "1400:\tlearn: 1.0906688\ttest: 1.0941598\tbest: 1.0941598 (1400)\ttotal: 6.97s\tremaining: 4m 1s\n",
            "1500:\tlearn: 1.0902545\ttest: 1.0939072\tbest: 1.0939063 (1497)\ttotal: 7.48s\tremaining: 4m 1s\n",
            "1600:\tlearn: 1.0898253\ttest: 1.0936604\tbest: 1.0936604 (1600)\ttotal: 7.98s\tremaining: 4m 1s\n",
            "1700:\tlearn: 1.0894132\ttest: 1.0934501\tbest: 1.0934443 (1696)\ttotal: 8.48s\tremaining: 4m\n",
            "1800:\tlearn: 1.0890516\ttest: 1.0932843\tbest: 1.0932843 (1800)\ttotal: 8.98s\tremaining: 4m\n",
            "1900:\tlearn: 1.0887066\ttest: 1.0931298\tbest: 1.0931298 (1900)\ttotal: 9.48s\tremaining: 3m 59s\n",
            "2000:\tlearn: 1.0884052\ttest: 1.0930009\tbest: 1.0929930 (1994)\ttotal: 9.98s\tremaining: 3m 59s\n",
            "2100:\tlearn: 1.0881072\ttest: 1.0928668\tbest: 1.0928668 (2100)\ttotal: 10.5s\tremaining: 3m 59s\n",
            "2200:\tlearn: 1.0878188\ttest: 1.0927657\tbest: 1.0927652 (2199)\ttotal: 11s\tremaining: 3m 59s\n",
            "2300:\tlearn: 1.0875510\ttest: 1.0926268\tbest: 1.0926268 (2298)\ttotal: 11.5s\tremaining: 3m 59s\n",
            "2400:\tlearn: 1.0872864\ttest: 1.0925300\tbest: 1.0925300 (2400)\ttotal: 12s\tremaining: 3m 58s\n",
            "2500:\tlearn: 1.0870456\ttest: 1.0924170\tbest: 1.0924170 (2500)\ttotal: 12.5s\tremaining: 3m 57s\n",
            "2600:\tlearn: 1.0868100\ttest: 1.0923332\tbest: 1.0923332 (2600)\ttotal: 13s\tremaining: 3m 57s\n",
            "2700:\tlearn: 1.0865946\ttest: 1.0922482\tbest: 1.0922475 (2699)\ttotal: 13.5s\tremaining: 3m 56s\n",
            "2800:\tlearn: 1.0863805\ttest: 1.0921938\tbest: 1.0921909 (2790)\ttotal: 14s\tremaining: 3m 56s\n",
            "2900:\tlearn: 1.0861803\ttest: 1.0921219\tbest: 1.0921207 (2898)\ttotal: 14.6s\tremaining: 3m 56s\n",
            "3000:\tlearn: 1.0860014\ttest: 1.0920524\tbest: 1.0920524 (3000)\ttotal: 15.1s\tremaining: 3m 56s\n",
            "3100:\tlearn: 1.0858076\ttest: 1.0920063\tbest: 1.0920063 (3100)\ttotal: 15.6s\tremaining: 3m 56s\n",
            "3200:\tlearn: 1.0856244\ttest: 1.0919582\tbest: 1.0919579 (3193)\ttotal: 16.1s\tremaining: 3m 55s\n",
            "3300:\tlearn: 1.0854383\ttest: 1.0919131\tbest: 1.0919121 (3299)\ttotal: 16.6s\tremaining: 3m 55s\n",
            "3400:\tlearn: 1.0852635\ttest: 1.0918597\tbest: 1.0918588 (3399)\ttotal: 17.2s\tremaining: 3m 55s\n",
            "3500:\tlearn: 1.0850921\ttest: 1.0918534\tbest: 1.0918534 (3500)\ttotal: 17.6s\tremaining: 3m 54s\n",
            "3600:\tlearn: 1.0849350\ttest: 1.0918473\tbest: 1.0918390 (3568)\ttotal: 18.2s\tremaining: 3m 53s\n",
            "3700:\tlearn: 1.0847670\ttest: 1.0918133\tbest: 1.0918124 (3697)\ttotal: 18.7s\tremaining: 3m 53s\n",
            "3800:\tlearn: 1.0846155\ttest: 1.0917798\tbest: 1.0917785 (3798)\ttotal: 19.2s\tremaining: 3m 53s\n",
            "3900:\tlearn: 1.0844619\ttest: 1.0917451\tbest: 1.0917432 (3884)\ttotal: 19.7s\tremaining: 3m 52s\n",
            "4000:\tlearn: 1.0843257\ttest: 1.0917212\tbest: 1.0917198 (3994)\ttotal: 20.2s\tremaining: 3m 52s\n",
            "4100:\tlearn: 1.0841843\ttest: 1.0916966\tbest: 1.0916951 (4095)\ttotal: 20.8s\tremaining: 3m 52s\n",
            "4200:\tlearn: 1.0840422\ttest: 1.0916650\tbest: 1.0916617 (4192)\ttotal: 21.3s\tremaining: 3m 52s\n",
            "4300:\tlearn: 1.0839029\ttest: 1.0916653\tbest: 1.0916572 (4263)\ttotal: 21.8s\tremaining: 3m 51s\n",
            "4400:\tlearn: 1.0837576\ttest: 1.0916279\tbest: 1.0916269 (4398)\ttotal: 22.3s\tremaining: 3m 51s\n",
            "4500:\tlearn: 1.0836124\ttest: 1.0915992\tbest: 1.0915992 (4500)\ttotal: 22.9s\tremaining: 3m 51s\n",
            "4600:\tlearn: 1.0834776\ttest: 1.0915743\tbest: 1.0915705 (4595)\ttotal: 23.4s\tremaining: 3m 51s\n",
            "4700:\tlearn: 1.0833519\ttest: 1.0915406\tbest: 1.0915406 (4700)\ttotal: 24s\tremaining: 3m 50s\n",
            "4800:\tlearn: 1.0832238\ttest: 1.0915058\tbest: 1.0915043 (4794)\ttotal: 24.5s\tremaining: 3m 50s\n",
            "4900:\tlearn: 1.0831122\ttest: 1.0914852\tbest: 1.0914814 (4892)\ttotal: 24.9s\tremaining: 3m 49s\n",
            "5000:\tlearn: 1.0829977\ttest: 1.0914566\tbest: 1.0914560 (4998)\ttotal: 25.5s\tremaining: 3m 49s\n",
            "5100:\tlearn: 1.0828837\ttest: 1.0914296\tbest: 1.0914282 (5087)\ttotal: 26s\tremaining: 3m 48s\n",
            "5200:\tlearn: 1.0827655\ttest: 1.0913992\tbest: 1.0913992 (5200)\ttotal: 26.5s\tremaining: 3m 48s\n",
            "5300:\tlearn: 1.0826470\ttest: 1.0913779\tbest: 1.0913764 (5284)\ttotal: 27s\tremaining: 3m 47s\n",
            "5400:\tlearn: 1.0825374\ttest: 1.0913859\tbest: 1.0913682 (5312)\ttotal: 27.5s\tremaining: 3m 46s\n",
            "5500:\tlearn: 1.0824167\ttest: 1.0914072\tbest: 1.0913682 (5312)\ttotal: 27.9s\tremaining: 3m 45s\n",
            "5600:\tlearn: 1.0823021\ttest: 1.0913985\tbest: 1.0913682 (5312)\ttotal: 28.4s\tremaining: 3m 45s\n",
            "5700:\tlearn: 1.0821940\ttest: 1.0913894\tbest: 1.0913682 (5312)\ttotal: 28.9s\tremaining: 3m 44s\n",
            "5800:\tlearn: 1.0820830\ttest: 1.0913741\tbest: 1.0913682 (5312)\ttotal: 29.4s\tremaining: 3m 43s\n",
            "5900:\tlearn: 1.0819693\ttest: 1.0913497\tbest: 1.0913497 (5900)\ttotal: 29.9s\tremaining: 3m 43s\n",
            "6000:\tlearn: 1.0818679\ttest: 1.0913430\tbest: 1.0913425 (5997)\ttotal: 30.4s\tremaining: 3m 42s\n",
            "6100:\tlearn: 1.0817720\ttest: 1.0913244\tbest: 1.0913226 (6092)\ttotal: 30.9s\tremaining: 3m 42s\n",
            "6200:\tlearn: 1.0816744\ttest: 1.0913362\tbest: 1.0913226 (6092)\ttotal: 31.4s\tremaining: 3m 41s\n",
            "6300:\tlearn: 1.0815781\ttest: 1.0913319\tbest: 1.0913226 (6092)\ttotal: 31.9s\tremaining: 3m 40s\n",
            "6400:\tlearn: 1.0814782\ttest: 1.0913491\tbest: 1.0913226 (6092)\ttotal: 32.4s\tremaining: 3m 40s\n",
            "6500:\tlearn: 1.0813818\ttest: 1.0913410\tbest: 1.0913226 (6092)\ttotal: 32.8s\tremaining: 3m 39s\n",
            "6600:\tlearn: 1.0812789\ttest: 1.0913283\tbest: 1.0913226 (6092)\ttotal: 33.3s\tremaining: 3m 39s\n",
            "6700:\tlearn: 1.0811778\ttest: 1.0913394\tbest: 1.0913226 (6092)\ttotal: 33.8s\tremaining: 3m 38s\n",
            "6800:\tlearn: 1.0810684\ttest: 1.0913364\tbest: 1.0913226 (6092)\ttotal: 34.3s\tremaining: 3m 38s\n",
            "6900:\tlearn: 1.0809753\ttest: 1.0913232\tbest: 1.0913226 (6092)\ttotal: 34.8s\tremaining: 3m 37s\n",
            "7000:\tlearn: 1.0808727\ttest: 1.0913121\tbest: 1.0913088 (6991)\ttotal: 35.3s\tremaining: 3m 36s\n",
            "7100:\tlearn: 1.0807689\ttest: 1.0913081\tbest: 1.0913074 (7091)\ttotal: 35.8s\tremaining: 3m 36s\n",
            "7200:\tlearn: 1.0806733\ttest: 1.0913048\tbest: 1.0913030 (7191)\ttotal: 36.3s\tremaining: 3m 35s\n",
            "7300:\tlearn: 1.0805768\ttest: 1.0912902\tbest: 1.0912871 (7295)\ttotal: 36.8s\tremaining: 3m 35s\n",
            "7400:\tlearn: 1.0804817\ttest: 1.0913020\tbest: 1.0912856 (7317)\ttotal: 37.3s\tremaining: 3m 34s\n",
            "7500:\tlearn: 1.0803819\ttest: 1.0912767\tbest: 1.0912735 (7493)\ttotal: 37.8s\tremaining: 3m 34s\n",
            "7600:\tlearn: 1.0802867\ttest: 1.0912613\tbest: 1.0912608 (7598)\ttotal: 38.3s\tremaining: 3m 33s\n",
            "7700:\tlearn: 1.0801925\ttest: 1.0912440\tbest: 1.0912440 (7694)\ttotal: 38.8s\tremaining: 3m 33s\n",
            "7800:\tlearn: 1.0800979\ttest: 1.0912438\tbest: 1.0912400 (7762)\ttotal: 39.3s\tremaining: 3m 32s\n",
            "7900:\tlearn: 1.0800135\ttest: 1.0912390\tbest: 1.0912327 (7829)\ttotal: 39.8s\tremaining: 3m 32s\n",
            "8000:\tlearn: 1.0799181\ttest: 1.0912504\tbest: 1.0912327 (7829)\ttotal: 40.3s\tremaining: 3m 31s\n",
            "8100:\tlearn: 1.0798199\ttest: 1.0912476\tbest: 1.0912327 (7829)\ttotal: 40.8s\tremaining: 3m 30s\n",
            "8200:\tlearn: 1.0797469\ttest: 1.0912482\tbest: 1.0912327 (7829)\ttotal: 41.3s\tremaining: 3m 30s\n",
            "8300:\tlearn: 1.0796630\ttest: 1.0912433\tbest: 1.0912327 (7829)\ttotal: 41.8s\tremaining: 3m 29s\n",
            "8400:\tlearn: 1.0795822\ttest: 1.0912483\tbest: 1.0912327 (7829)\ttotal: 42.3s\tremaining: 3m 29s\n",
            "8500:\tlearn: 1.0794982\ttest: 1.0912336\tbest: 1.0912309 (8493)\ttotal: 42.8s\tremaining: 3m 28s\n",
            "8600:\tlearn: 1.0794038\ttest: 1.0912517\tbest: 1.0912290 (8527)\ttotal: 43.3s\tremaining: 3m 28s\n",
            "8700:\tlearn: 1.0793229\ttest: 1.0912539\tbest: 1.0912290 (8527)\ttotal: 43.8s\tremaining: 3m 27s\n",
            "8800:\tlearn: 1.0792368\ttest: 1.0912508\tbest: 1.0912290 (8527)\ttotal: 44.3s\tremaining: 3m 27s\n",
            "8900:\tlearn: 1.0791606\ttest: 1.0912607\tbest: 1.0912290 (8527)\ttotal: 44.8s\tremaining: 3m 26s\n",
            "9000:\tlearn: 1.0790791\ttest: 1.0912650\tbest: 1.0912290 (8527)\ttotal: 45.3s\tremaining: 3m 26s\n",
            "9100:\tlearn: 1.0789979\ttest: 1.0912636\tbest: 1.0912290 (8527)\ttotal: 45.8s\tremaining: 3m 26s\n",
            "9200:\tlearn: 1.0789222\ttest: 1.0912688\tbest: 1.0912290 (8527)\ttotal: 46.4s\tremaining: 3m 25s\n",
            "9300:\tlearn: 1.0788363\ttest: 1.0912713\tbest: 1.0912290 (8527)\ttotal: 46.9s\tremaining: 3m 25s\n",
            "9400:\tlearn: 1.0787619\ttest: 1.0912757\tbest: 1.0912290 (8527)\ttotal: 47.4s\tremaining: 3m 24s\n",
            "9500:\tlearn: 1.0786894\ttest: 1.0912586\tbest: 1.0912290 (8527)\ttotal: 48s\tremaining: 3m 24s\n",
            "bestTest = 1.091229004\n",
            "bestIteration = 8527\n",
            "Shrink model to first 8528 iterations.\n",
            "fold: 5,log_loss: 1.0909545096518674\n",
            "catboost_3seeds_10fold ,log_loss: 1.0901937407402615\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f2d7dd1b-30ce-4f97-b97e-182cfac9d17e\", \"catboost_3seeds_10fold_oof.txt\", 3200161)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b97bb618-3674-45de-a7fa-890a6abd4491\", \"catboost_3seeds_10fold_test.csv\", 4261287)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G1hNbBKtUaN"
      },
      "source": [
        "# CBoost Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBMCCSDT9G7C"
      },
      "source": [
        "X = df_all.drop(labels=['id','target'],axis=1,inplace=False).copy()\n",
        "y = df_all['target'].map({\"Class_1\":0,\"Class_2\":1,\"Class_3\":2,\"Class_4\":3}).values\n",
        "X_test = df_test.drop(labels=['id'],axis=1,inplace=False).copy()\n",
        "random_seed = 0\n",
        "\n",
        "encoder = OrdinalEncoder()\n",
        "all_encoded = encoder.fit_transform(X.append(X_test))\n",
        "X = all_encoded[0:len(X)]\n",
        "X_test = all_encoded[len(X):]\n",
        "\n",
        "X = X.astype(int)\n",
        "X_test = X_test.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eBEKILftWVA"
      },
      "source": [
        "X = df_all.drop(labels=['id','target'],axis=1,inplace=False).copy()\n",
        "y = df_all['target'].values\n",
        "X_test = df_test.drop(labels=['id'],axis=1,inplace=False).copy()\n",
        "random_seed = 0\n",
        "\n",
        "encoder = OrdinalEncoder()\n",
        "all_encoded = encoder.fit_transform(X.append(X_test))\n",
        "X = all_encoded[0:len(X)]\n",
        "X_test = all_encoded[len(X):]\n",
        "\n",
        "X = X.astype(int)\n",
        "X_test = X_test.astype(int)\n",
        "cat_features = np.arange(0,X.shape[1]).tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zvo_r20ktnxP"
      },
      "source": [
        "# for the fixed learning rate, use the opt n iterations and tune the tree hyperparameters\n",
        "def objective(trial,data=X,target=y):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        " \n",
        "\n",
        "  param_space = {\n",
        "        \"od_type\" : \"Iter\",\n",
        "        \"od_wait\" : 1000,\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-2, 4e-2),\n",
        "         \"depth\": trial.suggest_int(\"depth\", 1, 16),\n",
        "        \"l2_leaf_reg\": trial.suggest_loguniform('l2_leaf_reg', 1e-4, 1e3),\n",
        "        \"random_strength\": trial.suggest_float(\"random_strength\",0,3),\n",
        "        # \"bagging_temperature\": trial.suggest_int(\"bagging_temperature\",0,100),\n",
        "        \"border_count\": trial.suggest_int(\"border_count\",128,128),\n",
        "        \"grow_policy\":trial.suggest_categorical(\"grow_policy\",[\"Depthwise\",\"SymmetricTree\",\"Lossguide\"]),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 300)\n",
        "\n",
        "        }\n",
        "            \n",
        "  #X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=.1,random_state=2021,stratify=y)\n",
        "  k=5\n",
        "  seed_list=[0]\n",
        "  kf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\n",
        "  oof = np.zeros((len(df_all),4))\n",
        "  score_list = []\n",
        "  fold=1\n",
        "  \n",
        "  splits = list(kf.split(X,y))\n",
        "  for train_idx, val_idx in splits:\n",
        "    X_train, X_val = X[train_idx,:], X[val_idx,:]\n",
        "    y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "    if fold > 1:break\n",
        "\n",
        "  \n",
        "    val_preds_list = []\n",
        "  \n",
        "    \n",
        "    for seed in seed_list:\n",
        "      # fit and run model\n",
        "      param_space['random_state'] = seed\n",
        "      param_space [\"loss_function\"] = 'MultiClass'\n",
        "\n",
        "      param_space[\"cat_features\"] = cat_features\n",
        "\n",
        "      model = CatBoostClassifier(**param_space,\n",
        "                                task_type=\"GPU\",\n",
        "                                 iterations=50000,\n",
        "                                 use_best_model=True)\n",
        "      \n",
        "      model.fit(X_train,y=y_train,\n",
        "              embedding_features=None,\n",
        "              use_best_model=True,\n",
        "              eval_set=[(X_val,y_val)],\n",
        "              verbose=0)\n",
        "    \n",
        "    \n",
        "      val_preds_list.append(model.predict_proba(X_val))\n",
        "     #test_preds_list.append(model.predict_proba(X_test)[:,1])\n",
        "    \n",
        "    oof[val_idx] = np.mean(val_preds_list,axis=0)\n",
        "    score = log_loss(y_val, oof[val_idx])\n",
        "    print(f\"fold: {fold},logloss: {score}\")\n",
        "    score_list.append(score)\n",
        "    fold +=1\n",
        "  \n",
        "  cv_logloss = np.mean(score_list)\n",
        "  \n",
        "  return cv_logloss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "excIEzThuOLZ",
        "outputId": "ce0d4b95-b0d9-484c-ab55-00fe083ae40a"
      },
      "source": [
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective,n_trials= 100)\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:', study.best_trial.params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:14:24,115]\u001b[0m A new study created in memory with name: no-name-3ad323a3-ad18-49b1-8059-860d69aafae9\u001b[0m\n",
            "\u001b[32m[I 2021-05-26 01:17:18,543]\u001b[0m Trial 0 finished with value: 1.0936730625857125 and parameters: {'learning_rate': 0.013156916090252357, 'depth': 11, 'l2_leaf_reg': 0.5384381111955518, 'random_strength': 1.2907674309630877, 'border_count': 128, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 102}. Best is trial 0 with value: 1.0936730625857125.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0936730625857125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:17:56,075]\u001b[0m Trial 1 finished with value: 1.0917748757104253 and parameters: {'learning_rate': 0.03371656914750022, 'depth': 15, 'l2_leaf_reg': 0.002015270203057493, 'random_strength': 2.7869012982784773, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 251}. Best is trial 1 with value: 1.0917748757104253.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0917748757104253\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:18:31,408]\u001b[0m Trial 2 finished with value: 1.09123335957795 and parameters: {'learning_rate': 0.029761539054575115, 'depth': 13, 'l2_leaf_reg': 3.870654880389206, 'random_strength': 2.846634602474385, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 174}. Best is trial 2 with value: 1.09123335957795.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.09123335957795\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:20:29,069]\u001b[0m Trial 3 finished with value: 1.0913736216612444 and parameters: {'learning_rate': 0.013462460010380298, 'depth': 14, 'l2_leaf_reg': 125.92653199898643, 'random_strength': 0.11545984929535558, 'border_count': 128, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 214}. Best is trial 2 with value: 1.09123335957795.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0913736216612444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:21:09,361]\u001b[0m Trial 4 finished with value: 1.0917277117303303 and parameters: {'learning_rate': 0.01501584954058455, 'depth': 10, 'l2_leaf_reg': 0.07428721415905945, 'random_strength': 0.8939338380058225, 'border_count': 128, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 172}. Best is trial 2 with value: 1.09123335957795.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0917277117303303\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:31:14,271]\u001b[0m Trial 5 finished with value: 1.1041153185477988 and parameters: {'learning_rate': 0.022040766722310794, 'depth': 14, 'l2_leaf_reg': 0.0003096138722320694, 'random_strength': 0.5947904870456222, 'border_count': 128, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 288}. Best is trial 2 with value: 1.09123335957795.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.1041153185477988\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:32:23,634]\u001b[0m Trial 6 finished with value: 1.0906025011984493 and parameters: {'learning_rate': 0.0108191065116097, 'depth': 4, 'l2_leaf_reg': 0.0009448001527833548, 'random_strength': 1.4822975999955914, 'border_count': 128, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 96}. Best is trial 6 with value: 1.0906025011984493.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0906025011984493\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:34:09,909]\u001b[0m Trial 7 finished with value: 1.0910982677715295 and parameters: {'learning_rate': 0.01312428002520567, 'depth': 2, 'l2_leaf_reg': 0.20000122136537346, 'random_strength': 0.6174284004490714, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 113}. Best is trial 6 with value: 1.0906025011984493.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0910982677715295\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:35:01,667]\u001b[0m Trial 8 finished with value: 1.0900635854779561 and parameters: {'learning_rate': 0.032485724898384104, 'depth': 4, 'l2_leaf_reg': 186.44838878460115, 'random_strength': 0.7845449907765651, 'border_count': 128, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 11}. Best is trial 8 with value: 1.0900635854779561.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0900635854779561\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:36:08,508]\u001b[0m Trial 9 finished with value: 1.0916669858008479 and parameters: {'learning_rate': 0.012268571866403464, 'depth': 10, 'l2_leaf_reg': 0.0004349197856241522, 'random_strength': 2.112385605279367, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 88}. Best is trial 8 with value: 1.0900635854779561.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0916669858008479\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:37:10,190]\u001b[0m Trial 10 finished with value: 1.0901273500896327 and parameters: {'learning_rate': 0.03886730105650687, 'depth': 6, 'l2_leaf_reg': 376.7645584214773, 'random_strength': 0.1300123728327689, 'border_count': 128, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 8}. Best is trial 8 with value: 1.0900635854779561.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0901273500896327\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:38:23,952]\u001b[0m Trial 11 finished with value: 1.0899171898961861 and parameters: {'learning_rate': 0.03986954511342789, 'depth': 6, 'l2_leaf_reg': 831.0008666303925, 'random_strength': 0.02831790154105862, 'border_count': 128, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 4}. Best is trial 11 with value: 1.0899171898961861.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0899171898961861\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:40:13,657]\u001b[0m Trial 12 finished with value: 1.0895409471737145 and parameters: {'learning_rate': 0.024855918581260232, 'depth': 6, 'l2_leaf_reg': 933.4915423830699, 'random_strength': 0.09734443178524069, 'border_count': 128, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 5}. Best is trial 12 with value: 1.0895409471737145.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0895409471737145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:40:53,434]\u001b[0m Trial 13 finished with value: 1.090858650947701 and parameters: {'learning_rate': 0.023439570435029554, 'depth': 7, 'l2_leaf_reg': 17.468683508680506, 'random_strength': 0.029147140000349653, 'border_count': 128, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 43}. Best is trial 12 with value: 1.0895409471737145.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.090858650947701\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:43:01,184]\u001b[0m Trial 14 finished with value: 1.0898932076940786 and parameters: {'learning_rate': 0.017914331265107778, 'depth': 7, 'l2_leaf_reg': 651.7613367455286, 'random_strength': 0.007872839841910388, 'border_count': 128, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 43}. Best is trial 12 with value: 1.0895409471737145.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0898932076940786\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:46:11,895]\u001b[0m Trial 15 finished with value: 1.0908979046255476 and parameters: {'learning_rate': 0.018691127809143393, 'depth': 1, 'l2_leaf_reg': 24.245227389460183, 'random_strength': 2.0369998134448632, 'border_count': 128, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 49}. Best is trial 12 with value: 1.0895409471737145.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0908979046255476\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:46:59,031]\u001b[0m Trial 16 finished with value: 1.0912775790493539 and parameters: {'learning_rate': 0.017508309781021757, 'depth': 4, 'l2_leaf_reg': 0.016718733212633414, 'random_strength': 0.3133634371883933, 'border_count': 128, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 54}. Best is trial 12 with value: 1.0895409471737145.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0912775790493539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:49:06,224]\u001b[0m Trial 17 finished with value: 1.0903837190237031 and parameters: {'learning_rate': 0.025336849250549836, 'depth': 8, 'l2_leaf_reg': 789.7621455742122, 'random_strength': 1.0555185040679134, 'border_count': 128, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 31}. Best is trial 12 with value: 1.0895409471737145.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0903837190237031\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:50:07,245]\u001b[0m Trial 18 finished with value: 1.090972787106554 and parameters: {'learning_rate': 0.015879807414925153, 'depth': 9, 'l2_leaf_reg': 24.054008941575752, 'random_strength': 0.3947847540086654, 'border_count': 128, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 66}. Best is trial 12 with value: 1.0895409471737145.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.090972787106554\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:50:38,981]\u001b[0m Trial 19 finished with value: 1.091211035223902 and parameters: {'learning_rate': 0.027073306858866025, 'depth': 6, 'l2_leaf_reg': 2.5834860174475804, 'random_strength': 2.023103410175221, 'border_count': 128, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 131}. Best is trial 12 with value: 1.0895409471737145.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.091211035223902\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:52:19,042]\u001b[0m Trial 20 finished with value: 1.0900380713247595 and parameters: {'learning_rate': 0.020505115895426237, 'depth': 3, 'l2_leaf_reg': 80.23542872515546, 'random_strength': 0.396246471804089, 'border_count': 128, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 9}. Best is trial 12 with value: 1.0895409471737145.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0900380713247595\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:53:27,938]\u001b[0m Trial 21 finished with value: 1.0898947241202845 and parameters: {'learning_rate': 0.03994437686124017, 'depth': 6, 'l2_leaf_reg': 751.8361503112579, 'random_strength': 0.011151543070703512, 'border_count': 128, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 3}. Best is trial 12 with value: 1.0895409471737145.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0898947241202845\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:56:11,787]\u001b[0m Trial 22 finished with value: 1.090286097839045 and parameters: {'learning_rate': 0.016708659684024168, 'depth': 8, 'l2_leaf_reg': 751.1092239882184, 'random_strength': 0.0157414799361085, 'border_count': 128, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 29}. Best is trial 12 with value: 1.0895409471737145.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.090286097839045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:57:16,931]\u001b[0m Trial 23 finished with value: 1.0906070531767451 and parameters: {'learning_rate': 0.020250924392917792, 'depth': 5, 'l2_leaf_reg': 46.08259250788128, 'random_strength': 0.38260298922814145, 'border_count': 128, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 1}. Best is trial 12 with value: 1.0895409471737145.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0906070531767451\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:58:38,972]\u001b[0m Trial 24 finished with value: 1.0901443193107259 and parameters: {'learning_rate': 0.034798402520633445, 'depth': 7, 'l2_leaf_reg': 837.3486941896192, 'random_strength': 0.01095389267904352, 'border_count': 128, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 78}. Best is trial 12 with value: 1.0895409471737145.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0901443193107259\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 01:59:11,510]\u001b[0m Trial 25 finished with value: 1.0910910227229447 and parameters: {'learning_rate': 0.02777020757150434, 'depth': 7, 'l2_leaf_reg': 3.4815776061530666, 'random_strength': 0.6234730213999158, 'border_count': 128, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 28}. Best is trial 12 with value: 1.0895409471737145.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0910910227229447\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:00:18,094]\u001b[0m Trial 26 finished with value: 1.0901492605209266 and parameters: {'learning_rate': 0.024095882680997993, 'depth': 5, 'l2_leaf_reg': 228.3063623022916, 'random_strength': 0.23475881250449476, 'border_count': 128, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 68}. Best is trial 12 with value: 1.0895409471737145.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0901492605209266\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:01:09,662]\u001b[0m Trial 27 finished with value: 1.0911240078360123 and parameters: {'learning_rate': 0.018825241076477806, 'depth': 9, 'l2_leaf_reg': 11.598650922502578, 'random_strength': 1.0599138612172527, 'border_count': 128, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 26}. Best is trial 12 with value: 1.0895409471737145.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0911240078360123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:03:03,032]\u001b[0m Trial 28 finished with value: 1.09117371845358 and parameters: {'learning_rate': 0.014988078711614136, 'depth': 11, 'l2_leaf_reg': 258.00437193286047, 'random_strength': 2.554212251511614, 'border_count': 128, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 131}. Best is trial 12 with value: 1.0895409471737145.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.09117371845358\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:03:45,512]\u001b[0m Trial 29 finished with value: 1.0907915005870064 and parameters: {'learning_rate': 0.036384762866682234, 'depth': 2, 'l2_leaf_reg': 0.8658570009071821, 'random_strength': 1.3498603421182762, 'border_count': 128, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 109}. Best is trial 12 with value: 1.0895409471737145.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0907915005870064\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:05:01,362]\u001b[0m Trial 30 finished with value: 1.0912125875181813 and parameters: {'learning_rate': 0.02189973687793114, 'depth': 12, 'l2_leaf_reg': 62.326559391495216, 'random_strength': 1.714561747736707, 'border_count': 128, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 54}. Best is trial 12 with value: 1.0895409471737145.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0912125875181813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:06:19,222]\u001b[0m Trial 31 finished with value: 1.089753167073865 and parameters: {'learning_rate': 0.039728943228352465, 'depth': 6, 'l2_leaf_reg': 816.4095807504168, 'random_strength': 0.20534225277445606, 'border_count': 128, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 5}. Best is trial 12 with value: 1.0895409471737145.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.089753167073865\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:07:37,055]\u001b[0m Trial 32 finished with value: 1.08945607964074 and parameters: {'learning_rate': 0.031477996156110674, 'depth': 5, 'l2_leaf_reg': 948.6944010932469, 'random_strength': 0.2444413507696459, 'border_count': 128, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 1}. Best is trial 32 with value: 1.08945607964074.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.08945607964074\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:08:32,189]\u001b[0m Trial 33 finished with value: 1.089838921794318 and parameters: {'learning_rate': 0.030263634271309108, 'depth': 5, 'l2_leaf_reg': 351.9511017255033, 'random_strength': 0.520871867179056, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 21}. Best is trial 32 with value: 1.08945607964074.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.089838921794318\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:09:24,898]\u001b[0m Trial 34 finished with value: 1.0901800049957902 and parameters: {'learning_rate': 0.031000913099242373, 'depth': 5, 'l2_leaf_reg': 146.7902500986551, 'random_strength': 0.5405178739368812, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 19}. Best is trial 32 with value: 1.08945607964074.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0901800049957902\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:10:07,291]\u001b[0m Trial 35 finished with value: 1.0912382669326703 and parameters: {'learning_rate': 0.028744007765263375, 'depth': 3, 'l2_leaf_reg': 0.011114512079984058, 'random_strength': 0.8294576319405047, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 221}. Best is trial 32 with value: 1.08945607964074.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0912382669326703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:10:58,846]\u001b[0m Trial 36 finished with value: 1.0893656078377918 and parameters: {'learning_rate': 0.031182867278316047, 'depth': 3, 'l2_leaf_reg': 385.0230714628302, 'random_strength': 0.21522540307264462, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 279}. Best is trial 36 with value: 1.0893656078377918.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0893656078377918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:11:37,910]\u001b[0m Trial 37 finished with value: 1.0910719922637888 and parameters: {'learning_rate': 0.03637530795200608, 'depth': 3, 'l2_leaf_reg': 8.855250925723956, 'random_strength': 0.19225914141439973, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 201}. Best is trial 36 with value: 1.0893656078377918.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0910719922637888\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:13:07,953]\u001b[0m Trial 38 finished with value: 1.0903594903006448 and parameters: {'learning_rate': 0.032959284020650424, 'depth': 1, 'l2_leaf_reg': 88.91361280713481, 'random_strength': 0.24807360150761337, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 276}. Best is trial 36 with value: 1.0893656078377918.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0903594903006448\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:14:17,319]\u001b[0m Trial 39 finished with value: 1.0895305155822956 and parameters: {'learning_rate': 0.026315245384276983, 'depth': 2, 'l2_leaf_reg': 344.60440506553186, 'random_strength': 0.7008795303535766, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 240}. Best is trial 36 with value: 1.0893656078377918.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0895305155822956\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:15:07,469]\u001b[0m Trial 40 finished with value: 1.090430926662173 and parameters: {'learning_rate': 0.02656867728788935, 'depth': 2, 'l2_leaf_reg': 41.560833475361974, 'random_strength': 1.1390829140156926, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 252}. Best is trial 36 with value: 1.0893656078377918.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.090430926662173\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:16:08,359]\u001b[0m Trial 41 finished with value: 1.0895383124597897 and parameters: {'learning_rate': 0.024976069820305535, 'depth': 4, 'l2_leaf_reg': 288.86017196944226, 'random_strength': 0.677879620208168, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 293}. Best is trial 36 with value: 1.0893656078377918.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0895383124597897\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:17:09,901]\u001b[0m Trial 42 finished with value: 1.0895509006588013 and parameters: {'learning_rate': 0.025355527021372025, 'depth': 4, 'l2_leaf_reg': 345.3780297991831, 'random_strength': 0.7589454644653556, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 289}. Best is trial 36 with value: 1.0893656078377918.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0895509006588013\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:17:29,755]\u001b[0m Trial 43 finished with value: 1.3722925766881116 and parameters: {'learning_rate': 0.02303238349929764, 'depth': 16, 'l2_leaf_reg': 0.000120421034537783, 'random_strength': 0.9648666389456422, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 262}. Best is trial 36 with value: 1.0893656078377918.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.3722925766881116\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:18:17,859]\u001b[0m Trial 44 finished with value: 1.0898762169823133 and parameters: {'learning_rate': 0.031078264565011185, 'depth': 3, 'l2_leaf_reg': 126.4955778516638, 'random_strength': 0.6580963598833454, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 222}. Best is trial 36 with value: 1.0893656078377918.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0898762169823133\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:20:52,864]\u001b[0m Trial 45 finished with value: 1.089841531290072 and parameters: {'learning_rate': 0.025474457408448926, 'depth': 1, 'l2_leaf_reg': 404.4084012232522, 'random_strength': 0.4152478978366809, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 297}. Best is trial 36 with value: 1.0893656078377918.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.089841531290072\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:21:58,013]\u001b[0m Trial 46 finished with value: 1.0896957877206954 and parameters: {'learning_rate': 0.028344985941309103, 'depth': 2, 'l2_leaf_reg': 173.24543849910293, 'random_strength': 0.670627863516998, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 237}. Best is trial 36 with value: 1.0893656078377918.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0896957877206954\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:23:15,160]\u001b[0m Trial 47 finished with value: 1.0894947079115642 and parameters: {'learning_rate': 0.022224386738554383, 'depth': 4, 'l2_leaf_reg': 424.9267188864411, 'random_strength': 0.4997144987986816, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 183}. Best is trial 36 with value: 1.0893656078377918.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0894947079115642\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:24:04,600]\u001b[0m Trial 48 finished with value: 1.0909108133930494 and parameters: {'learning_rate': 0.022662261291484603, 'depth': 3, 'l2_leaf_reg': 7.56458353654428, 'random_strength': 1.2506688174989327, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 172}. Best is trial 36 with value: 1.0893656078377918.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0909108133930494\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:24:40,251]\u001b[0m Trial 49 finished with value: 1.0905550763040048 and parameters: {'learning_rate': 0.029593221833337905, 'depth': 4, 'l2_leaf_reg': 35.753588218239855, 'random_strength': 0.49609462579133934, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 194}. Best is trial 36 with value: 1.0893656078377918.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0905550763040048\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:25:58,927]\u001b[0m Trial 50 finished with value: 1.0895460664718473 and parameters: {'learning_rate': 0.0213496480470279, 'depth': 2, 'l2_leaf_reg': 411.27034109266464, 'random_strength': 0.9093565209465545, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 272}. Best is trial 36 with value: 1.0893656078377918.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0895460664718473\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:27:22,983]\u001b[0m Trial 51 finished with value: 1.0895625117104677 and parameters: {'learning_rate': 0.024471011485167598, 'depth': 4, 'l2_leaf_reg': 946.4304547535247, 'random_strength': 0.7253976474947932, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 238}. Best is trial 36 with value: 1.0893656078377918.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0895625117104677\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:28:09,857]\u001b[0m Trial 52 finished with value: 1.0902002549107241 and parameters: {'learning_rate': 0.02735615509437021, 'depth': 5, 'l2_leaf_reg': 126.55776479781034, 'random_strength': 0.1737319481125681, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 298}. Best is trial 36 with value: 1.0893656078377918.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0902002549107241\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:29:42,551]\u001b[0m Trial 53 finished with value: 1.0896666565509825 and parameters: {'learning_rate': 0.026091179277786845, 'depth': 4, 'l2_leaf_reg': 509.5856147241807, 'random_strength': 0.3465143606557869, 'border_count': 128, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 157}. Best is trial 36 with value: 1.0893656078377918.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0896666565509825\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:30:33,491]\u001b[0m Trial 54 finished with value: 1.0895593120454514 and parameters: {'learning_rate': 0.031853551359313906, 'depth': 3, 'l2_leaf_reg': 215.92596410252526, 'random_strength': 0.10771409012684866, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 194}. Best is trial 36 with value: 1.0893656078377918.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0895593120454514\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:31:56,792]\u001b[0m Trial 55 finished with value: 1.0894581268604822 and parameters: {'learning_rate': 0.02416655127398458, 'depth': 4, 'l2_leaf_reg': 983.4926947861992, 'random_strength': 0.48921887753282756, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 280}. Best is trial 36 with value: 1.0893656078377918.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0894581268604822\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:34:30,090]\u001b[0m Trial 56 finished with value: 1.0903951665658365 and parameters: {'learning_rate': 0.021209372582557635, 'depth': 1, 'l2_leaf_reg': 78.33159979854739, 'random_strength': 0.5560152078242496, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 281}. Best is trial 36 with value: 1.0893656078377918.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0903951665658365\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:36:58,116]\u001b[0m Trial 57 finished with value: 1.0894578568126232 and parameters: {'learning_rate': 0.01948561311443658, 'depth': 2, 'l2_leaf_reg': 986.843322630798, 'random_strength': 0.48108309264475396, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 264}. Best is trial 36 with value: 1.0893656078377918.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0894578568126232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:38:02,209]\u001b[0m Trial 58 finished with value: 1.0893288494096096 and parameters: {'learning_rate': 0.03421749187575194, 'depth': 2, 'l2_leaf_reg': 980.0688977807835, 'random_strength': 0.2972310405198672, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 265}. Best is trial 58 with value: 1.0893288494096096.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0893288494096096\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:41:31,605]\u001b[0m Trial 59 finished with value: 1.0897962116319582 and parameters: {'learning_rate': 0.01919921759207699, 'depth': 1, 'l2_leaf_reg': 586.344560179548, 'random_strength': 0.4437939120610286, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 256}. Best is trial 58 with value: 1.0893288494096096.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0897962116319582\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:42:36,735]\u001b[0m Trial 60 finished with value: 1.0893677900361394 and parameters: {'learning_rate': 0.03444325353635256, 'depth': 2, 'l2_leaf_reg': 978.8484680152261, 'random_strength': 0.2568778535176919, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 268}. Best is trial 58 with value: 1.0893288494096096.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0893677900361394\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:43:41,709]\u001b[0m Trial 61 finished with value: 1.0892181195137285 and parameters: {'learning_rate': 0.03470328317940195, 'depth': 2, 'l2_leaf_reg': 820.7804346737378, 'random_strength': 0.336019499813798, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 267}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0892181195137285\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:44:46,538]\u001b[0m Trial 62 finished with value: 1.0892904968140071 and parameters: {'learning_rate': 0.034221785692382316, 'depth': 2, 'l2_leaf_reg': 835.3866281744371, 'random_strength': 0.28488828779267983, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 265}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0892904968140071\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:45:56,123]\u001b[0m Trial 63 finished with value: 1.0893174139621389 and parameters: {'learning_rate': 0.03457834568351262, 'depth': 2, 'l2_leaf_reg': 958.440235767502, 'random_strength': 0.29272237004676877, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 270}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0893174139621389\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:47:25,537]\u001b[0m Trial 64 finished with value: 1.0910299255646903 and parameters: {'learning_rate': 0.0346280861626067, 'depth': 1, 'l2_leaf_reg': 0.09081018170185653, 'random_strength': 0.29491707698180175, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 269}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0910299255646903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:48:25,146]\u001b[0m Trial 65 finished with value: 1.089318246144644 and parameters: {'learning_rate': 0.03710141600201844, 'depth': 2, 'l2_leaf_reg': 558.5968361865588, 'random_strength': 0.3127273674465709, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 243}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.089318246144644\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:49:20,142]\u001b[0m Trial 66 finished with value: 1.0894335000315427 and parameters: {'learning_rate': 0.03585904531411611, 'depth': 2, 'l2_leaf_reg': 582.7302964835054, 'random_strength': 0.11031112685956082, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 245}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0894335000315427\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:50:10,495]\u001b[0m Trial 67 finished with value: 1.0896915148405897 and parameters: {'learning_rate': 0.038562580203318646, 'depth': 3, 'l2_leaf_reg': 194.90345201456637, 'random_strength': 0.35228011342717114, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 228}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0896915148405897\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:51:32,264]\u001b[0m Trial 68 finished with value: 1.0909251690212947 and parameters: {'learning_rate': 0.03799055534571518, 'depth': 1, 'l2_leaf_reg': 1.4001406741123426, 'random_strength': 0.09098331421683264, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 284}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0909251690212947\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:52:19,422]\u001b[0m Trial 69 finished with value: 1.0899986793277991 and parameters: {'learning_rate': 0.03402495853699699, 'depth': 2, 'l2_leaf_reg': 97.43743822434416, 'random_strength': 0.291401549488778, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 257}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0899986793277991\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:55:09,262]\u001b[0m Trial 70 finished with value: 1.0900723453865782 and parameters: {'learning_rate': 0.033798062058272356, 'depth': 1, 'l2_leaf_reg': 599.448590066419, 'random_strength': 0.013744116111696736, 'border_count': 128, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 247}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0900723453865782\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:56:07,876]\u001b[0m Trial 71 finished with value: 1.0893400949749676 and parameters: {'learning_rate': 0.03621038263285698, 'depth': 2, 'l2_leaf_reg': 533.960668429752, 'random_strength': 0.10001092024569602, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 247}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0893400949749676\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:57:16,668]\u001b[0m Trial 72 finished with value: 1.0893254576401554 and parameters: {'learning_rate': 0.03728616440807451, 'depth': 2, 'l2_leaf_reg': 994.3601273634645, 'random_strength': 0.13574580234116104, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 269}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0893254576401554\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:58:05,880]\u001b[0m Trial 73 finished with value: 1.0896765016142818 and parameters: {'learning_rate': 0.03800427127814925, 'depth': 3, 'l2_leaf_reg': 247.7103947864746, 'random_strength': 0.12985613654360112, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 230}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0896765016142818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:59:03,625]\u001b[0m Trial 74 finished with value: 1.0893391818776295 and parameters: {'learning_rate': 0.03712071307129933, 'depth': 2, 'l2_leaf_reg': 528.9614400164178, 'random_strength': 0.357698560739957, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 213}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0893391818776295\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 02:59:59,699]\u001b[0m Trial 75 finished with value: 1.0894076000132484 and parameters: {'learning_rate': 0.037051826107494204, 'depth': 2, 'l2_leaf_reg': 591.0606183450992, 'random_strength': 0.3551828591588744, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 207}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0894076000132484\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 03:01:18,428]\u001b[0m Trial 76 finished with value: 1.090450838282479 and parameters: {'learning_rate': 0.03551544756394467, 'depth': 1, 'l2_leaf_reg': 57.39493018860778, 'random_strength': 0.055419698810689685, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 258}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.090450838282479\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 03:01:56,865]\u001b[0m Trial 77 finished with value: 1.0899319279236737 and parameters: {'learning_rate': 0.03983029402365815, 'depth': 3, 'l2_leaf_reg': 149.74734129163107, 'random_strength': 0.17656186016737035, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 246}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0899319279236737\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 03:03:03,674]\u001b[0m Trial 78 finished with value: 1.0893790284088367 and parameters: {'learning_rate': 0.03317143245170267, 'depth': 2, 'l2_leaf_reg': 972.8933059550332, 'random_strength': 0.6027626715653418, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 217}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0893790284088367\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 03:04:33,910]\u001b[0m Trial 79 finished with value: 1.0909897220244085 and parameters: {'learning_rate': 0.03743817129029097, 'depth': 1, 'l2_leaf_reg': 0.003212162328777696, 'random_strength': 1.7140744701350819, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 230}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0909897220244085\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 03:05:25,322]\u001b[0m Trial 80 finished with value: 1.0912291704274828 and parameters: {'learning_rate': 0.03272475351054391, 'depth': 2, 'l2_leaf_reg': 0.28560909285353414, 'random_strength': 2.9882596389249656, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 252}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0912291704274828\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 03:06:12,964]\u001b[0m Trial 81 finished with value: 1.0894591966681864 and parameters: {'learning_rate': 0.035765720277424445, 'depth': 3, 'l2_leaf_reg': 288.46139523159195, 'random_strength': 0.4148070916402826, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 275}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0894591966681864\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 03:08:13,641]\u001b[0m Trial 82 finished with value: 1.0898470480978866 and parameters: {'learning_rate': 0.029843541584785197, 'depth': 1, 'l2_leaf_reg': 481.36208842414953, 'random_strength': 0.1996032727496774, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 288}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0898470480978866\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 03:09:00,914]\u001b[0m Trial 83 finished with value: 1.0893463691319536 and parameters: {'learning_rate': 0.03926308163068799, 'depth': 3, 'l2_leaf_reg': 665.1377815081487, 'random_strength': 0.30976541266784574, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 265}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0893463691319536\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 03:09:59,944]\u001b[0m Trial 84 finished with value: 1.0893037525909588 and parameters: {'learning_rate': 0.03901528648125209, 'depth': 2, 'l2_leaf_reg': 663.0455721967816, 'random_strength': 0.32466049924708296, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 264}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0893037525909588\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 03:10:40,608]\u001b[0m Trial 85 finished with value: 1.0896210442910248 and parameters: {'learning_rate': 0.03688197212489121, 'depth': 2, 'l2_leaf_reg': 227.47635580437895, 'random_strength': 0.0037596386449170183, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 239}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0896210442910248\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 03:12:43,438]\u001b[0m Trial 86 finished with value: 1.0897703599912816 and parameters: {'learning_rate': 0.035168901321102834, 'depth': 1, 'l2_leaf_reg': 925.3767703252572, 'random_strength': 0.5678498712069063, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 261}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0897703599912816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 03:13:42,317]\u001b[0m Trial 87 finished with value: 1.0894965941547123 and parameters: {'learning_rate': 0.03993312509687114, 'depth': 2, 'l2_leaf_reg': 289.3191509574759, 'random_strength': 0.41744596106682363, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 272}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0894965941547123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 03:14:46,153]\u001b[0m Trial 88 finished with value: 1.089442569381887 and parameters: {'learning_rate': 0.03197878001976378, 'depth': 3, 'l2_leaf_reg': 675.7390560194259, 'random_strength': 0.28624922685166987, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 251}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.089442569381887\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 03:17:49,359]\u001b[0m Trial 89 finished with value: 1.0901926140174014 and parameters: {'learning_rate': 0.011399369008433094, 'depth': 2, 'l2_leaf_reg': 109.42954223924653, 'random_strength': 2.402778085636111, 'border_count': 128, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 211}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0901926140174014\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 03:18:35,801]\u001b[0m Trial 90 finished with value: 1.0900460310420026 and parameters: {'learning_rate': 0.03860712470790228, 'depth': 14, 'l2_leaf_reg': 455.09261237977887, 'random_strength': 0.1334769315571008, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 293}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0900460310420026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 03:19:33,680]\u001b[0m Trial 91 finished with value: 1.0893193156374572 and parameters: {'learning_rate': 0.03692639165004983, 'depth': 3, 'l2_leaf_reg': 691.3307287921568, 'random_strength': 0.3221854722749819, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 263}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0893193156374572\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 03:20:23,780]\u001b[0m Trial 92 finished with value: 1.0897744212699079 and parameters: {'learning_rate': 0.03658655226872698, 'depth': 3, 'l2_leaf_reg': 181.0410225755704, 'random_strength': 0.23702249008038628, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 300}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0897744212699079\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 03:21:33,117]\u001b[0m Trial 93 finished with value: 1.0893246296783705 and parameters: {'learning_rate': 0.03372924608412938, 'depth': 2, 'l2_leaf_reg': 714.6546855558656, 'random_strength': 0.3602034835049949, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 267}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0893246296783705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 03:23:24,638]\u001b[0m Trial 94 finished with value: 1.089809266669314 and parameters: {'learning_rate': 0.032868371577436356, 'depth': 1, 'l2_leaf_reg': 961.2929127244213, 'random_strength': 0.3469398348251096, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 285}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.089809266669314\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 03:24:31,339]\u001b[0m Trial 95 finished with value: 1.0895004476062962 and parameters: {'learning_rate': 0.03408571062191403, 'depth': 2, 'l2_leaf_reg': 358.73094195316924, 'random_strength': 0.44176044019574945, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 276}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0895004476062962\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 03:25:29,166]\u001b[0m Trial 96 finished with value: 1.0893817742856442 and parameters: {'learning_rate': 0.035005504442688004, 'depth': 2, 'l2_leaf_reg': 718.6664708642576, 'random_strength': 0.37373023043196835, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 265}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0893817742856442\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 03:26:58,995]\u001b[0m Trial 97 finished with value: 1.0899209516737272 and parameters: {'learning_rate': 0.03732433535686841, 'depth': 1, 'l2_leaf_reg': 312.4222472929482, 'random_strength': 0.6045950777204581, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 234}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0899209516737272\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 03:27:57,846]\u001b[0m Trial 98 finished with value: 1.0892932681969183 and parameters: {'learning_rate': 0.030297504795236803, 'depth': 3, 'l2_leaf_reg': 736.3557840598204, 'random_strength': 0.828589442581315, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 258}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0892932681969183\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-26 03:28:59,054]\u001b[0m Trial 99 finished with value: 1.0893328322289726 and parameters: {'learning_rate': 0.03052707157167038, 'depth': 3, 'l2_leaf_reg': 776.6442381094598, 'random_strength': 0.7784514824031952, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 257}. Best is trial 61 with value: 1.0892181195137285.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold: 1,logloss: 1.0893328322289726\n",
            "Number of finished trials: 100\n",
            "Best trial: {'learning_rate': 0.03470328317940195, 'depth': 2, 'l2_leaf_reg': 820.7804346737378, 'random_strength': 0.336019499813798, 'border_count': 128, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 267}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJR6_Wb1MN7X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}